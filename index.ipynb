{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Tuning Neural Networks with Regularization - Lab \n",
    "\n",
    "## Introduction\n",
    "\n",
    "In this lab, you'll use a train-test partition as well as a validation set to get better insights about how to tune neural networks using regularization techniques. You'll start by repeating the process from the last section: importing the data and performing preprocessing including one-hot encoding. From there, you'll define and compile the model like before. \n",
    "\n",
    "## Objectives\n",
    "\n",
    "You will be able to:\n",
    "\n",
    "- Apply early stopping criteria with a neural network \n",
    "- Apply L1, L2, and dropout regularization on a neural network  \n",
    "- Examine the effects of training with more data on a neural network  \n",
    "\n",
    "\n",
    "## Load the Data\n",
    "\n",
    "Run the following cell to import some of the libraries and classes you'll need in this lab. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using TensorFlow backend.\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import random\n",
    "import matplotlib.pyplot as plt\n",
    "%matplotlib inline\n",
    "from sklearn.model_selection import train_test_split\n",
    "from keras.utils.np_utils import to_categorical\n",
    "from sklearn.preprocessing import LabelBinarizer\n",
    "from keras.preprocessing.text import Tokenizer\n",
    "\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The data is stored in the file `'Bank_complaints.csv'`. Load and preview the dataset."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load and preview the dataset\n",
    "df = pd.read_csv('Bank_complaints.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Product</th>\n",
       "      <th>Consumer complaint narrative</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>0</td>\n",
       "      <td>Student loan</td>\n",
       "      <td>In XX/XX/XXXX I filled out the Fedlaon applica...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1</td>\n",
       "      <td>Student loan</td>\n",
       "      <td>I am being contacted by a debt collector for p...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2</td>\n",
       "      <td>Student loan</td>\n",
       "      <td>I cosigned XXXX student loans at SallieMae for...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>3</td>\n",
       "      <td>Student loan</td>\n",
       "      <td>Navient has sytematically and illegally failed...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>4</td>\n",
       "      <td>Student loan</td>\n",
       "      <td>My wife became eligible for XXXX Loan Forgiven...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "        Product                       Consumer complaint narrative\n",
       "0  Student loan  In XX/XX/XXXX I filled out the Fedlaon applica...\n",
       "1  Student loan  I am being contacted by a debt collector for p...\n",
       "2  Student loan  I cosigned XXXX student loans at SallieMae for...\n",
       "3  Student loan  Navient has sytematically and illegally failed...\n",
       "4  Student loan  My wife became eligible for XXXX Loan Forgiven..."
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Preprocessing Overview\n",
    "\n",
    "Before you begin to practice some of your new tools such as regularization and optimization, let's practice munging some data as you did in the previous section with bank complaints. Recall some techniques:\n",
    "\n",
    "* Sampling in order to reduce training time (investigate model accuracy vs data size later on)\n",
    "* Train - test split\n",
    "* One-hot encoding your complaint text\n",
    "* Transforming your category labels \n",
    "\n",
    "## Preprocessing: Generate a Random Sample\n",
    "\n",
    "Since you have quite a bit of data and training neural networks takes a substantial amount of time and resources, downsample in order to test your initial pipeline. Going forward, these can be interesting areas of investigation: how does your model's performance change as you increase (or decrease) the size of your dataset?  \n",
    "\n",
    "- Generate a random sample of 10,000 observations using seed 123 for consistency of results. \n",
    "- Split this sample into `X` and `y` "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Downsample the data\n",
    "df_sample = df.sample(n=10000, replace=False, random_state=123)\n",
    "\n",
    "# Split the data into X and y\n",
    "X = df['Consumer complaint narrative']\n",
    "y = df['Product']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0        In XX/XX/XXXX I filled out the Fedlaon applica...\n",
       "1        I am being contacted by a debt collector for p...\n",
       "2        I cosigned XXXX student loans at SallieMae for...\n",
       "3        Navient has sytematically and illegally failed...\n",
       "4        My wife became eligible for XXXX Loan Forgiven...\n",
       "                               ...                        \n",
       "59995    In XXXX, I defaulted on a credit card with XXX...\n",
       "59996    I HAVE CALLED TRANSUNION JUST ABOUT EVERY MONT...\n",
       "59997    Hello, there is a 2012 Chapter XXXX Bankruptcy...\n",
       "59998    I had a 2 yr internet contract with XXXX XXXX ...\n",
       "59999    I filed a complaint against XXXX XXXX XXXX wit...\n",
       "Name: Consumer complaint narrative, Length: 60000, dtype: object"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Train-test split\n",
    "\n",
    "- Split the data into training and test sets \n",
    "- Assign 1500 obervations to the test set and use 42 as the seed "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Split data into training and test sets\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=1500, random_state=42)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Validation set \n",
    "\n",
    "As mentioned in the previous lesson, it is good practice to set aside a validation set, which is then used during hyperparameter tuning. Afterwards, when you have decided upon a final model, the test set can then be used to determine an unbiased perforance of the model. \n",
    "\n",
    "Run the cell below to further divide the training data into training and validation sets. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Split the data into training and validation sets\n",
    "X_train_final, X_val, y_train_final, y_val = train_test_split(X_train, y_train, test_size=1000, random_state=42)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Preprocessing: One-hot Encoding the Complaints\n",
    "\n",
    "As before, you need to do some preprocessing before building a neural network model. \n",
    "\n",
    "- Keep the 2,000 most common words and use one-hot encoding to reformat the complaints into a matrix of vectors \n",
    "- Transform the training, validate, and test sets "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Use one-hot encoding to reformat the complaints into a matrix of vectors \n",
    "# Only keep the 2000 most common words \n",
    "tokenizer = Tokenizer(num_words=2000) \n",
    "\n",
    "tokenizer.fit_on_texts(X_train_final) \n",
    "\n",
    "X_train_tokens = tokenizer.texts_to_matrix(X_train_final, mode='binary') \n",
    "\n",
    "X_val_tokens = tokenizer.texts_to_matrix(X_val, mode='binary') \n",
    "X_test_tokens = tokenizer.texts_to_matrix(X_test, mode='binary') "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Preprocessing: Encoding the Products\n",
    "\n",
    "Similarly, now transform the descriptive product labels to integers labels. After transforming them to integer labels, retransform them into a matrix of binary flags, one for each of the various product labels.  \n",
    "  \n",
    "> **Note**: This is similar to your previous work with dummy variables. Each of the various product categories will be its own column, and each observation will be a row. In turn, each of these observation rows will have a 1 in the column associated with it's label, and all other entries for the row will be zero. \n",
    "\n",
    "Transform the training, validate, and test sets. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Student loan                   11404\n",
       "Credit card                     9540\n",
       "Consumer Loan                   9474\n",
       "Mortgage                        8332\n",
       "Bank account or service         8309\n",
       "Credit reporting                6864\n",
       "Checking or savings account     6077\n",
       "Name: Product, dtype: int64"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.Product.value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Transform the product labels to numerical values\n",
    "\n",
    "lb = LabelBinarizer()\n",
    "lb.fit(y_train_final)\n",
    "\n",
    "y_train_lb = to_categorical(lb.transform(y_train_final))[:, :, 1]\n",
    "y_val_lb = to_categorical(lb.transform(y_val))[:, :, 1]\n",
    "y_test_lb = to_categorical(lb.transform(y_test))[:, :, 1]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## A Baseline Model \n",
    "\n",
    "Rebuild a fully connected (Dense) layer network:  \n",
    "- Use 2 hidden layers with 50 units in the first and 25 in the second layer, both with `'relu'` activation functions (since you are dealing with a multiclass problem, classifying the complaints into 7 classes) \n",
    "- Use a `'softmax'` activation function for the output layer  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Build a baseline neural network model using Keras\n",
    "random.seed(123)\n",
    "from keras import models\n",
    "from keras import layers\n",
    "baseline_model = models.Sequential()\n",
    "\n",
    "baseline_model.add(layers.Dense(50, activation='relu'))\n",
    "baseline_model.add(layers.Dense(25, activation='relu'))\n",
    "baseline_model.add(layers.Dense(7, activation='softmax'))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Compile the Model\n",
    "\n",
    "Compile this model with: \n",
    "\n",
    "- a stochastic gradient descent optimizer \n",
    "- `'categorical_crossentropy'` as the loss function \n",
    "- a focus on `'accuracy'` "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Compile the model\n",
    "baseline_model.compile(optimizer='SGD',\n",
    "              loss='categorical_crossentropy',\n",
    "              metrics=['accuracy'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Train the Model\n",
    "\n",
    "- Train the model for 150 epochs in mini-batches of 256 samples \n",
    "- Include the `validation_data` argument to ensure you keep track of the validation loss  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 57500 samples, validate on 1000 samples\n",
      "Epoch 1/150\n",
      "57500/57500 [==============================] - 4s 61us/step - loss: 1.8957 - acc: 0.2214 - val_loss: 1.8249 - val_acc: 0.2890\n",
      "Epoch 2/150\n",
      "57500/57500 [==============================] - 2s 42us/step - loss: 1.6749 - acc: 0.3871 - val_loss: 1.5250 - val_acc: 0.4700\n",
      "Epoch 3/150\n",
      "57500/57500 [==============================] - 2s 42us/step - loss: 1.3612 - acc: 0.5378 - val_loss: 1.2229 - val_acc: 0.5930\n",
      "Epoch 4/150\n",
      "57500/57500 [==============================] - 3s 47us/step - loss: 1.0999 - acc: 0.6387 - val_loss: 1.0088 - val_acc: 0.6610\n",
      "Epoch 5/150\n",
      "57500/57500 [==============================] - 2s 41us/step - loss: 0.9240 - acc: 0.6896 - val_loss: 0.8786 - val_acc: 0.6820\n",
      "Epoch 6/150\n",
      "57500/57500 [==============================] - 2s 38us/step - loss: 0.8121 - acc: 0.7200 - val_loss: 0.7912 - val_acc: 0.7210\n",
      "Epoch 7/150\n",
      "57500/57500 [==============================] - 2s 35us/step - loss: 0.7394 - acc: 0.7395 - val_loss: 0.7371 - val_acc: 0.7310\n",
      "Epoch 8/150\n",
      "57500/57500 [==============================] - 2s 34us/step - loss: 0.6892 - acc: 0.7543 - val_loss: 0.6967 - val_acc: 0.7500\n",
      "Epoch 9/150\n",
      "57500/57500 [==============================] - 2s 39us/step - loss: 0.6527 - acc: 0.7650 - val_loss: 0.6675 - val_acc: 0.7520\n",
      "Epoch 10/150\n",
      "57500/57500 [==============================] - 2s 40us/step - loss: 0.6252 - acc: 0.7738 - val_loss: 0.6485 - val_acc: 0.7680\n",
      "Epoch 11/150\n",
      "57500/57500 [==============================] - 2s 36us/step - loss: 0.6031 - acc: 0.7818 - val_loss: 0.6312 - val_acc: 0.7660\n",
      "Epoch 12/150\n",
      "57500/57500 [==============================] - 2s 36us/step - loss: 0.5853 - acc: 0.7875 - val_loss: 0.6204 - val_acc: 0.7740\n",
      "Epoch 13/150\n",
      "57500/57500 [==============================] - 2s 37us/step - loss: 0.5703 - acc: 0.7925 - val_loss: 0.6092 - val_acc: 0.7770\n",
      "Epoch 14/150\n",
      "57500/57500 [==============================] - 2s 41us/step - loss: 0.5573 - acc: 0.7978 - val_loss: 0.5991 - val_acc: 0.7790\n",
      "Epoch 15/150\n",
      "57500/57500 [==============================] - 2s 36us/step - loss: 0.5462 - acc: 0.8023 - val_loss: 0.5951 - val_acc: 0.7790\n",
      "Epoch 16/150\n",
      "57500/57500 [==============================] - 2s 38us/step - loss: 0.5362 - acc: 0.8059 - val_loss: 0.5900 - val_acc: 0.7830\n",
      "Epoch 17/150\n",
      "57500/57500 [==============================] - 2s 39us/step - loss: 0.5272 - acc: 0.8089 - val_loss: 0.5795 - val_acc: 0.7860\n",
      "Epoch 18/150\n",
      "57500/57500 [==============================] - 2s 42us/step - loss: 0.5191 - acc: 0.8117 - val_loss: 0.5779 - val_acc: 0.7900\n",
      "Epoch 19/150\n",
      "57500/57500 [==============================] - 2s 36us/step - loss: 0.5114 - acc: 0.8163 - val_loss: 0.5744 - val_acc: 0.7920\n",
      "Epoch 20/150\n",
      "57500/57500 [==============================] - 2s 38us/step - loss: 0.5048 - acc: 0.8187 - val_loss: 0.5725 - val_acc: 0.7960\n",
      "Epoch 21/150\n",
      "57500/57500 [==============================] - 2s 39us/step - loss: 0.4981 - acc: 0.8213 - val_loss: 0.5651 - val_acc: 0.7960\n",
      "Epoch 22/150\n",
      "57500/57500 [==============================] - 2s 41us/step - loss: 0.4922 - acc: 0.8243 - val_loss: 0.5645 - val_acc: 0.7920\n",
      "Epoch 23/150\n",
      "57500/57500 [==============================] - 2s 41us/step - loss: 0.4868 - acc: 0.8253 - val_loss: 0.5599 - val_acc: 0.8030\n",
      "Epoch 24/150\n",
      "57500/57500 [==============================] - 2s 38us/step - loss: 0.4813 - acc: 0.8287 - val_loss: 0.5580 - val_acc: 0.8050\n",
      "Epoch 25/150\n",
      "57500/57500 [==============================] - 2s 38us/step - loss: 0.4767 - acc: 0.8309 - val_loss: 0.5587 - val_acc: 0.8030\n",
      "Epoch 26/150\n",
      "57500/57500 [==============================] - 2s 39us/step - loss: 0.4719 - acc: 0.8319 - val_loss: 0.5567 - val_acc: 0.8040\n",
      "Epoch 27/150\n",
      "57500/57500 [==============================] - 2s 39us/step - loss: 0.4675 - acc: 0.8334 - val_loss: 0.5554 - val_acc: 0.8100\n",
      "Epoch 28/150\n",
      "57500/57500 [==============================] - 2s 39us/step - loss: 0.4634 - acc: 0.8350 - val_loss: 0.5542 - val_acc: 0.8070\n",
      "Epoch 29/150\n",
      "57500/57500 [==============================] - 3s 45us/step - loss: 0.4592 - acc: 0.8365 - val_loss: 0.5505 - val_acc: 0.8070\n",
      "Epoch 30/150\n",
      "57500/57500 [==============================] - 3s 44us/step - loss: 0.4555 - acc: 0.8375 - val_loss: 0.5541 - val_acc: 0.8060\n",
      "Epoch 31/150\n",
      "57500/57500 [==============================] - 2s 40us/step - loss: 0.4521 - acc: 0.8394 - val_loss: 0.5513 - val_acc: 0.8130\n",
      "Epoch 32/150\n",
      "57500/57500 [==============================] - 2s 42us/step - loss: 0.4486 - acc: 0.8405 - val_loss: 0.5606 - val_acc: 0.8030\n",
      "Epoch 33/150\n",
      "57500/57500 [==============================] - 2s 43us/step - loss: 0.4453 - acc: 0.8415 - val_loss: 0.5489 - val_acc: 0.8090\n",
      "Epoch 34/150\n",
      "57500/57500 [==============================] - 2s 41us/step - loss: 0.4420 - acc: 0.8428 - val_loss: 0.5476 - val_acc: 0.8040\n",
      "Epoch 35/150\n",
      "57500/57500 [==============================] - 2s 40us/step - loss: 0.4390 - acc: 0.8450 - val_loss: 0.5555 - val_acc: 0.8020\n",
      "Epoch 36/150\n",
      "57500/57500 [==============================] - 2s 41us/step - loss: 0.4360 - acc: 0.8449 - val_loss: 0.5505 - val_acc: 0.8090\n",
      "Epoch 37/150\n",
      "57500/57500 [==============================] - 2s 39us/step - loss: 0.4330 - acc: 0.8463 - val_loss: 0.5481 - val_acc: 0.8090\n",
      "Epoch 38/150\n",
      "57500/57500 [==============================] - 2s 42us/step - loss: 0.4305 - acc: 0.8474 - val_loss: 0.5453 - val_acc: 0.8140\n",
      "Epoch 39/150\n",
      "57500/57500 [==============================] - 2s 40us/step - loss: 0.4279 - acc: 0.8485 - val_loss: 0.5482 - val_acc: 0.8070\n",
      "Epoch 40/150\n",
      "57500/57500 [==============================] - 2s 43us/step - loss: 0.4254 - acc: 0.8487 - val_loss: 0.5438 - val_acc: 0.8160\n",
      "Epoch 41/150\n",
      "57500/57500 [==============================] - 2s 38us/step - loss: 0.4226 - acc: 0.8503 - val_loss: 0.5451 - val_acc: 0.8070\n",
      "Epoch 42/150\n",
      "57500/57500 [==============================] - 3s 50us/step - loss: 0.4205 - acc: 0.8512 - val_loss: 0.5455 - val_acc: 0.8200\n",
      "Epoch 43/150\n",
      "57500/57500 [==============================] - 3s 48us/step - loss: 0.4182 - acc: 0.8527 - val_loss: 0.5479 - val_acc: 0.8150\n",
      "Epoch 44/150\n",
      "57500/57500 [==============================] - 3s 50us/step - loss: 0.4159 - acc: 0.8533 - val_loss: 0.5452 - val_acc: 0.8160\n",
      "Epoch 45/150\n",
      "57500/57500 [==============================] - 2s 40us/step - loss: 0.4135 - acc: 0.8541 - val_loss: 0.5480 - val_acc: 0.8170\n",
      "Epoch 46/150\n",
      "57500/57500 [==============================] - 2s 41us/step - loss: 0.4115 - acc: 0.8545 - val_loss: 0.5501 - val_acc: 0.8030\n",
      "Epoch 47/150\n",
      "57500/57500 [==============================] - 2s 43us/step - loss: 0.4095 - acc: 0.8549 - val_loss: 0.5446 - val_acc: 0.8140\n",
      "Epoch 48/150\n",
      "57500/57500 [==============================] - 2s 37us/step - loss: 0.4076 - acc: 0.8564 - val_loss: 0.5446 - val_acc: 0.8120\n",
      "Epoch 49/150\n",
      "57500/57500 [==============================] - 2s 37us/step - loss: 0.4056 - acc: 0.8568 - val_loss: 0.5495 - val_acc: 0.8110\n",
      "Epoch 50/150\n",
      "57500/57500 [==============================] - 2s 36us/step - loss: 0.4039 - acc: 0.8577 - val_loss: 0.5465 - val_acc: 0.8070\n",
      "Epoch 51/150\n",
      "57500/57500 [==============================] - 2s 36us/step - loss: 0.4018 - acc: 0.8587 - val_loss: 0.5517 - val_acc: 0.8050\n",
      "Epoch 52/150\n",
      "57500/57500 [==============================] - 2s 36us/step - loss: 0.4001 - acc: 0.8586 - val_loss: 0.5514 - val_acc: 0.8100\n",
      "Epoch 53/150\n",
      "57500/57500 [==============================] - 4s 62us/step - loss: 0.3982 - acc: 0.8594 - val_loss: 0.5502 - val_acc: 0.8140\n",
      "Epoch 54/150\n",
      "57500/57500 [==============================] - 3s 55us/step - loss: 0.3967 - acc: 0.8607 - val_loss: 0.5504 - val_acc: 0.8100\n",
      "Epoch 55/150\n",
      "57500/57500 [==============================] - 3s 58us/step - loss: 0.3947 - acc: 0.8605 - val_loss: 0.5523 - val_acc: 0.8120\n",
      "Epoch 56/150\n",
      "57500/57500 [==============================] - 3s 59us/step - loss: 0.3932 - acc: 0.8605 - val_loss: 0.5545 - val_acc: 0.8060\n",
      "Epoch 57/150\n",
      "57500/57500 [==============================] - 3s 53us/step - loss: 0.3915 - acc: 0.8620 - val_loss: 0.5551 - val_acc: 0.8080\n",
      "Epoch 58/150\n",
      "57500/57500 [==============================] - 4s 62us/step - loss: 0.3902 - acc: 0.8621 - val_loss: 0.5555 - val_acc: 0.8080\n",
      "Epoch 59/150\n",
      "57500/57500 [==============================] - 4s 75us/step - loss: 0.3885 - acc: 0.8627 - val_loss: 0.5534 - val_acc: 0.8150\n",
      "Epoch 60/150\n",
      "57500/57500 [==============================] - 5s 81us/step - loss: 0.3870 - acc: 0.8629 - val_loss: 0.5537 - val_acc: 0.8100\n",
      "Epoch 61/150\n",
      "57500/57500 [==============================] - 4s 67us/step - loss: 0.3854 - acc: 0.8641 - val_loss: 0.5538 - val_acc: 0.8100\n",
      "Epoch 62/150\n",
      "57500/57500 [==============================] - 4s 61us/step - loss: 0.3839 - acc: 0.8641 - val_loss: 0.5582 - val_acc: 0.8130\n",
      "Epoch 63/150\n",
      "57500/57500 [==============================] - 4s 64us/step - loss: 0.3822 - acc: 0.8644 - val_loss: 0.5571 - val_acc: 0.8120\n",
      "Epoch 64/150\n",
      "57500/57500 [==============================] - 4s 65us/step - loss: 0.3810 - acc: 0.8660 - val_loss: 0.5567 - val_acc: 0.8040\n",
      "Epoch 65/150\n",
      "57500/57500 [==============================] - 4s 78us/step - loss: 0.3798 - acc: 0.8658 - val_loss: 0.5561 - val_acc: 0.8090\n",
      "Epoch 66/150\n",
      "57500/57500 [==============================] - 5s 85us/step - loss: 0.3784 - acc: 0.8661 - val_loss: 0.5564 - val_acc: 0.8080\n",
      "Epoch 67/150\n",
      "57500/57500 [==============================] - 5s 85us/step - loss: 0.3772 - acc: 0.8668 - val_loss: 0.5571 - val_acc: 0.8020\n",
      "Epoch 68/150\n",
      "57500/57500 [==============================] - 3s 59us/step - loss: 0.3759 - acc: 0.8674 - val_loss: 0.5618 - val_acc: 0.8060\n",
      "Epoch 69/150\n",
      "57500/57500 [==============================] - 2s 40us/step - loss: 0.3745 - acc: 0.8681 - val_loss: 0.5616 - val_acc: 0.8110\n",
      "Epoch 70/150\n",
      "57500/57500 [==============================] - 2s 37us/step - loss: 0.3733 - acc: 0.8687 - val_loss: 0.5635 - val_acc: 0.8000\n",
      "Epoch 71/150\n",
      "57500/57500 [==============================] - 3s 52us/step - loss: 0.3722 - acc: 0.8689 - val_loss: 0.5612 - val_acc: 0.8040\n",
      "Epoch 72/150\n",
      "57500/57500 [==============================] - 3s 57us/step - loss: 0.3708 - acc: 0.8686 - val_loss: 0.5689 - val_acc: 0.8040\n",
      "Epoch 73/150\n",
      "57500/57500 [==============================] - 3s 44us/step - loss: 0.3696 - acc: 0.8694 - val_loss: 0.5628 - val_acc: 0.8040\n",
      "Epoch 74/150\n",
      "57500/57500 [==============================] - 2s 40us/step - loss: 0.3683 - acc: 0.8694 - val_loss: 0.5651 - val_acc: 0.8050\n",
      "Epoch 75/150\n",
      "57500/57500 [==============================] - 2s 39us/step - loss: 0.3671 - acc: 0.8717 - val_loss: 0.5691 - val_acc: 0.8070\n",
      "Epoch 76/150\n",
      "57500/57500 [==============================] - 2s 35us/step - loss: 0.3665 - acc: 0.8705 - val_loss: 0.5704 - val_acc: 0.8100\n",
      "Epoch 77/150\n",
      "57500/57500 [==============================] - 2s 32us/step - loss: 0.3648 - acc: 0.8709 - val_loss: 0.5684 - val_acc: 0.8090\n",
      "Epoch 78/150\n",
      "57500/57500 [==============================] - 2s 36us/step - loss: 0.3637 - acc: 0.8717 - val_loss: 0.5664 - val_acc: 0.8030\n",
      "Epoch 79/150\n",
      "57500/57500 [==============================] - 2s 39us/step - loss: 0.3627 - acc: 0.8725 - val_loss: 0.5754 - val_acc: 0.8020\n",
      "Epoch 80/150\n",
      "57500/57500 [==============================] - 2s 41us/step - loss: 0.3616 - acc: 0.8721 - val_loss: 0.5697 - val_acc: 0.7990\n",
      "Epoch 81/150\n",
      "57500/57500 [==============================] - 2s 41us/step - loss: 0.3605 - acc: 0.8725 - val_loss: 0.5744 - val_acc: 0.8110\n",
      "Epoch 82/150\n",
      "57500/57500 [==============================] - 2s 36us/step - loss: 0.3593 - acc: 0.8737 - val_loss: 0.5690 - val_acc: 0.8050\n",
      "Epoch 83/150\n",
      "57500/57500 [==============================] - 2s 38us/step - loss: 0.3585 - acc: 0.8730 - val_loss: 0.5770 - val_acc: 0.8020\n",
      "Epoch 84/150\n",
      "57500/57500 [==============================] - 3s 45us/step - loss: 0.3573 - acc: 0.8737 - val_loss: 0.5728 - val_acc: 0.8040\n",
      "Epoch 85/150\n",
      "57500/57500 [==============================] - 2s 33us/step - loss: 0.3560 - acc: 0.8750 - val_loss: 0.5749 - val_acc: 0.8050\n",
      "Epoch 86/150\n",
      "57500/57500 [==============================] - 2s 35us/step - loss: 0.3555 - acc: 0.8738 - val_loss: 0.5806 - val_acc: 0.8040\n",
      "Epoch 87/150\n",
      "57500/57500 [==============================] - 2s 32us/step - loss: 0.3543 - acc: 0.8758 - val_loss: 0.5795 - val_acc: 0.8050\n",
      "Epoch 88/150\n",
      "57500/57500 [==============================] - 2s 31us/step - loss: 0.3534 - acc: 0.8756 - val_loss: 0.5774 - val_acc: 0.8010\n",
      "Epoch 89/150\n",
      "57500/57500 [==============================] - 2s 31us/step - loss: 0.3525 - acc: 0.8764 - val_loss: 0.5736 - val_acc: 0.8030\n",
      "Epoch 90/150\n",
      "57500/57500 [==============================] - 2s 39us/step - loss: 0.3512 - acc: 0.8765 - val_loss: 0.5798 - val_acc: 0.8030\n",
      "Epoch 91/150\n",
      "57500/57500 [==============================] - 3s 52us/step - loss: 0.3508 - acc: 0.8769 - val_loss: 0.5833 - val_acc: 0.8000\n",
      "Epoch 92/150\n",
      "57500/57500 [==============================] - 4s 63us/step - loss: 0.3496 - acc: 0.8763 - val_loss: 0.5788 - val_acc: 0.7990\n",
      "Epoch 93/150\n",
      "57500/57500 [==============================] - 2s 31us/step - loss: 0.3485 - acc: 0.8776 - val_loss: 0.5792 - val_acc: 0.7990\n",
      "Epoch 94/150\n",
      "57500/57500 [==============================] - 2s 32us/step - loss: 0.3474 - acc: 0.8773 - val_loss: 0.5822 - val_acc: 0.7980\n",
      "Epoch 95/150\n",
      "57500/57500 [==============================] - 2s 34us/step - loss: 0.3464 - acc: 0.8776 - val_loss: 0.5847 - val_acc: 0.8040\n",
      "Epoch 96/150\n",
      "57500/57500 [==============================] - 2s 35us/step - loss: 0.3455 - acc: 0.8784 - val_loss: 0.5890 - val_acc: 0.8030\n",
      "Epoch 97/150\n",
      "57500/57500 [==============================] - 2s 35us/step - loss: 0.3448 - acc: 0.8786 - val_loss: 0.5877 - val_acc: 0.8020\n",
      "Epoch 98/150\n",
      "57500/57500 [==============================] - 2s 31us/step - loss: 0.3438 - acc: 0.8785 - val_loss: 0.5864 - val_acc: 0.8070\n",
      "Epoch 99/150\n",
      "57500/57500 [==============================] - 2s 37us/step - loss: 0.3430 - acc: 0.8790 - val_loss: 0.5931 - val_acc: 0.8010\n",
      "Epoch 100/150\n",
      "57500/57500 [==============================] - 2s 32us/step - loss: 0.3421 - acc: 0.8792 - val_loss: 0.5858 - val_acc: 0.8010\n",
      "Epoch 101/150\n",
      "57500/57500 [==============================] - 2s 31us/step - loss: 0.3410 - acc: 0.8797 - val_loss: 0.5903 - val_acc: 0.8020\n",
      "Epoch 102/150\n",
      "57500/57500 [==============================] - 2s 32us/step - loss: 0.3404 - acc: 0.8802 - val_loss: 0.5934 - val_acc: 0.8040\n",
      "Epoch 103/150\n",
      "57500/57500 [==============================] - 2s 35us/step - loss: 0.3397 - acc: 0.8802 - val_loss: 0.5953 - val_acc: 0.7970\n",
      "Epoch 104/150\n",
      "57500/57500 [==============================] - 2s 43us/step - loss: 0.3385 - acc: 0.8805 - val_loss: 0.5901 - val_acc: 0.7970\n",
      "Epoch 105/150\n",
      "57500/57500 [==============================] - 3s 44us/step - loss: 0.3379 - acc: 0.8813 - val_loss: 0.5946 - val_acc: 0.8040\n",
      "Epoch 106/150\n",
      "57500/57500 [==============================] - 3s 48us/step - loss: 0.3370 - acc: 0.8813 - val_loss: 0.6028 - val_acc: 0.8010\n",
      "Epoch 107/150\n",
      "57500/57500 [==============================] - 2s 42us/step - loss: 0.3360 - acc: 0.8819 - val_loss: 0.6048 - val_acc: 0.8040\n",
      "Epoch 108/150\n",
      "57500/57500 [==============================] - 3s 44us/step - loss: 0.3348 - acc: 0.8821 - val_loss: 0.6095 - val_acc: 0.7990\n",
      "Epoch 109/150\n",
      "57500/57500 [==============================] - 2s 36us/step - loss: 0.3339 - acc: 0.8833 - val_loss: 0.5986 - val_acc: 0.8010\n",
      "Epoch 110/150\n",
      "57500/57500 [==============================] - 3s 47us/step - loss: 0.3332 - acc: 0.8824 - val_loss: 0.6032 - val_acc: 0.8010\n",
      "Epoch 111/150\n",
      "57500/57500 [==============================] - 3s 49us/step - loss: 0.3324 - acc: 0.8832 - val_loss: 0.6065 - val_acc: 0.7980\n",
      "Epoch 112/150\n",
      "57500/57500 [==============================] - 3s 60us/step - loss: 0.3314 - acc: 0.8834 - val_loss: 0.6037 - val_acc: 0.7940\n",
      "Epoch 113/150\n",
      "57500/57500 [==============================] - 2s 40us/step - loss: 0.3305 - acc: 0.8839 - val_loss: 0.6062 - val_acc: 0.8010\n",
      "Epoch 114/150\n",
      "57500/57500 [==============================] - 2s 43us/step - loss: 0.3297 - acc: 0.8840 - val_loss: 0.6009 - val_acc: 0.7950\n",
      "Epoch 115/150\n",
      "57500/57500 [==============================] - 2s 37us/step - loss: 0.3288 - acc: 0.8842 - val_loss: 0.6039 - val_acc: 0.8040\n",
      "Epoch 116/150\n",
      "57500/57500 [==============================] - 2s 40us/step - loss: 0.3280 - acc: 0.8845 - val_loss: 0.6021 - val_acc: 0.7950\n",
      "Epoch 117/150\n",
      "57500/57500 [==============================] - 2s 38us/step - loss: 0.3274 - acc: 0.8847 - val_loss: 0.6042 - val_acc: 0.8010\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 118/150\n",
      "57500/57500 [==============================] - 2s 37us/step - loss: 0.3264 - acc: 0.8847 - val_loss: 0.6097 - val_acc: 0.7980\n",
      "Epoch 119/150\n",
      "57500/57500 [==============================] - 2s 37us/step - loss: 0.3258 - acc: 0.8855 - val_loss: 0.6169 - val_acc: 0.7950\n",
      "Epoch 120/150\n",
      "57500/57500 [==============================] - 2s 36us/step - loss: 0.3249 - acc: 0.8863 - val_loss: 0.6109 - val_acc: 0.8010\n",
      "Epoch 121/150\n",
      "57500/57500 [==============================] - 2s 36us/step - loss: 0.3239 - acc: 0.8861 - val_loss: 0.6131 - val_acc: 0.7950\n",
      "Epoch 122/150\n",
      "57500/57500 [==============================] - 2s 37us/step - loss: 0.3230 - acc: 0.8860 - val_loss: 0.6090 - val_acc: 0.7880\n",
      "Epoch 123/150\n",
      "57500/57500 [==============================] - 2s 39us/step - loss: 0.3223 - acc: 0.8866 - val_loss: 0.6204 - val_acc: 0.7930\n",
      "Epoch 124/150\n",
      "57500/57500 [==============================] - 2s 38us/step - loss: 0.3213 - acc: 0.8880 - val_loss: 0.6231 - val_acc: 0.7920\n",
      "Epoch 125/150\n",
      "57500/57500 [==============================] - 2s 37us/step - loss: 0.3206 - acc: 0.8875 - val_loss: 0.6187 - val_acc: 0.7970\n",
      "Epoch 126/150\n",
      "57500/57500 [==============================] - 2s 36us/step - loss: 0.3197 - acc: 0.8875 - val_loss: 0.6204 - val_acc: 0.7920\n",
      "Epoch 127/150\n",
      "57500/57500 [==============================] - 2s 38us/step - loss: 0.3189 - acc: 0.8880 - val_loss: 0.6161 - val_acc: 0.7950\n",
      "Epoch 128/150\n",
      "57500/57500 [==============================] - 2s 36us/step - loss: 0.3184 - acc: 0.8878 - val_loss: 0.6145 - val_acc: 0.7950\n",
      "Epoch 129/150\n",
      "57500/57500 [==============================] - 2s 35us/step - loss: 0.3173 - acc: 0.8884 - val_loss: 0.6215 - val_acc: 0.7940\n",
      "Epoch 130/150\n",
      "57500/57500 [==============================] - 2s 37us/step - loss: 0.3165 - acc: 0.8888 - val_loss: 0.6247 - val_acc: 0.7990\n",
      "Epoch 131/150\n",
      "57500/57500 [==============================] - 2s 38us/step - loss: 0.3154 - acc: 0.8894 - val_loss: 0.6187 - val_acc: 0.7940\n",
      "Epoch 132/150\n",
      "57500/57500 [==============================] - 2s 37us/step - loss: 0.3148 - acc: 0.8889 - val_loss: 0.6203 - val_acc: 0.7910\n",
      "Epoch 133/150\n",
      "57500/57500 [==============================] - 2s 36us/step - loss: 0.3139 - acc: 0.8899 - val_loss: 0.6277 - val_acc: 0.7920\n",
      "Epoch 134/150\n",
      "57500/57500 [==============================] - 2s 38us/step - loss: 0.3130 - acc: 0.8900 - val_loss: 0.6251 - val_acc: 0.7950\n",
      "Epoch 135/150\n",
      "57500/57500 [==============================] - 2s 38us/step - loss: 0.3121 - acc: 0.8905 - val_loss: 0.6401 - val_acc: 0.7940\n",
      "Epoch 136/150\n",
      "57500/57500 [==============================] - 2s 37us/step - loss: 0.3110 - acc: 0.8910 - val_loss: 0.6359 - val_acc: 0.7960\n",
      "Epoch 137/150\n",
      "57500/57500 [==============================] - 2s 37us/step - loss: 0.3101 - acc: 0.8913 - val_loss: 0.6243 - val_acc: 0.7930\n",
      "Epoch 138/150\n",
      "57500/57500 [==============================] - 2s 37us/step - loss: 0.3095 - acc: 0.8913 - val_loss: 0.6251 - val_acc: 0.7940\n",
      "Epoch 139/150\n",
      "57500/57500 [==============================] - 2s 37us/step - loss: 0.3092 - acc: 0.8922 - val_loss: 0.6257 - val_acc: 0.7890\n",
      "Epoch 140/150\n",
      "57500/57500 [==============================] - 2s 37us/step - loss: 0.3077 - acc: 0.8919 - val_loss: 0.6330 - val_acc: 0.7910\n",
      "Epoch 141/150\n",
      "57500/57500 [==============================] - 2s 37us/step - loss: 0.3070 - acc: 0.8934 - val_loss: 0.6305 - val_acc: 0.7920\n",
      "Epoch 142/150\n",
      "57500/57500 [==============================] - 2s 39us/step - loss: 0.3063 - acc: 0.8929 - val_loss: 0.6376 - val_acc: 0.7920\n",
      "Epoch 143/150\n",
      "57500/57500 [==============================] - 2s 37us/step - loss: 0.3052 - acc: 0.8935 - val_loss: 0.6338 - val_acc: 0.7980\n",
      "Epoch 144/150\n",
      "57500/57500 [==============================] - 2s 38us/step - loss: 0.3047 - acc: 0.8936 - val_loss: 0.6360 - val_acc: 0.7990\n",
      "Epoch 145/150\n",
      "57500/57500 [==============================] - 2s 38us/step - loss: 0.3037 - acc: 0.8940 - val_loss: 0.6405 - val_acc: 0.7980\n",
      "Epoch 146/150\n",
      "57500/57500 [==============================] - 2s 39us/step - loss: 0.3026 - acc: 0.8946 - val_loss: 0.6382 - val_acc: 0.7900\n",
      "Epoch 147/150\n",
      "57500/57500 [==============================] - 2s 36us/step - loss: 0.3016 - acc: 0.8950 - val_loss: 0.6367 - val_acc: 0.7900\n",
      "Epoch 148/150\n",
      "57500/57500 [==============================] - 2s 37us/step - loss: 0.3008 - acc: 0.8952 - val_loss: 0.6364 - val_acc: 0.7900\n",
      "Epoch 149/150\n",
      "57500/57500 [==============================] - 2s 36us/step - loss: 0.3001 - acc: 0.8956 - val_loss: 0.6385 - val_acc: 0.7880\n",
      "Epoch 150/150\n",
      "57500/57500 [==============================] - 2s 40us/step - loss: 0.2990 - acc: 0.8961 - val_loss: 0.6425 - val_acc: 0.7920\n"
     ]
    }
   ],
   "source": [
    "# Train the model\n",
    "baseline_model_val = baseline_model.fit(X_train_tokens,\n",
    "                                        y_train_lb,\n",
    "                                        epochs=150,\n",
    "                                        batch_size=256,\n",
    "                                        validation_data=(X_val_tokens, y_val_lb))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Model Performance\n",
    "\n",
    "The attribute `.history` (stored as a dictionary) contains four entries now: one per metric that was being monitored during training and validation. Print the keys of this dictionary for confirmation: "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "dict_keys(['val_loss', 'val_acc', 'loss', 'acc'])\n"
     ]
    }
   ],
   "source": [
    "# Access the history attribute and store the dictionary\n",
    "baseline_model_val_dict = baseline_model_val.history\n",
    "\n",
    "# Print the keys\n",
    "print(baseline_model_val_dict.keys())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Evaluate this model on the training data: "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "57500/57500 [==============================] - 4s 62us/step\n",
      "----------\n",
      "Training Loss: 0.291 \n",
      "Training Accuracy: 0.901\n"
     ]
    }
   ],
   "source": [
    "results_train = baseline_model.evaluate(X_train_tokens, y_train_lb)\n",
    "print('----------')\n",
    "print(f'Training Loss: {results_train[0]:.3} \\nTraining Accuracy: {results_train[1]:.3}')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Evaluate this model on the test data: "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1500/1500 [==============================] - 0s 150us/step\n",
      "----------\n",
      "Test Loss: 0.608 \n",
      "Test Accuracy: 0.787\n"
     ]
    }
   ],
   "source": [
    "results_test = baseline_model.evaluate(X_test_tokens, y_test_lb)\n",
    "print('----------')\n",
    "print(f'Test Loss: {results_test[0]:.3} \\nTest Accuracy: {results_test[1]:.3}')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Plot the Results \n",
    "\n",
    "Plot the loss versus the number of epochs. Be sure to include the training and the validation loss in the same plot. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "def visualize_training_results(results):\n",
    "    history = results.history\n",
    "    plt.figure()\n",
    "    plt.plot(history['val_loss'])\n",
    "    plt.plot(history['loss'])\n",
    "    plt.legend(['val_loss', 'loss'])\n",
    "    plt.title('Loss')\n",
    "    plt.xlabel('Epochs')\n",
    "    plt.ylabel('Loss')\n",
    "    plt.show()\n",
    "    \n",
    "    plt.figure()\n",
    "    plt.plot(history['val_acc'])\n",
    "    plt.plot(history['acc'])\n",
    "    plt.legend(['val_acc', 'acc'])\n",
    "    plt.title('Accuracy')\n",
    "    plt.xlabel('Epochs')\n",
    "    plt.ylabel('Accuracy')\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Create a second plot comparing training and validation accuracy to the number of epochs. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "visualize_training_results(baseline_model_val)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Did you notice an interesting pattern here? Although the training accuracy keeps increasing when going through more epochs, and the training loss keeps decreasing, the validation accuracy and loss don't necessarily do the same. After a certain point, validation accuracy keeps swinging, which means that you're probably **overfitting** the model to the training data when you train for many epochs past a certain dropoff point. Let's tackle this now. You will now specify an early stopping point when training your model. \n",
    "\n",
    "\n",
    "## Early Stopping\n",
    "\n",
    "Overfitting neural networks is something you **_want_** to avoid at all costs. However, it's not possible to know in advance how many *epochs* you need to train your model on, and running the model multiple times with varying number of *epochs* maybe helpful, but is a time-consuming process. \n",
    "\n",
    "We've defined a model with the same architecture as above. This time specify an early stopping point when training the model. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "random.seed(123)\n",
    "model_2 = models.Sequential()\n",
    "model_2.add(layers.Dense(50, activation='relu', input_shape=(2000,)))\n",
    "model_2.add(layers.Dense(25, activation='relu'))\n",
    "model_2.add(layers.Dense(7, activation='softmax'))\n",
    "\n",
    "model_2.compile(optimizer='SGD', \n",
    "                loss='categorical_crossentropy', \n",
    "                metrics=['accuracy'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- Import `EarlyStopping` and `ModelCheckpoint` from `keras.callbacks` \n",
    "- Define a list, `early_stopping`: \n",
    "  - Monitor `'val_loss'` and continue training for 10 epochs before stopping \n",
    "  - Save the best model while monitoring `'val_loss'` \n",
    " \n",
    "> If you need help, consult [documentation](https://keras.io/callbacks/).   "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Import EarlyStopping and ModelCheckpoint\n",
    "from keras.callbacks import EarlyStopping, ModelCheckpoint\n",
    "\n",
    "checkpoint_filepath = 'best_model.h5'\n",
    "\n",
    "\n",
    "callbacks=[EarlyStopping(monitor='val_loss', patience=10),\n",
    "           ModelCheckpoint(filepath='best_model.h5', monitor='val_loss', save_best_only=True)]\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Train `model_2`. Make sure you set the `callbacks` argument to `early_stopping`. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 57500 samples, validate on 1000 samples\n",
      "Epoch 1/150\n",
      "57500/57500 [==============================] - 2s 37us/step - loss: 0.3729 - acc: 0.8683 - val_loss: 0.5752 - val_acc: 0.7910\n",
      "Epoch 2/150\n",
      "57500/57500 [==============================] - 2s 38us/step - loss: 0.3716 - acc: 0.8687 - val_loss: 0.5767 - val_acc: 0.7940\n",
      "Epoch 3/150\n",
      "57500/57500 [==============================] - 3s 48us/step - loss: 0.3705 - acc: 0.8687 - val_loss: 0.5762 - val_acc: 0.7920\n",
      "Epoch 4/150\n",
      "57500/57500 [==============================] - 3s 49us/step - loss: 0.3692 - acc: 0.8683 - val_loss: 0.5794 - val_acc: 0.7910\n",
      "Epoch 5/150\n",
      "57500/57500 [==============================] - 2s 39us/step - loss: 0.3682 - acc: 0.8701 - val_loss: 0.5835 - val_acc: 0.7940\n",
      "Epoch 6/150\n",
      "57500/57500 [==============================] - 2s 41us/step - loss: 0.3669 - acc: 0.8700 - val_loss: 0.5820 - val_acc: 0.7980\n",
      "Epoch 7/150\n",
      "57500/57500 [==============================] - 2s 32us/step - loss: 0.3660 - acc: 0.8708 - val_loss: 0.5763 - val_acc: 0.7990\n",
      "Epoch 8/150\n",
      "57500/57500 [==============================] - 2s 32us/step - loss: 0.3648 - acc: 0.8713 - val_loss: 0.5822 - val_acc: 0.7990\n",
      "Epoch 9/150\n",
      "57500/57500 [==============================] - 2s 40us/step - loss: 0.3633 - acc: 0.8715 - val_loss: 0.5923 - val_acc: 0.7960\n",
      "Epoch 10/150\n",
      "57500/57500 [==============================] - 2s 39us/step - loss: 0.3624 - acc: 0.8723 - val_loss: 0.5798 - val_acc: 0.7970\n",
      "Epoch 11/150\n",
      "57500/57500 [==============================] - 3s 52us/step - loss: 0.3610 - acc: 0.8721 - val_loss: 0.5815 - val_acc: 0.7950\n"
     ]
    }
   ],
   "source": [
    "model_2_val = model_2.fit(X_train_tokens,\n",
    "                          y_train_lb,\n",
    "                          epochs=150,\n",
    "                          batch_size=256,\n",
    "                          callbacks=callbacks,\n",
    "                          validation_data=(X_val_tokens, y_val_lb))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Load the best (saved) model. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load the best (saved) model\n",
    "from keras.models import load_model\n",
    "saved_model = load_model('best_model.h5')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now, use this model to to calculate the training and test accuracy: "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "57500/57500 [==============================] - 3s 60us/step\n",
      "Training Loss: 0.383 \n",
      "Training Accuracy: 0.865\n",
      "----------\n",
      "1500/1500 [==============================] - 0s 96us/step\n",
      "Test Loss: 0.545 \n",
      "Test Accuracy: 0.791\n"
     ]
    }
   ],
   "source": [
    "results_train = saved_model.evaluate(X_train_tokens, y_train_lb)\n",
    "print(f'Training Loss: {results_train[0]:.3} \\nTraining Accuracy: {results_train[1]:.3}')\n",
    "\n",
    "print('----------')\n",
    "\n",
    "results_test = saved_model.evaluate(X_test_tokens, y_test_lb)\n",
    "print(f'Test Loss: {results_test[0]:.3} \\nTest Accuracy: {results_test[1]:.3}')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Nicely done! Did you notice that the model didn't train for all 150 epochs? You reduced your training time. \n",
    "\n",
    "Now, take a look at how regularization techniques can further improve your model performance. \n",
    "\n",
    "## L2 Regularization \n",
    "\n",
    "First, take a look at L2 regularization. Keras makes L2 regularization easy. Simply add the `kernel_regularizer=keras.regularizers.l2(lambda_coeff)` parameter to any model layer. The `lambda_coeff` parameter determines the strength of the regularization you wish to perform. \n",
    "\n",
    "- Use 2 hidden layers with 50 units in the first and 25 in the second layer, both with `'relu'` activation functions \n",
    "- Add L2 regularization to both the hidden layers with 0.005 as the `lambda_coeff` "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 57500 samples, validate on 1000 samples\n",
      "Epoch 1/150\n",
      "57500/57500 [==============================] - 3s 54us/step - loss: 2.5399 - acc: 0.2254 - val_loss: 2.4362 - val_acc: 0.3060\n",
      "Epoch 2/150\n",
      "57500/57500 [==============================] - 2s 43us/step - loss: 2.2605 - acc: 0.3940 - val_loss: 2.0869 - val_acc: 0.4720\n",
      "Epoch 3/150\n",
      "57500/57500 [==============================] - 3s 49us/step - loss: 1.9161 - acc: 0.5634 - val_loss: 1.7803 - val_acc: 0.6250\n",
      "Epoch 4/150\n",
      "57500/57500 [==============================] - 2s 40us/step - loss: 1.6610 - acc: 0.6585 - val_loss: 1.5718 - val_acc: 0.6780\n",
      "Epoch 5/150\n",
      "57500/57500 [==============================] - 2s 40us/step - loss: 1.4942 - acc: 0.7020 - val_loss: 1.4511 - val_acc: 0.7050\n",
      "Epoch 6/150\n",
      "57500/57500 [==============================] - 3s 51us/step - loss: 1.3844 - acc: 0.7266 - val_loss: 1.3603 - val_acc: 0.7270\n",
      "Epoch 7/150\n",
      "57500/57500 [==============================] - 3s 55us/step - loss: 1.3065 - acc: 0.7449 - val_loss: 1.2944 - val_acc: 0.7350\n",
      "Epoch 8/150\n",
      "57500/57500 [==============================] - 2s 40us/step - loss: 1.2471 - acc: 0.7575 - val_loss: 1.2504 - val_acc: 0.7420\n",
      "Epoch 9/150\n",
      "57500/57500 [==============================] - 2s 37us/step - loss: 1.1988 - acc: 0.7668 - val_loss: 1.2087 - val_acc: 0.7530\n",
      "Epoch 10/150\n",
      "57500/57500 [==============================] - 2s 43us/step - loss: 1.1582 - acc: 0.7749 - val_loss: 1.1763 - val_acc: 0.7510\n",
      "Epoch 11/150\n",
      "57500/57500 [==============================] - 2s 41us/step - loss: 1.1227 - acc: 0.7826 - val_loss: 1.1410 - val_acc: 0.7640\n",
      "Epoch 12/150\n",
      "57500/57500 [==============================] - 2s 42us/step - loss: 1.0911 - acc: 0.7885 - val_loss: 1.1159 - val_acc: 0.7600\n",
      "Epoch 13/150\n",
      "57500/57500 [==============================] - 2s 42us/step - loss: 1.0623 - acc: 0.7942 - val_loss: 1.0964 - val_acc: 0.7660\n",
      "Epoch 14/150\n",
      "57500/57500 [==============================] - 3s 54us/step - loss: 1.0362 - acc: 0.7979 - val_loss: 1.0695 - val_acc: 0.7790\n",
      "Epoch 15/150\n",
      "57500/57500 [==============================] - 3s 48us/step - loss: 1.0120 - acc: 0.8023 - val_loss: 1.0460 - val_acc: 0.7790\n",
      "Epoch 16/150\n",
      "57500/57500 [==============================] - 3s 58us/step - loss: 0.9894 - acc: 0.8059 - val_loss: 1.0277 - val_acc: 0.7750\n",
      "Epoch 17/150\n",
      "57500/57500 [==============================] - 3s 46us/step - loss: 0.9683 - acc: 0.8088 - val_loss: 1.0144 - val_acc: 0.7790\n",
      "Epoch 18/150\n",
      "57500/57500 [==============================] - 2s 39us/step - loss: 0.9487 - acc: 0.8118 - val_loss: 0.9952 - val_acc: 0.7800\n",
      "Epoch 19/150\n",
      "57500/57500 [==============================] - 2s 37us/step - loss: 0.9302 - acc: 0.8148 - val_loss: 0.9775 - val_acc: 0.7890\n",
      "Epoch 20/150\n",
      "57500/57500 [==============================] - 2s 37us/step - loss: 0.9128 - acc: 0.8178 - val_loss: 0.9647 - val_acc: 0.7900\n",
      "Epoch 21/150\n",
      "57500/57500 [==============================] - 2s 37us/step - loss: 0.8967 - acc: 0.8195 - val_loss: 0.9524 - val_acc: 0.7900\n",
      "Epoch 22/150\n",
      "57500/57500 [==============================] - 2s 39us/step - loss: 0.8813 - acc: 0.8215 - val_loss: 0.9372 - val_acc: 0.7920\n",
      "Epoch 23/150\n",
      "57500/57500 [==============================] - 2s 38us/step - loss: 0.8668 - acc: 0.8234 - val_loss: 0.9272 - val_acc: 0.7970\n",
      "Epoch 24/150\n",
      "57500/57500 [==============================] - 2s 40us/step - loss: 0.8527 - acc: 0.8247 - val_loss: 0.9146 - val_acc: 0.7940\n",
      "Epoch 25/150\n",
      "57500/57500 [==============================] - 2s 38us/step - loss: 0.8397 - acc: 0.8270 - val_loss: 0.9025 - val_acc: 0.7970\n",
      "Epoch 26/150\n",
      "57500/57500 [==============================] - 2s 37us/step - loss: 0.8272 - acc: 0.8281 - val_loss: 0.8918 - val_acc: 0.7990\n",
      "Epoch 27/150\n",
      "57500/57500 [==============================] - 2s 37us/step - loss: 0.8153 - acc: 0.8303 - val_loss: 0.8808 - val_acc: 0.8000\n",
      "Epoch 28/150\n",
      "57500/57500 [==============================] - 2s 39us/step - loss: 0.8041 - acc: 0.8317 - val_loss: 0.8697 - val_acc: 0.8020\n",
      "Epoch 29/150\n",
      "57500/57500 [==============================] - 2s 39us/step - loss: 0.7932 - acc: 0.8333 - val_loss: 0.8712 - val_acc: 0.8000\n",
      "Epoch 30/150\n",
      "57500/57500 [==============================] - 2s 37us/step - loss: 0.7831 - acc: 0.8339 - val_loss: 0.8552 - val_acc: 0.8050\n",
      "Epoch 31/150\n",
      "57500/57500 [==============================] - 2s 36us/step - loss: 0.7734 - acc: 0.8353 - val_loss: 0.8493 - val_acc: 0.8030\n",
      "Epoch 32/150\n",
      "57500/57500 [==============================] - 2s 39us/step - loss: 0.7641 - acc: 0.8362 - val_loss: 0.8395 - val_acc: 0.8050\n",
      "Epoch 33/150\n",
      "57500/57500 [==============================] - 2s 38us/step - loss: 0.7553 - acc: 0.8372 - val_loss: 0.8293 - val_acc: 0.8060\n",
      "Epoch 34/150\n",
      "57500/57500 [==============================] - 2s 39us/step - loss: 0.7467 - acc: 0.8384 - val_loss: 0.8239 - val_acc: 0.8070\n",
      "Epoch 35/150\n",
      "57500/57500 [==============================] - 2s 38us/step - loss: 0.7386 - acc: 0.8384 - val_loss: 0.8166 - val_acc: 0.8110\n",
      "Epoch 36/150\n",
      "57500/57500 [==============================] - 3s 48us/step - loss: 0.7309 - acc: 0.8403 - val_loss: 0.8164 - val_acc: 0.8070\n",
      "Epoch 37/150\n",
      "57500/57500 [==============================] - 3s 53us/step - loss: 0.7234 - acc: 0.8409 - val_loss: 0.8083 - val_acc: 0.8050\n",
      "Epoch 38/150\n",
      "57500/57500 [==============================] - 4s 67us/step - loss: 0.7163 - acc: 0.8406 - val_loss: 0.7974 - val_acc: 0.8080\n",
      "Epoch 39/150\n",
      "57500/57500 [==============================] - 4s 76us/step - loss: 0.7097 - acc: 0.8424 - val_loss: 0.7934 - val_acc: 0.8030\n",
      "Epoch 40/150\n",
      "57500/57500 [==============================] - 3s 45us/step - loss: 0.7031 - acc: 0.8441 - val_loss: 0.7916 - val_acc: 0.8090\n",
      "Epoch 41/150\n",
      "57500/57500 [==============================] - 3s 57us/step - loss: 0.6972 - acc: 0.8439 - val_loss: 0.7841 - val_acc: 0.8060\n",
      "Epoch 42/150\n",
      "57500/57500 [==============================] - 2s 33us/step - loss: 0.6911 - acc: 0.8443 - val_loss: 0.7793 - val_acc: 0.8080\n",
      "Epoch 43/150\n",
      "57500/57500 [==============================] - 2s 34us/step - loss: 0.6855 - acc: 0.8449 - val_loss: 0.7732 - val_acc: 0.8120\n",
      "Epoch 44/150\n",
      "57500/57500 [==============================] - 2s 32us/step - loss: 0.6800 - acc: 0.8448 - val_loss: 0.7702 - val_acc: 0.8100\n",
      "Epoch 45/150\n",
      "57500/57500 [==============================] - 3s 59us/step - loss: 0.6747 - acc: 0.8454 - val_loss: 0.7676 - val_acc: 0.8080\n",
      "Epoch 46/150\n",
      "57500/57500 [==============================] - 2s 32us/step - loss: 0.6697 - acc: 0.8465 - val_loss: 0.7629 - val_acc: 0.8060\n",
      "Epoch 47/150\n",
      "57500/57500 [==============================] - 2s 31us/step - loss: 0.6648 - acc: 0.8473 - val_loss: 0.7581 - val_acc: 0.8120\n",
      "Epoch 48/150\n",
      "57500/57500 [==============================] - 2s 37us/step - loss: 0.6600 - acc: 0.8475 - val_loss: 0.7547 - val_acc: 0.8040\n",
      "Epoch 49/150\n",
      "57500/57500 [==============================] - 3s 45us/step - loss: 0.6557 - acc: 0.8482 - val_loss: 0.7499 - val_acc: 0.8050\n",
      "Epoch 50/150\n",
      "57500/57500 [==============================] - 3s 50us/step - loss: 0.6514 - acc: 0.8493 - val_loss: 0.7491 - val_acc: 0.8090\n",
      "Epoch 51/150\n",
      "57500/57500 [==============================] - 4s 62us/step - loss: 0.6473 - acc: 0.8498 - val_loss: 0.7413 - val_acc: 0.8160\n",
      "Epoch 52/150\n",
      "57500/57500 [==============================] - 2s 43us/step - loss: 0.6434 - acc: 0.8502 - val_loss: 0.7410 - val_acc: 0.8010\n",
      "Epoch 53/150\n",
      "57500/57500 [==============================] - 4s 67us/step - loss: 0.6396 - acc: 0.8502 - val_loss: 0.7401 - val_acc: 0.8130\n",
      "Epoch 54/150\n",
      "57500/57500 [==============================] - 3s 49us/step - loss: 0.6362 - acc: 0.8505 - val_loss: 0.7356 - val_acc: 0.7990\n",
      "Epoch 55/150\n",
      "57500/57500 [==============================] - 2s 43us/step - loss: 0.6326 - acc: 0.8507 - val_loss: 0.7327 - val_acc: 0.8090\n",
      "Epoch 56/150\n",
      "57500/57500 [==============================] - 2s 35us/step - loss: 0.6293 - acc: 0.8512 - val_loss: 0.7302 - val_acc: 0.8110\n",
      "Epoch 57/150\n",
      "57500/57500 [==============================] - 2s 35us/step - loss: 0.6257 - acc: 0.8513 - val_loss: 0.7315 - val_acc: 0.8110\n",
      "Epoch 58/150\n",
      "57500/57500 [==============================] - 2s 39us/step - loss: 0.6228 - acc: 0.8516 - val_loss: 0.7239 - val_acc: 0.8120\n",
      "Epoch 59/150\n",
      "57500/57500 [==============================] - 2s 40us/step - loss: 0.6199 - acc: 0.8515 - val_loss: 0.7262 - val_acc: 0.8060\n",
      "Epoch 60/150\n",
      "57500/57500 [==============================] - 2s 38us/step - loss: 0.6168 - acc: 0.8521 - val_loss: 0.7239 - val_acc: 0.8100\n",
      "Epoch 61/150\n",
      "57500/57500 [==============================] - 2s 31us/step - loss: 0.6140 - acc: 0.8531 - val_loss: 0.7199 - val_acc: 0.8110\n",
      "Epoch 62/150\n",
      "57500/57500 [==============================] - 2s 41us/step - loss: 0.6114 - acc: 0.8528 - val_loss: 0.7203 - val_acc: 0.8060\n",
      "Epoch 63/150\n",
      "57500/57500 [==============================] - 2s 38us/step - loss: 0.6087 - acc: 0.8526 - val_loss: 0.7208 - val_acc: 0.8090\n",
      "Epoch 64/150\n",
      "57500/57500 [==============================] - 2s 32us/step - loss: 0.6061 - acc: 0.8532 - val_loss: 0.7198 - val_acc: 0.8120\n",
      "Epoch 65/150\n",
      "57500/57500 [==============================] - 2s 33us/step - loss: 0.6037 - acc: 0.8530 - val_loss: 0.7121 - val_acc: 0.8120\n",
      "Epoch 66/150\n",
      "57500/57500 [==============================] - 2s 34us/step - loss: 0.6016 - acc: 0.8541 - val_loss: 0.7079 - val_acc: 0.8100\n",
      "Epoch 67/150\n",
      "57500/57500 [==============================] - 2s 34us/step - loss: 0.5992 - acc: 0.8540 - val_loss: 0.7107 - val_acc: 0.8080\n",
      "Epoch 68/150\n",
      "57500/57500 [==============================] - 2s 33us/step - loss: 0.5972 - acc: 0.8548 - val_loss: 0.7057 - val_acc: 0.8070\n",
      "Epoch 69/150\n",
      "57500/57500 [==============================] - 2s 31us/step - loss: 0.5950 - acc: 0.8552 - val_loss: 0.7078 - val_acc: 0.8100\n",
      "Epoch 70/150\n",
      "57500/57500 [==============================] - 2s 39us/step - loss: 0.5931 - acc: 0.8547 - val_loss: 0.7028 - val_acc: 0.8070\n",
      "Epoch 71/150\n",
      "57500/57500 [==============================] - 2s 40us/step - loss: 0.5908 - acc: 0.8549 - val_loss: 0.7022 - val_acc: 0.8050\n",
      "Epoch 72/150\n",
      "57500/57500 [==============================] - 2s 43us/step - loss: 0.5889 - acc: 0.8553 - val_loss: 0.7053 - val_acc: 0.8040\n",
      "Epoch 73/150\n",
      "57500/57500 [==============================] - 3s 45us/step - loss: 0.5873 - acc: 0.8550 - val_loss: 0.7013 - val_acc: 0.8050\n",
      "Epoch 74/150\n",
      "57500/57500 [==============================] - 2s 33us/step - loss: 0.5852 - acc: 0.8563 - val_loss: 0.6964 - val_acc: 0.8080\n",
      "Epoch 75/150\n",
      "57500/57500 [==============================] - 2s 30us/step - loss: 0.5836 - acc: 0.8565 - val_loss: 0.6948 - val_acc: 0.8010\n",
      "Epoch 76/150\n",
      "57500/57500 [==============================] - 2s 38us/step - loss: 0.5821 - acc: 0.8563 - val_loss: 0.6955 - val_acc: 0.8090\n",
      "Epoch 77/150\n",
      "57500/57500 [==============================] - 2s 35us/step - loss: 0.5804 - acc: 0.8561 - val_loss: 0.6939 - val_acc: 0.8060\n",
      "Epoch 78/150\n",
      "57500/57500 [==============================] - 2s 35us/step - loss: 0.5784 - acc: 0.8573 - val_loss: 0.6936 - val_acc: 0.8090\n",
      "Epoch 79/150\n",
      "57500/57500 [==============================] - 2s 32us/step - loss: 0.5772 - acc: 0.8568 - val_loss: 0.6936 - val_acc: 0.8160\n",
      "Epoch 80/150\n",
      "57500/57500 [==============================] - 2s 38us/step - loss: 0.5759 - acc: 0.8575 - val_loss: 0.6944 - val_acc: 0.8100\n",
      "Epoch 81/150\n",
      "57500/57500 [==============================] - 2s 37us/step - loss: 0.5744 - acc: 0.8574 - val_loss: 0.6933 - val_acc: 0.8110\n",
      "Epoch 82/150\n",
      "57500/57500 [==============================] - 2s 36us/step - loss: 0.5734 - acc: 0.8569 - val_loss: 0.6896 - val_acc: 0.8080\n",
      "Epoch 83/150\n",
      "57500/57500 [==============================] - 3s 44us/step - loss: 0.5718 - acc: 0.8576 - val_loss: 0.6880 - val_acc: 0.8100\n",
      "Epoch 84/150\n",
      "57500/57500 [==============================] - 3s 49us/step - loss: 0.5705 - acc: 0.8570 - val_loss: 0.6906 - val_acc: 0.8120\n",
      "Epoch 85/150\n",
      "57500/57500 [==============================] - 3s 48us/step - loss: 0.5692 - acc: 0.8575 - val_loss: 0.6895 - val_acc: 0.8130\n",
      "Epoch 86/150\n",
      "57500/57500 [==============================] - 3s 55us/step - loss: 0.5679 - acc: 0.8574 - val_loss: 0.6873 - val_acc: 0.8020\n",
      "Epoch 87/150\n",
      "57500/57500 [==============================] - 4s 64us/step - loss: 0.5665 - acc: 0.8580 - val_loss: 0.6897 - val_acc: 0.8080\n",
      "Epoch 88/150\n",
      "57500/57500 [==============================] - 4s 69us/step - loss: 0.5654 - acc: 0.8588 - val_loss: 0.6905 - val_acc: 0.8060\n",
      "Epoch 89/150\n",
      "57500/57500 [==============================] - 4s 68us/step - loss: 0.5641 - acc: 0.8583 - val_loss: 0.6870 - val_acc: 0.8050\n",
      "Epoch 90/150\n",
      "57500/57500 [==============================] - 5s 81us/step - loss: 0.5631 - acc: 0.8583 - val_loss: 0.6891 - val_acc: 0.8080\n",
      "Epoch 91/150\n",
      "57500/57500 [==============================] - 3s 50us/step - loss: 0.5620 - acc: 0.8586 - val_loss: 0.6846 - val_acc: 0.8030\n",
      "Epoch 92/150\n",
      "57500/57500 [==============================] - 3s 57us/step - loss: 0.5609 - acc: 0.8585 - val_loss: 0.6877 - val_acc: 0.8030\n",
      "Epoch 93/150\n",
      "57500/57500 [==============================] - 3s 44us/step - loss: 0.5601 - acc: 0.8593 - val_loss: 0.6811 - val_acc: 0.8080\n",
      "Epoch 94/150\n",
      "57500/57500 [==============================] - 2s 36us/step - loss: 0.5590 - acc: 0.8583 - val_loss: 0.6821 - val_acc: 0.8090\n",
      "Epoch 95/150\n",
      "57500/57500 [==============================] - 2s 33us/step - loss: 0.5581 - acc: 0.8589 - val_loss: 0.6801 - val_acc: 0.8080\n",
      "Epoch 96/150\n",
      "57500/57500 [==============================] - 2s 34us/step - loss: 0.5570 - acc: 0.8591 - val_loss: 0.6812 - val_acc: 0.8060\n",
      "Epoch 97/150\n",
      "57500/57500 [==============================] - 2s 37us/step - loss: 0.5560 - acc: 0.8602 - val_loss: 0.6791 - val_acc: 0.8020\n",
      "Epoch 98/150\n",
      "57500/57500 [==============================] - 2s 36us/step - loss: 0.5552 - acc: 0.8591 - val_loss: 0.6789 - val_acc: 0.8110\n",
      "Epoch 99/150\n",
      "57500/57500 [==============================] - 2s 40us/step - loss: 0.5542 - acc: 0.8596 - val_loss: 0.6806 - val_acc: 0.8060\n",
      "Epoch 100/150\n",
      "57500/57500 [==============================] - 2s 36us/step - loss: 0.5535 - acc: 0.8598 - val_loss: 0.6834 - val_acc: 0.8120\n",
      "Epoch 101/150\n",
      "57500/57500 [==============================] - 2s 34us/step - loss: 0.5526 - acc: 0.8593 - val_loss: 0.6770 - val_acc: 0.8130\n",
      "Epoch 102/150\n",
      "57500/57500 [==============================] - 2s 33us/step - loss: 0.5519 - acc: 0.8593 - val_loss: 0.6756 - val_acc: 0.8050\n",
      "Epoch 103/150\n",
      "57500/57500 [==============================] - 2s 36us/step - loss: 0.5508 - acc: 0.8603 - val_loss: 0.6765 - val_acc: 0.8080\n",
      "Epoch 104/150\n",
      "57500/57500 [==============================] - 2s 39us/step - loss: 0.5501 - acc: 0.8603 - val_loss: 0.6775 - val_acc: 0.8130\n",
      "Epoch 105/150\n",
      "57500/57500 [==============================] - 2s 32us/step - loss: 0.5492 - acc: 0.8604 - val_loss: 0.6741 - val_acc: 0.8070\n",
      "Epoch 106/150\n",
      "57500/57500 [==============================] - 2s 34us/step - loss: 0.5486 - acc: 0.8601 - val_loss: 0.6767 - val_acc: 0.8050\n",
      "Epoch 107/150\n",
      "57500/57500 [==============================] - 2s 36us/step - loss: 0.5482 - acc: 0.8607 - val_loss: 0.6748 - val_acc: 0.8060\n",
      "Epoch 108/150\n",
      "57500/57500 [==============================] - 2s 36us/step - loss: 0.5469 - acc: 0.8604 - val_loss: 0.6732 - val_acc: 0.8030\n",
      "Epoch 109/150\n",
      "57500/57500 [==============================] - 2s 35us/step - loss: 0.5464 - acc: 0.8607 - val_loss: 0.6712 - val_acc: 0.8050\n",
      "Epoch 110/150\n",
      "57500/57500 [==============================] - 2s 35us/step - loss: 0.5456 - acc: 0.8605 - val_loss: 0.6730 - val_acc: 0.8050\n",
      "Epoch 111/150\n",
      "57500/57500 [==============================] - 2s 38us/step - loss: 0.5447 - acc: 0.8615 - val_loss: 0.6739 - val_acc: 0.8100\n",
      "Epoch 112/150\n",
      "57500/57500 [==============================] - 3s 54us/step - loss: 0.5443 - acc: 0.8613 - val_loss: 0.6765 - val_acc: 0.8090\n",
      "Epoch 113/150\n",
      "57500/57500 [==============================] - 3s 52us/step - loss: 0.5436 - acc: 0.8609 - val_loss: 0.6828 - val_acc: 0.8060\n",
      "Epoch 114/150\n",
      "57500/57500 [==============================] - 3s 53us/step - loss: 0.5427 - acc: 0.8617 - val_loss: 0.6736 - val_acc: 0.8100\n",
      "Epoch 115/150\n",
      "57500/57500 [==============================] - 4s 63us/step - loss: 0.5424 - acc: 0.8626 - val_loss: 0.6733 - val_acc: 0.8060\n",
      "Epoch 116/150\n",
      "57500/57500 [==============================] - 4s 76us/step - loss: 0.5420 - acc: 0.8622 - val_loss: 0.6699 - val_acc: 0.8030\n",
      "Epoch 117/150\n",
      "57500/57500 [==============================] - 3s 49us/step - loss: 0.5414 - acc: 0.8615 - val_loss: 0.6710 - val_acc: 0.8120\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 118/150\n",
      "57500/57500 [==============================] - 3s 49us/step - loss: 0.5407 - acc: 0.8614 - val_loss: 0.6714 - val_acc: 0.8040\n",
      "Epoch 119/150\n",
      "57500/57500 [==============================] - 2s 30us/step - loss: 0.5401 - acc: 0.8613 - val_loss: 0.6748 - val_acc: 0.8070\n",
      "Epoch 120/150\n",
      "57500/57500 [==============================] - 2s 34us/step - loss: 0.5393 - acc: 0.8616 - val_loss: 0.6696 - val_acc: 0.8030\n",
      "Epoch 121/150\n",
      "57500/57500 [==============================] - 2s 32us/step - loss: 0.5387 - acc: 0.8624 - val_loss: 0.6706 - val_acc: 0.8010\n",
      "Epoch 122/150\n",
      "57500/57500 [==============================] - 2s 34us/step - loss: 0.5381 - acc: 0.8615 - val_loss: 0.6733 - val_acc: 0.8010\n",
      "Epoch 123/150\n",
      "57500/57500 [==============================] - 2s 35us/step - loss: 0.5378 - acc: 0.8618 - val_loss: 0.6702 - val_acc: 0.8070\n",
      "Epoch 124/150\n",
      "57500/57500 [==============================] - 2s 39us/step - loss: 0.5370 - acc: 0.8632 - val_loss: 0.6710 - val_acc: 0.8080\n",
      "Epoch 125/150\n",
      "57500/57500 [==============================] - 2s 36us/step - loss: 0.5366 - acc: 0.8621 - val_loss: 0.6726 - val_acc: 0.8030\n",
      "Epoch 126/150\n",
      "57500/57500 [==============================] - 2s 40us/step - loss: 0.5361 - acc: 0.8619 - val_loss: 0.6697 - val_acc: 0.8070\n",
      "Epoch 127/150\n",
      "57500/57500 [==============================] - 2s 33us/step - loss: 0.5354 - acc: 0.8616 - val_loss: 0.6704 - val_acc: 0.8030\n",
      "Epoch 128/150\n",
      "57500/57500 [==============================] - 2s 35us/step - loss: 0.5348 - acc: 0.8623 - val_loss: 0.6675 - val_acc: 0.8010\n",
      "Epoch 129/150\n",
      "57500/57500 [==============================] - 2s 37us/step - loss: 0.5343 - acc: 0.8627 - val_loss: 0.6736 - val_acc: 0.8060\n",
      "Epoch 130/150\n",
      "57500/57500 [==============================] - 2s 33us/step - loss: 0.5337 - acc: 0.8625 - val_loss: 0.6681 - val_acc: 0.8060\n",
      "Epoch 131/150\n",
      "57500/57500 [==============================] - 2s 37us/step - loss: 0.5336 - acc: 0.8634 - val_loss: 0.6652 - val_acc: 0.8000\n",
      "Epoch 132/150\n",
      "57500/57500 [==============================] - 2s 35us/step - loss: 0.5329 - acc: 0.8625 - val_loss: 0.6651 - val_acc: 0.7990\n",
      "Epoch 133/150\n",
      "57500/57500 [==============================] - 2s 40us/step - loss: 0.5323 - acc: 0.8627 - val_loss: 0.6702 - val_acc: 0.8040\n",
      "Epoch 134/150\n",
      "57500/57500 [==============================] - 2s 35us/step - loss: 0.5318 - acc: 0.8629 - val_loss: 0.6697 - val_acc: 0.8100\n",
      "Epoch 135/150\n",
      "57500/57500 [==============================] - 2s 33us/step - loss: 0.5314 - acc: 0.8636 - val_loss: 0.6664 - val_acc: 0.8080\n",
      "Epoch 136/150\n",
      "57500/57500 [==============================] - 3s 48us/step - loss: 0.5311 - acc: 0.8633 - val_loss: 0.6672 - val_acc: 0.8080\n",
      "Epoch 137/150\n",
      "57500/57500 [==============================] - 2s 41us/step - loss: 0.5303 - acc: 0.8633 - val_loss: 0.6668 - val_acc: 0.8050\n",
      "Epoch 138/150\n",
      "57500/57500 [==============================] - 2s 38us/step - loss: 0.5299 - acc: 0.8629 - val_loss: 0.6679 - val_acc: 0.8050\n",
      "Epoch 139/150\n",
      "57500/57500 [==============================] - 2s 34us/step - loss: 0.5295 - acc: 0.8635 - val_loss: 0.6663 - val_acc: 0.7990\n",
      "Epoch 140/150\n",
      "57500/57500 [==============================] - 2s 33us/step - loss: 0.5289 - acc: 0.8640 - val_loss: 0.6694 - val_acc: 0.8060\n",
      "Epoch 141/150\n",
      "57500/57500 [==============================] - 2s 40us/step - loss: 0.5288 - acc: 0.8628 - val_loss: 0.6660 - val_acc: 0.8000\n",
      "Epoch 142/150\n",
      "57500/57500 [==============================] - 2s 35us/step - loss: 0.5283 - acc: 0.8635 - val_loss: 0.6646 - val_acc: 0.8030\n",
      "Epoch 143/150\n",
      "57500/57500 [==============================] - 2s 34us/step - loss: 0.5275 - acc: 0.8640 - val_loss: 0.6730 - val_acc: 0.8020\n",
      "Epoch 144/150\n",
      "57500/57500 [==============================] - 2s 35us/step - loss: 0.5275 - acc: 0.8641 - val_loss: 0.6637 - val_acc: 0.8000\n",
      "Epoch 145/150\n",
      "57500/57500 [==============================] - 2s 35us/step - loss: 0.5270 - acc: 0.8632 - val_loss: 0.6629 - val_acc: 0.8040\n",
      "Epoch 146/150\n",
      "57500/57500 [==============================] - 2s 41us/step - loss: 0.5265 - acc: 0.8640 - val_loss: 0.6651 - val_acc: 0.8020\n",
      "Epoch 147/150\n",
      "57500/57500 [==============================] - 2s 34us/step - loss: 0.5262 - acc: 0.8640 - val_loss: 0.6675 - val_acc: 0.8040\n",
      "Epoch 148/150\n",
      "57500/57500 [==============================] - 2s 38us/step - loss: 0.5257 - acc: 0.8648 - val_loss: 0.6634 - val_acc: 0.8050\n",
      "Epoch 149/150\n",
      "57500/57500 [==============================] - 2s 33us/step - loss: 0.5254 - acc: 0.8642 - val_loss: 0.6625 - val_acc: 0.8010\n",
      "Epoch 150/150\n",
      "57500/57500 [==============================] - 2s 36us/step - loss: 0.5250 - acc: 0.8639 - val_loss: 0.6628 - val_acc: 0.8000\n"
     ]
    }
   ],
   "source": [
    "# Import regularizers\n",
    "from keras import regularizers\n",
    "\n",
    "lambda_coeff = 0.005\n",
    "random.seed(123)\n",
    "L2_model = models.Sequential()\n",
    "\n",
    "# Add the input and first hidden layer\n",
    "L2_model.add(layers.Dense(50, activation='relu', input_shape=(2000,), kernel_regularizer=regularizers.l2(l=lambda_coeff)))\n",
    "\n",
    "# Add another hidden layer\n",
    "L2_model.add(layers.Dense(25, activation='relu', kernel_regularizer=regularizers.l2(l=lambda_coeff)))\n",
    "\n",
    "\n",
    "# Add an output layer\n",
    "L2_model.add(layers.Dense(7, activation='softmax'))\n",
    "\n",
    "# Compile the model\n",
    "L2_model.compile(optimizer='SGD', \n",
    "                 loss='categorical_crossentropy', \n",
    "                 metrics=['accuracy'])\n",
    "\n",
    "# Train the model \n",
    "L2_model_val = L2_model.fit(X_train_tokens, \n",
    "                            y_train_lb, \n",
    "                            epochs=150, \n",
    "                            batch_size=256, \n",
    "                            validation_data=(X_val_tokens, y_val_lb))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now, look at the training as well as the validation accuracy for both the L2 and the baseline models. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 864x576 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "# L2 model details\n",
    "L2_model_dict = L2_model_val.history\n",
    "L2_acc_values = L2_model_dict['acc'] \n",
    "L2_val_acc_values = L2_model_dict['val_acc']\n",
    "\n",
    "# Baseline model\n",
    "baseline_model_acc = baseline_model_val_dict['acc'] \n",
    "baseline_model_val_acc = baseline_model_val_dict['val_acc']\n",
    "\n",
    "# Plot the accuracy for these models\n",
    "fig, ax = plt.subplots(figsize=(12, 8))\n",
    "epochs = range(1, len(L2_acc_values) + 1)\n",
    "ax.plot(epochs, L2_acc_values, label='Training acc L2')\n",
    "ax.plot(epochs, L2_val_acc_values, label='Validation acc L2')\n",
    "ax.plot(epochs, baseline_model_acc, label='Training acc')\n",
    "ax.plot(epochs, baseline_model_val_acc, label='Validation acc')\n",
    "ax.set_title('Training & validation accuracy L2 vs regular')\n",
    "ax.set_xlabel('Epochs')\n",
    "ax.set_ylabel('Loss')\n",
    "ax.legend();"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The results of L2 regularization are quite disappointing here. Notice the discrepancy between validation and training accuracy seems to have decreased slightly, but the end result is definitely not getting better.  \n",
    "\n",
    "\n",
    "## L1 Regularization\n",
    "\n",
    "Now have a look at L1 regularization. Will this work better? \n",
    "\n",
    "- Use 2 hidden layers with 50 units in the first and 25 in the second layer, both with `'relu'` activation functions \n",
    "- Add L1 regularization to both the hidden layers with 0.005 as the `lambda_coeff` "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 57500 samples, validate on 1000 samples\n",
      "Epoch 1/150\n",
      "57500/57500 [==============================] - 3s 54us/step - loss: 13.6832 - acc: 0.2259 - val_loss: 11.1562 - val_acc: 0.2870\n",
      "Epoch 2/150\n",
      "57500/57500 [==============================] - 2s 42us/step - loss: 9.0069 - acc: 0.4245 - val_loss: 7.0541 - val_acc: 0.5300\n",
      "Epoch 3/150\n",
      "57500/57500 [==============================] - 3s 46us/step - loss: 5.5204 - acc: 0.6087 - val_loss: 4.2041 - val_acc: 0.6320\n",
      "Epoch 4/150\n",
      "57500/57500 [==============================] - 3s 47us/step - loss: 3.2899 - acc: 0.6674 - val_loss: 2.5939 - val_acc: 0.6640\n",
      "Epoch 5/150\n",
      "57500/57500 [==============================] - 3s 53us/step - loss: 2.2508 - acc: 0.6815 - val_loss: 2.0784 - val_acc: 0.6710\n",
      "Epoch 6/150\n",
      "57500/57500 [==============================] - 4s 69us/step - loss: 1.9864 - acc: 0.6864 - val_loss: 1.9346 - val_acc: 0.6730\n",
      "Epoch 7/150\n",
      "57500/57500 [==============================] - 4s 66us/step - loss: 1.8667 - acc: 0.6900 - val_loss: 1.8363 - val_acc: 0.6720\n",
      "Epoch 8/150\n",
      "57500/57500 [==============================] - 3s 54us/step - loss: 1.7763 - acc: 0.6936 - val_loss: 1.7547 - val_acc: 0.6760\n",
      "Epoch 9/150\n",
      "57500/57500 [==============================] - 3s 56us/step - loss: 1.7017 - acc: 0.6974 - val_loss: 1.6876 - val_acc: 0.6780\n",
      "Epoch 10/150\n",
      "57500/57500 [==============================] - 3s 52us/step - loss: 1.6379 - acc: 0.6998 - val_loss: 1.6275 - val_acc: 0.6850\n",
      "Epoch 11/150\n",
      "57500/57500 [==============================] - 3s 54us/step - loss: 1.5813 - acc: 0.7019 - val_loss: 1.5747 - val_acc: 0.6850\n",
      "Epoch 12/150\n",
      "57500/57500 [==============================] - 3s 51us/step - loss: 1.5296 - acc: 0.7050 - val_loss: 1.5232 - val_acc: 0.6900\n",
      "Epoch 13/150\n",
      "57500/57500 [==============================] - 3s 47us/step - loss: 1.4821 - acc: 0.7079 - val_loss: 1.4803 - val_acc: 0.6950\n",
      "Epoch 14/150\n",
      "57500/57500 [==============================] - 3s 53us/step - loss: 1.4381 - acc: 0.7110 - val_loss: 1.4376 - val_acc: 0.6940\n",
      "Epoch 15/150\n",
      "57500/57500 [==============================] - 2s 41us/step - loss: 1.3972 - acc: 0.7133 - val_loss: 1.3995 - val_acc: 0.7040\n",
      "Epoch 16/150\n",
      "57500/57500 [==============================] - 3s 47us/step - loss: 1.3595 - acc: 0.7161 - val_loss: 1.3626 - val_acc: 0.7030\n",
      "Epoch 17/150\n",
      "57500/57500 [==============================] - 2s 38us/step - loss: 1.3243 - acc: 0.7192 - val_loss: 1.3302 - val_acc: 0.7050\n",
      "Epoch 18/150\n",
      "57500/57500 [==============================] - 2s 40us/step - loss: 1.2925 - acc: 0.7213 - val_loss: 1.2980 - val_acc: 0.7090\n",
      "Epoch 19/150\n",
      "57500/57500 [==============================] - 3s 46us/step - loss: 1.2625 - acc: 0.7233 - val_loss: 1.2719 - val_acc: 0.7070\n",
      "Epoch 20/150\n",
      "57500/57500 [==============================] - 3s 48us/step - loss: 1.2358 - acc: 0.7260 - val_loss: 1.2455 - val_acc: 0.7180\n",
      "Epoch 21/150\n",
      "57500/57500 [==============================] - 2s 38us/step - loss: 1.2116 - acc: 0.7283 - val_loss: 1.2219 - val_acc: 0.7200\n",
      "Epoch 22/150\n",
      "57500/57500 [==============================] - 2s 38us/step - loss: 1.1897 - acc: 0.7296 - val_loss: 1.2013 - val_acc: 0.7220\n",
      "Epoch 23/150\n",
      "57500/57500 [==============================] - 2s 36us/step - loss: 1.1699 - acc: 0.7317 - val_loss: 1.1835 - val_acc: 0.7250\n",
      "Epoch 24/150\n",
      "57500/57500 [==============================] - 2s 32us/step - loss: 1.1523 - acc: 0.7341 - val_loss: 1.1662 - val_acc: 0.7250\n",
      "Epoch 25/150\n",
      "57500/57500 [==============================] - 2s 40us/step - loss: 1.1362 - acc: 0.7351 - val_loss: 1.1515 - val_acc: 0.7260\n",
      "Epoch 26/150\n",
      "57500/57500 [==============================] - 2s 37us/step - loss: 1.1217 - acc: 0.7373 - val_loss: 1.1423 - val_acc: 0.7280\n",
      "Epoch 27/150\n",
      "57500/57500 [==============================] - 2s 36us/step - loss: 1.1083 - acc: 0.7385 - val_loss: 1.1261 - val_acc: 0.7300\n",
      "Epoch 28/150\n",
      "57500/57500 [==============================] - 4s 63us/step - loss: 1.0961 - acc: 0.7391 - val_loss: 1.1158 - val_acc: 0.7320\n",
      "Epoch 29/150\n",
      "57500/57500 [==============================] - 2s 39us/step - loss: 1.0843 - acc: 0.7406 - val_loss: 1.1107 - val_acc: 0.7260\n",
      "Epoch 30/150\n",
      "57500/57500 [==============================] - 3s 44us/step - loss: 1.0731 - acc: 0.7424 - val_loss: 1.0941 - val_acc: 0.7360\n",
      "Epoch 31/150\n",
      "57500/57500 [==============================] - 2s 33us/step - loss: 1.0630 - acc: 0.7428 - val_loss: 1.0850 - val_acc: 0.7280\n",
      "Epoch 32/150\n",
      "57500/57500 [==============================] - 2s 42us/step - loss: 1.0539 - acc: 0.7442 - val_loss: 1.0771 - val_acc: 0.7310\n",
      "Epoch 33/150\n",
      "57500/57500 [==============================] - 2s 37us/step - loss: 1.0453 - acc: 0.7457 - val_loss: 1.0666 - val_acc: 0.7400\n",
      "Epoch 34/150\n",
      "57500/57500 [==============================] - 2s 34us/step - loss: 1.0371 - acc: 0.7465 - val_loss: 1.0634 - val_acc: 0.7360\n",
      "Epoch 35/150\n",
      "57500/57500 [==============================] - 2s 35us/step - loss: 1.0293 - acc: 0.7477 - val_loss: 1.0527 - val_acc: 0.7360\n",
      "Epoch 36/150\n",
      "57500/57500 [==============================] - 4s 63us/step - loss: 1.0220 - acc: 0.7488 - val_loss: 1.0451 - val_acc: 0.7350\n",
      "Epoch 37/150\n",
      "57500/57500 [==============================] - 3s 55us/step - loss: 1.0147 - acc: 0.7495 - val_loss: 1.0381 - val_acc: 0.7410\n",
      "Epoch 38/150\n",
      "57500/57500 [==============================] - 2s 41us/step - loss: 1.0081 - acc: 0.7522 - val_loss: 1.0343 - val_acc: 0.7340\n",
      "Epoch 39/150\n",
      "57500/57500 [==============================] - 2s 32us/step - loss: 1.0018 - acc: 0.7515 - val_loss: 1.0258 - val_acc: 0.7400\n",
      "Epoch 40/150\n",
      "57500/57500 [==============================] - 2s 34us/step - loss: 0.9956 - acc: 0.7530 - val_loss: 1.0212 - val_acc: 0.7390\n",
      "Epoch 41/150\n",
      "57500/57500 [==============================] - 2s 32us/step - loss: 0.9897 - acc: 0.7543 - val_loss: 1.0197 - val_acc: 0.7410\n",
      "Epoch 42/150\n",
      "57500/57500 [==============================] - 2s 38us/step - loss: 0.9841 - acc: 0.7544 - val_loss: 1.0120 - val_acc: 0.7420\n",
      "Epoch 43/150\n",
      "57500/57500 [==============================] - 4s 61us/step - loss: 0.9790 - acc: 0.7558 - val_loss: 1.0078 - val_acc: 0.7380\n",
      "Epoch 44/150\n",
      "57500/57500 [==============================] - 3s 55us/step - loss: 0.9735 - acc: 0.7564 - val_loss: 1.0017 - val_acc: 0.7510\n",
      "Epoch 45/150\n",
      "57500/57500 [==============================] - 2s 38us/step - loss: 0.9686 - acc: 0.7573 - val_loss: 1.0001 - val_acc: 0.7460\n",
      "Epoch 46/150\n",
      "57500/57500 [==============================] - 2s 38us/step - loss: 0.9636 - acc: 0.7581 - val_loss: 0.9950 - val_acc: 0.7380\n",
      "Epoch 47/150\n",
      "57500/57500 [==============================] - 2s 33us/step - loss: 0.9593 - acc: 0.7601 - val_loss: 0.9899 - val_acc: 0.7540\n",
      "Epoch 48/150\n",
      "57500/57500 [==============================] - 2s 32us/step - loss: 0.9553 - acc: 0.7600 - val_loss: 0.9851 - val_acc: 0.7480\n",
      "Epoch 49/150\n",
      "57500/57500 [==============================] - 2s 30us/step - loss: 0.9515 - acc: 0.7607 - val_loss: 0.9803 - val_acc: 0.7430\n",
      "Epoch 50/150\n",
      "57500/57500 [==============================] - 2s 32us/step - loss: 0.9478 - acc: 0.7621 - val_loss: 0.9769 - val_acc: 0.7440\n",
      "Epoch 51/150\n",
      "57500/57500 [==============================] - 2s 35us/step - loss: 0.9443 - acc: 0.7629 - val_loss: 0.9765 - val_acc: 0.7450\n",
      "Epoch 52/150\n",
      "57500/57500 [==============================] - 3s 57us/step - loss: 0.9409 - acc: 0.7631 - val_loss: 0.9757 - val_acc: 0.7450\n",
      "Epoch 53/150\n",
      "57500/57500 [==============================] - 3s 47us/step - loss: 0.9381 - acc: 0.7634 - val_loss: 0.9680 - val_acc: 0.7530\n",
      "Epoch 54/150\n",
      "57500/57500 [==============================] - 3s 54us/step - loss: 0.9351 - acc: 0.7634 - val_loss: 0.9695 - val_acc: 0.7480\n",
      "Epoch 55/150\n",
      "57500/57500 [==============================] - 2s 33us/step - loss: 0.9320 - acc: 0.7661 - val_loss: 0.9726 - val_acc: 0.7490\n",
      "Epoch 56/150\n",
      "57500/57500 [==============================] - 3s 44us/step - loss: 0.9293 - acc: 0.7654 - val_loss: 0.9617 - val_acc: 0.7480\n",
      "Epoch 57/150\n",
      "57500/57500 [==============================] - 2s 37us/step - loss: 0.9267 - acc: 0.7659 - val_loss: 0.9647 - val_acc: 0.7400\n",
      "Epoch 58/150\n",
      "57500/57500 [==============================] - 2s 37us/step - loss: 0.9239 - acc: 0.7677 - val_loss: 0.9558 - val_acc: 0.7510\n",
      "Epoch 59/150\n",
      "57500/57500 [==============================] - 2s 39us/step - loss: 0.9216 - acc: 0.7681 - val_loss: 0.9531 - val_acc: 0.7550\n",
      "Epoch 60/150\n",
      "57500/57500 [==============================] - 3s 44us/step - loss: 0.9191 - acc: 0.7667 - val_loss: 0.9498 - val_acc: 0.7480\n",
      "Epoch 61/150\n",
      "57500/57500 [==============================] - 2s 36us/step - loss: 0.9169 - acc: 0.7684 - val_loss: 0.9579 - val_acc: 0.7500\n",
      "Epoch 62/150\n",
      "57500/57500 [==============================] - 3s 48us/step - loss: 0.9153 - acc: 0.7679 - val_loss: 0.9518 - val_acc: 0.7500\n",
      "Epoch 63/150\n",
      "57500/57500 [==============================] - 2s 39us/step - loss: 0.9129 - acc: 0.7692 - val_loss: 0.9454 - val_acc: 0.7500\n",
      "Epoch 64/150\n",
      "57500/57500 [==============================] - 2s 33us/step - loss: 0.9107 - acc: 0.7705 - val_loss: 0.9479 - val_acc: 0.7490\n",
      "Epoch 65/150\n",
      "57500/57500 [==============================] - 3s 45us/step - loss: 0.9091 - acc: 0.7710 - val_loss: 0.9392 - val_acc: 0.7590\n",
      "Epoch 66/150\n",
      "57500/57500 [==============================] - 2s 39us/step - loss: 0.9070 - acc: 0.7709 - val_loss: 0.9421 - val_acc: 0.7460\n",
      "Epoch 67/150\n",
      "57500/57500 [==============================] - 2s 32us/step - loss: 0.9049 - acc: 0.7713 - val_loss: 0.9418 - val_acc: 0.7540\n",
      "Epoch 68/150\n",
      "57500/57500 [==============================] - 2s 34us/step - loss: 0.9034 - acc: 0.7718 - val_loss: 0.9405 - val_acc: 0.7480\n",
      "Epoch 69/150\n",
      "57500/57500 [==============================] - 2s 42us/step - loss: 0.9017 - acc: 0.7719 - val_loss: 0.9403 - val_acc: 0.7520\n",
      "Epoch 70/150\n",
      "57500/57500 [==============================] - 2s 35us/step - loss: 0.8995 - acc: 0.7720 - val_loss: 0.9314 - val_acc: 0.7560\n",
      "Epoch 71/150\n",
      "57500/57500 [==============================] - 2s 35us/step - loss: 0.8981 - acc: 0.7729 - val_loss: 0.9369 - val_acc: 0.7570\n",
      "Epoch 72/150\n",
      "57500/57500 [==============================] - 2s 36us/step - loss: 0.8962 - acc: 0.7722 - val_loss: 0.9298 - val_acc: 0.7580\n",
      "Epoch 73/150\n",
      "57500/57500 [==============================] - 2s 34us/step - loss: 0.8945 - acc: 0.7728 - val_loss: 0.9286 - val_acc: 0.7550\n",
      "Epoch 74/150\n",
      "57500/57500 [==============================] - 3s 44us/step - loss: 0.8929 - acc: 0.7739 - val_loss: 0.9286 - val_acc: 0.7460\n",
      "Epoch 75/150\n",
      "57500/57500 [==============================] - 2s 31us/step - loss: 0.8913 - acc: 0.7737 - val_loss: 0.9256 - val_acc: 0.7540\n",
      "Epoch 76/150\n",
      "57500/57500 [==============================] - 2s 34us/step - loss: 0.8897 - acc: 0.7749 - val_loss: 0.9265 - val_acc: 0.7570\n",
      "Epoch 77/150\n",
      "57500/57500 [==============================] - 2s 36us/step - loss: 0.8878 - acc: 0.7749 - val_loss: 0.9224 - val_acc: 0.7550\n",
      "Epoch 78/150\n",
      "57500/57500 [==============================] - 2s 39us/step - loss: 0.8865 - acc: 0.7749 - val_loss: 0.9177 - val_acc: 0.7580\n",
      "Epoch 79/150\n",
      "57500/57500 [==============================] - 2s 35us/step - loss: 0.8852 - acc: 0.7748 - val_loss: 0.9248 - val_acc: 0.7470\n",
      "Epoch 80/150\n",
      "57500/57500 [==============================] - 2s 34us/step - loss: 0.8833 - acc: 0.7756 - val_loss: 0.9181 - val_acc: 0.7560\n",
      "Epoch 81/150\n",
      "57500/57500 [==============================] - 2s 37us/step - loss: 0.8821 - acc: 0.7763 - val_loss: 0.9206 - val_acc: 0.7550\n",
      "Epoch 82/150\n",
      "57500/57500 [==============================] - 2s 33us/step - loss: 0.8807 - acc: 0.7762 - val_loss: 0.9157 - val_acc: 0.7640\n",
      "Epoch 83/150\n",
      "57500/57500 [==============================] - 2s 31us/step - loss: 0.8795 - acc: 0.7766 - val_loss: 0.9101 - val_acc: 0.7620\n",
      "Epoch 84/150\n",
      "57500/57500 [==============================] - 2s 36us/step - loss: 0.8774 - acc: 0.7772 - val_loss: 0.9165 - val_acc: 0.7490\n",
      "Epoch 85/150\n",
      "57500/57500 [==============================] - 2s 39us/step - loss: 0.8767 - acc: 0.7772 - val_loss: 0.9079 - val_acc: 0.7560\n",
      "Epoch 86/150\n",
      "57500/57500 [==============================] - 2s 42us/step - loss: 0.8752 - acc: 0.7774 - val_loss: 0.9107 - val_acc: 0.7600\n",
      "Epoch 87/150\n",
      "57500/57500 [==============================] - 2s 43us/step - loss: 0.8741 - acc: 0.7782 - val_loss: 0.9046 - val_acc: 0.7610\n",
      "Epoch 88/150\n",
      "57500/57500 [==============================] - 3s 45us/step - loss: 0.8729 - acc: 0.7771 - val_loss: 0.9131 - val_acc: 0.7500\n",
      "Epoch 89/150\n",
      "57500/57500 [==============================] - 2s 42us/step - loss: 0.8715 - acc: 0.7786 - val_loss: 0.9082 - val_acc: 0.7520\n",
      "Epoch 90/150\n",
      "57500/57500 [==============================] - 3s 52us/step - loss: 0.8697 - acc: 0.7793 - val_loss: 0.9137 - val_acc: 0.7490\n",
      "Epoch 91/150\n",
      "57500/57500 [==============================] - 3s 47us/step - loss: 0.8689 - acc: 0.7786 - val_loss: 0.9102 - val_acc: 0.7520\n",
      "Epoch 92/150\n",
      "57500/57500 [==============================] - 2s 38us/step - loss: 0.8677 - acc: 0.7787 - val_loss: 0.9023 - val_acc: 0.7610\n",
      "Epoch 93/150\n",
      "57500/57500 [==============================] - 2s 39us/step - loss: 0.8664 - acc: 0.7797 - val_loss: 0.8979 - val_acc: 0.7620\n",
      "Epoch 94/150\n",
      "57500/57500 [==============================] - 3s 48us/step - loss: 0.8659 - acc: 0.7797 - val_loss: 0.9080 - val_acc: 0.7560\n",
      "Epoch 95/150\n",
      "57500/57500 [==============================] - 3s 48us/step - loss: 0.8642 - acc: 0.7802 - val_loss: 0.9038 - val_acc: 0.7590\n",
      "Epoch 96/150\n",
      "57500/57500 [==============================] - 3s 45us/step - loss: 0.8630 - acc: 0.7793 - val_loss: 0.8962 - val_acc: 0.7600\n",
      "Epoch 97/150\n",
      "57500/57500 [==============================] - 2s 41us/step - loss: 0.8618 - acc: 0.7814 - val_loss: 0.9005 - val_acc: 0.7660\n",
      "Epoch 98/150\n",
      "57500/57500 [==============================] - 2s 40us/step - loss: 0.8619 - acc: 0.7794 - val_loss: 0.9009 - val_acc: 0.7480\n",
      "Epoch 99/150\n",
      "57500/57500 [==============================] - 2s 36us/step - loss: 0.8605 - acc: 0.7817 - val_loss: 0.8954 - val_acc: 0.7640\n",
      "Epoch 100/150\n",
      "57500/57500 [==============================] - 3s 44us/step - loss: 0.8595 - acc: 0.7813 - val_loss: 0.8997 - val_acc: 0.7550\n",
      "Epoch 101/150\n",
      "57500/57500 [==============================] - 4s 65us/step - loss: 0.8585 - acc: 0.7818 - val_loss: 0.8913 - val_acc: 0.7630\n",
      "Epoch 102/150\n",
      "57500/57500 [==============================] - 4s 69us/step - loss: 0.8576 - acc: 0.7806 - val_loss: 0.8902 - val_acc: 0.7670\n",
      "Epoch 103/150\n",
      "57500/57500 [==============================] - 2s 38us/step - loss: 0.8563 - acc: 0.7813 - val_loss: 0.8939 - val_acc: 0.7600\n",
      "Epoch 104/150\n",
      "57500/57500 [==============================] - 2s 33us/step - loss: 0.8556 - acc: 0.7827 - val_loss: 0.8930 - val_acc: 0.7540\n",
      "Epoch 105/150\n",
      "57500/57500 [==============================] - 2s 31us/step - loss: 0.8557 - acc: 0.7816 - val_loss: 0.8900 - val_acc: 0.7660\n",
      "Epoch 106/150\n",
      "57500/57500 [==============================] - 2s 43us/step - loss: 0.8539 - acc: 0.7817 - val_loss: 0.8936 - val_acc: 0.7540\n",
      "Epoch 107/150\n",
      "57500/57500 [==============================] - 2s 41us/step - loss: 0.8536 - acc: 0.7820 - val_loss: 0.9064 - val_acc: 0.7560\n",
      "Epoch 108/150\n",
      "57500/57500 [==============================] - 2s 41us/step - loss: 0.8532 - acc: 0.7817 - val_loss: 0.8821 - val_acc: 0.7640\n",
      "Epoch 109/150\n",
      "57500/57500 [==============================] - 2s 37us/step - loss: 0.8513 - acc: 0.7839 - val_loss: 0.8864 - val_acc: 0.7640\n",
      "Epoch 110/150\n",
      "57500/57500 [==============================] - 2s 35us/step - loss: 0.8513 - acc: 0.7819 - val_loss: 0.8962 - val_acc: 0.7530\n",
      "Epoch 111/150\n",
      "57500/57500 [==============================] - 2s 41us/step - loss: 0.8503 - acc: 0.7832 - val_loss: 0.8824 - val_acc: 0.7630\n",
      "Epoch 112/150\n",
      "57500/57500 [==============================] - 2s 38us/step - loss: 0.8493 - acc: 0.7835 - val_loss: 0.8896 - val_acc: 0.7610\n",
      "Epoch 113/150\n",
      "57500/57500 [==============================] - 2s 34us/step - loss: 0.8495 - acc: 0.7838 - val_loss: 0.9008 - val_acc: 0.7510\n",
      "Epoch 114/150\n",
      "57500/57500 [==============================] - 2s 32us/step - loss: 0.8478 - acc: 0.7833 - val_loss: 0.8846 - val_acc: 0.7670\n",
      "Epoch 115/150\n",
      "57500/57500 [==============================] - 2s 33us/step - loss: 0.8473 - acc: 0.7845 - val_loss: 0.8849 - val_acc: 0.7680\n",
      "Epoch 116/150\n",
      "57500/57500 [==============================] - 3s 51us/step - loss: 0.8465 - acc: 0.7838 - val_loss: 0.8891 - val_acc: 0.7500\n",
      "Epoch 117/150\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "57500/57500 [==============================] - 3s 45us/step - loss: 0.8455 - acc: 0.7851 - val_loss: 0.8812 - val_acc: 0.7620\n",
      "Epoch 118/150\n",
      "57500/57500 [==============================] - 3s 47us/step - loss: 0.8454 - acc: 0.7846 - val_loss: 0.8831 - val_acc: 0.7590\n",
      "Epoch 119/150\n",
      "57500/57500 [==============================] - 2s 30us/step - loss: 0.8442 - acc: 0.7847 - val_loss: 0.8755 - val_acc: 0.7700\n",
      "Epoch 120/150\n",
      "57500/57500 [==============================] - 2s 34us/step - loss: 0.8435 - acc: 0.7850 - val_loss: 0.8814 - val_acc: 0.7600\n",
      "Epoch 121/150\n",
      "57500/57500 [==============================] - 2s 38us/step - loss: 0.8426 - acc: 0.7859 - val_loss: 0.8786 - val_acc: 0.7580\n",
      "Epoch 122/150\n",
      "57500/57500 [==============================] - 3s 56us/step - loss: 0.8422 - acc: 0.7846 - val_loss: 0.9097 - val_acc: 0.7470\n",
      "Epoch 123/150\n",
      "57500/57500 [==============================] - 3s 44us/step - loss: 0.8419 - acc: 0.7852 - val_loss: 0.8737 - val_acc: 0.7690\n",
      "Epoch 124/150\n",
      "57500/57500 [==============================] - 2s 31us/step - loss: 0.8412 - acc: 0.7847 - val_loss: 0.8995 - val_acc: 0.7470\n",
      "Epoch 125/150\n",
      "57500/57500 [==============================] - 3s 48us/step - loss: 0.8400 - acc: 0.7847 - val_loss: 0.8732 - val_acc: 0.7620\n",
      "Epoch 126/150\n",
      "57500/57500 [==============================] - 2s 43us/step - loss: 0.8404 - acc: 0.7836 - val_loss: 0.8860 - val_acc: 0.7570\n",
      "Epoch 127/150\n",
      "57500/57500 [==============================] - 2s 31us/step - loss: 0.8403 - acc: 0.7846 - val_loss: 0.8747 - val_acc: 0.7690\n",
      "Epoch 128/150\n",
      "57500/57500 [==============================] - 2s 31us/step - loss: 0.8374 - acc: 0.7863 - val_loss: 0.8932 - val_acc: 0.7530\n",
      "Epoch 129/150\n",
      "57500/57500 [==============================] - 2s 31us/step - loss: 0.8372 - acc: 0.7849 - val_loss: 0.8782 - val_acc: 0.7660\n",
      "Epoch 130/150\n",
      "57500/57500 [==============================] - 2s 36us/step - loss: 0.8391 - acc: 0.7837 - val_loss: 0.8805 - val_acc: 0.7590\n",
      "Epoch 131/150\n",
      "57500/57500 [==============================] - 2s 32us/step - loss: 0.8373 - acc: 0.7851 - val_loss: 0.8672 - val_acc: 0.7630\n",
      "Epoch 132/150\n",
      "57500/57500 [==============================] - 3s 45us/step - loss: 0.8365 - acc: 0.7838 - val_loss: 0.8713 - val_acc: 0.7660\n",
      "Epoch 133/150\n",
      "57500/57500 [==============================] - 2s 32us/step - loss: 0.8356 - acc: 0.7864 - val_loss: 0.8657 - val_acc: 0.7660\n",
      "Epoch 134/150\n",
      "57500/57500 [==============================] - 3s 58us/step - loss: 0.8352 - acc: 0.7850 - val_loss: 0.8781 - val_acc: 0.7660\n",
      "Epoch 135/150\n",
      "57500/57500 [==============================] - 2s 42us/step - loss: 0.8344 - acc: 0.7865 - val_loss: 0.8655 - val_acc: 0.7760\n",
      "Epoch 136/150\n",
      "57500/57500 [==============================] - 3s 44us/step - loss: 0.8347 - acc: 0.7858 - val_loss: 0.8911 - val_acc: 0.7690\n",
      "Epoch 137/150\n",
      "57500/57500 [==============================] - 3s 44us/step - loss: 0.8347 - acc: 0.7863 - val_loss: 0.8658 - val_acc: 0.7720\n",
      "Epoch 138/150\n",
      "57500/57500 [==============================] - 3s 44us/step - loss: 0.8323 - acc: 0.7868 - val_loss: 0.8671 - val_acc: 0.7650\n",
      "Epoch 139/150\n",
      "57500/57500 [==============================] - 2s 41us/step - loss: 0.8334 - acc: 0.7850 - val_loss: 0.8679 - val_acc: 0.7680\n",
      "Epoch 140/150\n",
      "57500/57500 [==============================] - 2s 33us/step - loss: 0.8325 - acc: 0.7850 - val_loss: 0.8626 - val_acc: 0.7790\n",
      "Epoch 141/150\n",
      "57500/57500 [==============================] - 2s 31us/step - loss: 0.8302 - acc: 0.7856 - val_loss: 0.8895 - val_acc: 0.7570\n",
      "Epoch 142/150\n",
      "57500/57500 [==============================] - 2s 37us/step - loss: 0.8307 - acc: 0.7866 - val_loss: 0.8623 - val_acc: 0.7710\n",
      "Epoch 143/150\n",
      "57500/57500 [==============================] - 2s 32us/step - loss: 0.8307 - acc: 0.7850 - val_loss: 0.8673 - val_acc: 0.7560\n",
      "Epoch 144/150\n",
      "57500/57500 [==============================] - 2s 31us/step - loss: 0.8306 - acc: 0.7863 - val_loss: 0.8748 - val_acc: 0.7750\n",
      "Epoch 145/150\n",
      "57500/57500 [==============================] - 2s 32us/step - loss: 0.8288 - acc: 0.7882 - val_loss: 0.8627 - val_acc: 0.7760\n",
      "Epoch 146/150\n",
      "57500/57500 [==============================] - 2s 32us/step - loss: 0.8285 - acc: 0.7873 - val_loss: 0.8633 - val_acc: 0.7750\n",
      "Epoch 147/150\n",
      "57500/57500 [==============================] - 2s 35us/step - loss: 0.8289 - acc: 0.7871 - val_loss: 0.8899 - val_acc: 0.7810\n",
      "Epoch 148/150\n",
      "57500/57500 [==============================] - 2s 36us/step - loss: 0.8299 - acc: 0.7851 - val_loss: 0.8603 - val_acc: 0.7710\n",
      "Epoch 149/150\n",
      "57500/57500 [==============================] - 2s 32us/step - loss: 0.8258 - acc: 0.7880 - val_loss: 0.8541 - val_acc: 0.7700\n",
      "Epoch 150/150\n",
      "57500/57500 [==============================] - 2s 34us/step - loss: 0.8276 - acc: 0.7859 - val_loss: 0.8654 - val_acc: 0.7710\n"
     ]
    }
   ],
   "source": [
    "random.seed(123)\n",
    "L1_model = models.Sequential()\n",
    "\n",
    "# Add the input and first hidden layer\n",
    "lambda_coeff = 0.005\n",
    "random.seed(123)\n",
    "L1_model = models.Sequential()\n",
    "\n",
    "# Add the input and first hidden layer\n",
    "L1_model.add(layers.Dense(50, activation='relu', input_shape=(2000,), kernel_regularizer=regularizers.l1(l=lambda_coeff)))\n",
    "\n",
    "# Add another hidden layer\n",
    "L1_model.add(layers.Dense(25, activation='relu', kernel_regularizer=regularizers.l1(l=lambda_coeff)))\n",
    "\n",
    "\n",
    "\n",
    "# Add an output layer\n",
    "L1_model.add(layers.Dense(7, activation='softmax'))\n",
    "\n",
    "# Compile the model\n",
    "L1_model.compile(optimizer='SGD', \n",
    "                 loss='categorical_crossentropy', \n",
    "                 metrics=['accuracy'])\n",
    "\n",
    "# Train the model \n",
    "L1_model_val = L1_model.fit(X_train_tokens, \n",
    "                            y_train_lb, \n",
    "                            epochs=150, \n",
    "                            batch_size=256, \n",
    "                            validation_data=(X_val_tokens, y_val_lb))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Plot the training as well as the validation accuracy for the L1 model: "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAtAAAAHwCAYAAACPE1g3AAAABHNCSVQICAgIfAhkiAAAAAlwSFlzAAALEgAACxIB0t1+/AAAADh0RVh0U29mdHdhcmUAbWF0cGxvdGxpYiB2ZXJzaW9uMy4xLjMsIGh0dHA6Ly9tYXRwbG90bGliLm9yZy+AADFEAAAgAElEQVR4nOydd3hUVfrHP2fSeyWQELp0CKGIKEgRRUGKIhbUta2irmVdV1dX3RVd1/Vn721VdBXBioIKFgQUEem9l0BCeu9lZs7vj/dO6iQkgUCI5/M882TmlnPPPfdO5nvf8xaltcZgMBgMBoPBYDA0DtvJ7oDBYDAYDAaDwXAqYQS0wWAwGAwGg8HQBIyANhgMBoPBYDAYmoAR0AaDwWAwGAwGQxMwAtpgMBgMBoPBYGgCRkAbDAaDwWAwGAxNwAhog+EURSnloZQqVEp1Pp7btnaUUh8opWZb78cqpbY3ZttmHKfNjFlrRym1Wyl1dgPrVyqlrjuBXTrhKKUeU0q9ewz7v6WUeuA4dsnV7ndKqauOd7sGw6mOEdAGwwnCEmOul1MpVVLtc5N/oLTWDq11oNb68PHctjkopU5XSm1QShUopXYppc5tiePURmu9XGvd/3i0VVuktfSYGarQWvfWWv8Mx0VInquUSqhn3Xil1HKlVL5Sal9zj9Ea0VrfqLV+/FjacDf2WusJWuu5x9Q5g6ENYgS0wXCCsMRYoNY6EDgMTKm2rM4PlFLK88T3stm8CiwEgoFJwJGT2x1DfSilbEqp3+v//iLgLeC+pu7Ymr+PSimPk90Hg+H3xu/1n6jB0OqwrD8fKaXmKaUKgKuVUmcqpVYrpXKVUilKqReVUl7W9p5KKa2U6mp9/sBav9iyBP+qlOrW1G2t9ROVUnuUUnlKqZeUUr8cZQrdDhzSwgGt9c6jnOtepdQF1T57K6WylVJxlsD7VCmVap33cqVU33raqWFtVEoNVUptss5pHuBTbV2EUuobpVSGUipHKbVIKdXRWvd/wJnA69aMwPNuxizUGrcMpVSCUurvSillrbtRKbVCKfWc1ecDSqkJDZz/Q9Y2BUqp7UqpqbXW32xZ8guUUtuUUoOs5V2UUl9YfchUSr1gLa9hOVRKnaaU0tU+r1RK/Usp9SsiIjtbfd5pHWO/UurGWn2Ybo1lvlJqn1JqglJqplLqt1rb3aeU+tTNOZ6nlNpY7fNypdSqap9XK6UmW++TlLjjTAb+BlxlXYf11ZrsppRaZfV3iVIqvL7xrQ+t9Wqt9QfAwaNt6xpDpdT1SqnDwHfW8pGq6ju5SSk1uto+PayxLlDi+vCa67rUvlern7ebYzf4HbDuw1escSgCzlY1XZsWq7ozXldb6162jpuvlFqrlDrLWu527FW1mRmrX/9USh1SSqUrpd5VSgXXGq9rrPYzlFL3N+7KGAynHkZAGwyti4uBD4EQ4CNEmP4ZiARGAhcANzew/5XAP4BwxMr9r6Zuq5SKAj4G7rWOexAYfpR+rwGecQm9RjAPmFnt80QgWWu9xfr8FdAT6ABsA94/WoNKKR/gS+Ad5Jy+BC6qtokN+C/QGegCVAAvAGit7wN+BW6xZgTucnOIVwF/oDtwDvBH4Jpq688CtgIRwHPA2w10dw9yPUOAfwMfKqXaW+cxE3gIuAqx6E8HspVYQL8G9gFdgU7IdWosfwBusNpMAtKAC63PNwEvKaXirD6chYzjX4FQYBxwCPgC6K2U6lmt3atxf31WAX2VUmFKKW+gDyKCA5RSAUA8sLL6Dlrrr4AngbnWdRhabfWVwLVAeyAAuLsJ534sjEb6fqFSqhMy0/Iwco/dD3yulIqwtp0H/ILcA48hY9NcjvYduBJ4BAhC7t1KtNYTq812XQGkAMus1b8BcVb/PwU+UUr5HGXsXdxondNYoAcQhvUdqsZZwGnA+cAjte4Vg6HNYAS0wdC6WKm1XqS1dmqtS7TWa7XWv2mt7VrrA8CbwJgG9v9Ua71Oa10BzEVESlO3nQxs0lp/aa17DsisrxHLsjUS+WH9upoIm1jbWlmND4GLlFK+1ucrrWVY5/6u1rpAa10KzAaGWqKrIUYCGnhJa12htZ4PVFpAtdYZWusF1rjmA4/T8FhWP0cv4DLgfqtfB5Bx+UO1zfZrrd/RWjuA94BYpVSku/a01h9rrVOsc/0QSACGWatvBJ7QWq+3LPp7tNaJiIU8ErhPa11knccvjem/xTta653W2Nit++yAdYwfgaWAK5Dvj8B/tdZLrT4maq13a61LgE+whKFSKh6IBr5xc45FyPifjTyAbUCE3pmIyNqhtc5tQv/f1lrv1VoXW31o6N4+njystS62zv0aYKHW+ltrXJYAm4ELlFLdgUHAbK11udb6J+SBp8k08juwQGv9q7Vtmbt2lFJ9kAehS7XWR6y239daZ2ut7YhgDkYEb2O4Cnhaa31Qa10APABcqWq6BM3WWpdqrTcA25ExMRjaHEZAGwyti8TqH5RSfZRSX1tTufnAo4iIqo/Uau+LgcBmbBtTvR9aa41YLOvjz8CLWutvgNuA7ywRfRbwg7sdtNa7gP2IVS8QEe0fQmX2iyeVuDjkIxZXaPi8Xf1Osvrr4pDrjWX5fEspddhq98dGtOkiCvCo3p71vmO1z7XHE+oZf6XUdUqpzdb0fC5i4XT1pRMyNrXpBCRYAr051L63JiulflPiOpMLTGhEH0AeDlxBr1cDH1kPWu5YgVgrR1vvlyMPLWOsz02hKff28aT6uHUBZrqumzVuI5B7LwbIsoS2u30bTSO/Aw22rZQKRazlf9daV3ed+ZsS96A8IAex5jf2exBD3e+AN9DOtUBrfbKuk8FwQjEC2mBoXehan99Apm9P01oHA/8EVAv3IQWIdX1QSilqCsXaeCKuJmitv0QCtH5AxNXzDezncuO4GLF4J1jLr0ECEc9BXBxc1rGjnXeNfltUT0H3N6AbMNway3NqbVt77KuTDjgQAVW97SYHS1qWyteAW4EIrXUosIuq80tEpsdrkwh0Ue4DxooQ9xIXHdxsU90n2g+Zvv8P0N7qw3eN6ANa65VWGyOR69eQe01tAb2Cowvohq7DCafWA1kiMEdrHVrtFaC1fgq5/yKqzaqAPIi4qHGNLJecCNzTmO9AveNk3SPzgSVa67erLR+HuL5cgrjmhAGF1do92tgnU/c7UA5kHGU/g6HNYQS0wdC6CQLygCIriKgh/+fjxVfAEKXUFOtH/s9UszC54RNgtlJqoDWVuwv5UfUDfBvYbx7i+zwLy/psEQSUAVmI4Ph3I/u9ErAppW5XEgB4KTCkVrvFQI7ls/rPWvunIf7NdbAsrJ8CjyulApUEXP4F+KCRfatOICJUMpDnkxsRC7SLt4C/KaUGK6Gn5Xv7KzImjyul/JVSfpaIBdgEjFFKdbIsj0cL3vJBLIcZgMMKIBtfbf3bwI1KqXFW4FisUqp3tfXvIw8BRVrr1Q0cZyXQHxgMrAe2IGJwGPBzPfukAV2tB7fmopRSvrVeyjoXX8Cr2jZeTWj3feBiJQGSHtb+45RSMVrr/YgP/MNKgmJHIT7mLnYBQUqp861jPmz1wx3N/Q64eMJqu7afeBDysJtprZ+NWKBdHG3s5wF3K6W6KqWCrH7N01o7m9g/g+GUxwhog6F181ckcKoAsUZ/1NIH1FqnAZcDzyI/4D0QX1a3fpbA/wH/Q6aLsxGr843Ij+3XyorSd3OcJGAdMgVePRhuDmLpSkZ8KFfV3dtte2WINfsmZGp6OhL05uJZxJqXZbW5uFYTz1M1Pf+sm0P8CXkwOIhYT9+zzrtJaAmUfBEJvExBxPNv1dbPQ8b0IyAf+BwIs3xWJwN9EUvoYWCGtdsSYAEi4NYg16KhPuQiDwALkGs2A3lwcq1fhYzji8gD3DJqWlP/BwzgKMGdlp/sFmCL5Xutrf7t01pn1bPbR4i4z1ZKrWmo/QboDJTUenVBLLolyPh0t97Xvg/qxZoluRgJvs1ArsFfqfotnYlY27MQgfwR1vdGa50D3IHcN0eQca/u7lCdZn0HqjETcaHKVVWZOC5HfNV/APYifvf5yD3o4mhj/19rm5+BA8j/pT83sW8GQ5tA1ZydMhgMhppY08HJwAxtFbsw/L6xgtnSgQFa66OmhPu9opT6DHFPaigbjsFgOAUxFmiDwVAHpdQFSqkQJanh/oFM+zbXGmhoe9wG/GLEc02UUsOVUt0sV5FJyIzBlye7XwaD4fjTaisrGQyGk8ooJLWdNzKFfFF9qbIMvy+UUklIDu1pJ7svrZAY4DMkx3IScJOuym1uMBjaEMaFw2AwGAwGg8FgaALGhcNgMBgMBoPBYGgCRkAbDAaDwWAwGAxN4JTzgY6MjNRdu3Y92d0wGAwGg8FgMLRx1q9fn6m1rlML4ZQT0F27dmXdunUnuxsGg8FgMBgMhjaOUuqQu+XGhcNgMBgMBoPBYGgCRkAbDAaDwWAwGAxNwAhog8FgMBgMBoOhCZxyPtDuqKioICkpidLS0pPdFUML4evrS2xsLF5eXie7KwaDwWAwGH7ntAkBnZSURFBQEF27dkUpdbK7YzjOaK3JysoiKSmJbt26nezuGAwGg8Fg+J3TJlw4SktLiYiIMOK5jaKUIiIiwswwGAwGg8FgaBW0qIBWSl2glNqtlNqnlLrfzfrOSqllSqmNSqktSqlJx3CsY+usoVVjrq/BYDAYDIbWQosJaKWUB/AKMBHoB8xUSvWrtdlDwMda68HAFcCrLdWfliQrK4v4+Hji4+Pp0KEDHTt2rPxcXl7eqDauv/56du/e3eA2r7zyCnPnzj0eXT7uPPTQQzz//PN1ll977bW0a9eO+Pj4k9Arg8FgMBgMhuNPS/pADwf2aa0PACil5gPTgB3VttFAsPU+BEhuwf60GBEREWzatAmA2bNnExgYyD333FNjG601WmtsNvfPLHPmzDnqcW677bZj7+wJ5oYbbuC2225j1qxZJ7srBoPBYDAYDMeFlnTh6AgkVvucZC2rzmzgaqVUEvANcIe7hpRSs5RS65RS6zIyMlqiry3Cvn37GDBgALfccgtDhgwhJSWFWbNmMWzYMPr378+jjz5aue2oUaPYtGkTdrud0NBQ7r//fgYNGsSZZ55Jeno6UNPKO2rUKO6//36GDx9O7969WbVqFQBFRUVccsklDBo0iJkzZzJs2LBKcV+dhx9+mNNPP72yf1prAPbs2cM555zDoEGDGDJkCAkJCQA8/vjjDBw4kEGDBvHggw82egzGjBlDeHh4s8bPYDAYDAaDoTXSkhZod06rutbnmcC7WutnlFJnAu8rpQZorZ01dtL6TeBNgGHDhtVuowaPLNrOjuT8Y+h2XfrFBPPwlP7N2nfHjh3MmTOH119/HYAnnniC8PBw7HY748aNY8aMGfTrV9OzJS8vjzFjxvDEE09w9913884773D//XVcyNFas2bNGhYuXMijjz7KkiVLeOmll+jQoQOfffYZmzdvZsiQIW779ec//5lHHnkErTVXXnklS5YsYeLEicycOZPZs2czZcoUSktLcTqdLFq0iMWLF7NmzRr8/PzIzs5u1lgYDAaDwWAwtAVa0gKdBHSq9jmWui4afwQ+BtBa/wr4ApEt2KcTTo8ePTj99NMrP8+bN48hQ4YwZMgQdu7cyY4dO+rs4+fnx8SJEwEYOnRopRW4NtOnT6+zzcqVK7niiisAGDRoEP37uxf+S5cuZfjw4QwaNIgVK1awfft2cnJyyMzMZMqUKYDkXvb39+eHH37ghhtuwM/PD8BYlA0Gg8FgMPyuaUkL9Fqgp1KqG3AECRK8stY2h4HxwLtKqb6IgD4mH43mWopbioCAgMr3e/fu5YUXXmDNmjWEhoZy9dVXu03N5u3tXfnew8MDu93utm0fH58627hcMRqiuLiY22+/nQ0bNtCxY0ceeuihyn64y3ahtTZZMAwGg8FgMBgsWswCrbW2A7cD3wI7kWwb25VSjyqlplqb/RW4SSm1GZgHXKcbowBPUfLz8wkKCiI4OJiUlBS+/fbb436MUaNG8fHHHwOwdetWtxbukpISbDYbkZGRFBQU8NlnnwEQFhZGZGQkixYtAiS/dnFxMRMmTODtt9+mpKQEwLhwGAwGg8Fg+F3TonmgtdbfaK17aa17aK3/bS37p9Z6ofV+h9Z6pNZ6kNY6Xmv9XUv252QzZMgQ+vXrx4ABA7jpppsYOXLkcT/GHXfcwZEjR4iLi+OZZ55hwIABhISE1NgmIiKCa6+9lgEDBnDxxRdzxhlnVK6bO3cuzzzzDHFxcYwaNYqMjAwmT57MBRdcwLBhw4iPj+e5555ze+zZs2cTGxtLbGwsXbt2BeDSSy/l7LPPZseOHcTGxvLuu+8e93M2GAwGg8FgOJGoU83gO2zYML1u3boay3bu3Enfvn1PUo9aF3a7Hbvdjq+vL3v37mXChAns3bsXT89Tv2q7uc4Gg8FgMBhOJEqp9VrrYbWXn/qqylCDwsJCxo8fj91uR2vNG2+80SbEs8FgMBgMhtZPhcOJh1LYbG07dsooqzZGaGgo69evP9ndMBgMBoPBcJLRWuPU4NHCYrak3MGy3el8vSWFpbvSAOgaEUCPdoF0bxdAuyAffL088PXywM/Lgx7tAujeLrBOO7tTC3h1+T4Ss4u5YEAHJsfFEBPq16J9by5GQBsMBoPBYDhlyS0uZ39GIQczi2kf7EN8p1CCfL1a7Hhaa3anFbBsVwZ70wroGx3M4M6hDOgYgq+XR7Pb/GVfFh+tS8Tfy4NhXcM4vWs4XSL8qXBotiTl8tvBbFYfyKKswklMqC/RoX7EhPrh42Ejs6iMrMJysgrLyCoql/dFZWQXleNpszGqZyTj+0Qxrk8U7YN93fah3O4kLb+U5NwS9qYXsietgD1pBSRml9AvJphRp0Uy8rRIerQLoLTCybbkPDYn5rLhcA7Ld2dQXO4gIsCbS4bE4uflwYHMIrYn57FkeyoOZ1134b7RwUyOi2ZyXDT5JXZeXraXb7enEeDtQdfIAB7/ZhePf7OL4d3CmToohhlDY5s9vi2B8YE2nDKY62wwGAynFlprjuSWsO1IHql5pcSE+tE5wp9OYf54eii2J+ez4VAO6xJy2JdRSLCvJxGBPkQGehPm740G7A4nFQ6N3emkuNxBcZmDonI7BaV2ErOLySoqr3FMpaBXVBCDO4fi6aFIzSslJa+U1LxSNBAe4E1EgDcRgd74e3vWqPoW7OdFv+hg+ncMpke7QLw8bOSVVLAvvZD96YVsSspl+a50kvMk9WtkoA+ZhWUAeHko+kUHM7hzGIM7hzKkcxixYX4czi5mbUIOaw9msy05j9gwP+I7hRHfKZRe7QP5fkca7/xykD1phYQHeOPUmtziCqt9bwrL7JRWSH25Ph2CCPbzIiWvhJTcUuzVhKm/twcRgd5EBMj4RQT4EBHoTX5pBct2ZXAkVzJpdYsMwMfThk0pbDawOzQZBWV1xjHQx5Oe7QOJCfVja1Ieh7OLAYgI8Ca3pKJSFEeH+DK2dxST46I5o1s4nh4181OU250UlFZQUuGgtMJBUZmDdYdy+HpLMhsO51ZuF+TryfUju3H9WV0JC/AmIbOIhZuT+XLTEdILylj30Ln4eJ54AV2fD7QR0IZTBnOdDQaDAUorHKTmldIp3P+Ypua11mw4nMun65NYsi2F2DB/Jg2M5sKB0XSO8AeguNzOtiP5bEnKJTWvlKJyB0VldnmV2ymyxGxRmdQiCPXzJtTfi1B/L0oqnGw7kkd2LWHmwsOmKkVY53B/+nQIorjcQWZhGZmF5eQWl2NTCg+bwtND4eVhw8/LgwAfDwJ8PAnw9qRTuB/dIwPpERVAl4gAknNL2HBIrKKbEnNRCqJD/IgO8aVDiC8KyLYstJlFZZSWO2r0Kbu4vFKsenvaCPb1qhTIAAHeHozqGcm43lGM7R1FhxBfMgrK2Hg4h42JuWw8nMPmxDxKKqRdXy9bZXshfl4M7BhCUk4xCVnFNY7bNzqYP47qxpRB0XjZbOzPKGRtQg4bDucQ6OPJiO4RnNEtnLCAqjoRDqcI3wqHs/JhoKFrvSetkKW70tialIfDKa4dTq2xKWgX5EuHYF/aB/vQIcSXnu2DiAnxrVED4nBWMb/sz2T9oRyiQ3wZFBtKXKcQooLcW7QbQ1JOMUu2pQJw2emdCHYzc6C1JjW/lOiQk+PKYQS04ZTHXGeDwdDacDo1O1Ly6RTmT4h/3R//4nI7S7alkl1UToifF8F+XoT4eVVaGXOKy8ktrsDXy4MBMcH07xhCoE+VENJak1VUzp60Albvz2L1gWw2JeZS7nDi62Wjb3QwA2JCOC0qEKfWlFY4KbM7Kv+W2Z2UVjiocGh8PG34e3vg5y1WvO+3p3Egswg/Lw/G940iMbuYzUl5APSPCcapYU9aQaXIFfHqSaCPB/7engT6eBLg44G/jyeB3p5o5JxySyrIK65AKRjYMYS4TqHEdQwhOtSXlNxSEnOKOZxdTGGpnbjYEIZ0DiOqHreCE43d4eRgZhHbk/PZnpxHbnEFPaICOa1dIKdFBTbqocXucLI7rYCNh3PZm1ZAz/ZBnN41nJ5RgZWBddlF5WxOzGVHSj5DOocxonu4KVjWSjECugUZO3Ysf//73zn//PMrlz3//PPs2bOHV199td79AgMDKSwsJDk5mTvvvJNPP/3UbdtPP/00w4bVuXY1jjVr1iz8/cViMGnSJD788ENCQ0OP4ayOP8uXL+fpp5/mq6++qrH85Zdf5vnnn2f//v1kZGQQGem+mvvJvs4Gg6FtUlrhwGn9FmotU9qZRWWk55eRUVhGXnE50SF+9IgKpFOYH54eNvakFbBg4xG+3HiE5LxSvDwUY3pFMS0+hnP7tudgZhHz1hzmi41HKChzX03WHUpB98gAIgN9SM0X14Nyu1gwbZYgHdE9gm6RAexJK2Rbch47kvMprHUMbw8bPp42fLw88PG04e1po6zCQXGFuECUO5wM7xbOjKGxTBoYXSnaE7OLWbwthe93pOHr5UF8p1DiO4USFxtKuyCf4zTiht8t5UXw8bUQ0A4ufu1k96ZRmDR2LcjMmTOZP39+DQE9f/58nnrqqUbtHxMT41Y8N5bnn3+eq6++ulJAf/PNN81u62QwcuRIJk+ezNixY092VwwGwymE0ynBXHvSCkjKKSEpp5iknBLK7U6iQ6qCrML9vXFojdOpsTs1haUV7MsoZF96IfvSi2pM0R8NLw9FZKAPKXmleNgUZ/eM5K5ze7EnrYBFW5L5YWca3h42yh1OvD1tTB4YzcwzOtOrfRD5JRXkWS+lIMxf/HxD/b0oKLWz7UgeW5Ly2Hokj9zicgZ2DOH8/h2ICfGlS2QAQ7uEuZ3idjpF8HvZbPh6eeDtaTuqldTh1G636RTuz6zRPZg1ukejx8RwClOYDps+hLPuAFsL+xdXlMCHl0PCz/J54CVw2rkte8wWxAjo48CMGTN46KGHKCsrw8fHh4SEBJKTkxk1ahSFhYVMmzaNnJwcKioqeOyxx5g2bVqN/RMSEpg8eTLbtm2jpKSE66+/nh07dtC3b9/K8tkAt956K2vXrqWkpIQZM2bwyCOP8OKLL5KcnMy4ceOIjIxk2bJldO3alXXr1hEZGcmzzz7LO++8A8CNN97IXXfdRUJCAhMnTmTUqFGsWrWKjh078uWXX+LnV9O/aNGiRTz22GOUl5cTERHB3Llzad++PYWFhdxxxx2sW7cOpRQPP/wwl1xyCUuWLOGBBx7A4XAQGRnJ0qVLGzV+gwcPPsYrYDAYWjMugZeSW0pafikOp0ZmqxVKSZCRy9WgtMJBSl4ph7KKOZRVxOHsYoJ8vegXE0y/6GD6RgeRV1LBr/uzWH0gixwr2AokuCk2zA9vTxvrDuWQuiWlRpBVdYJ8PTktKpBz+rSjc7g/nh62ymAyD5uI5KggH9oF+RDi50VSbgkHMorYn1FIYnYxw7qEMXlQDJGBVVbZv0/qy5qD2Xy7PZVO4f5cMqQjof5VPqshfl50qmeMfL08GGdlSWgqNptqsh9qS6c1M5wifPcQbPkIYodB11Etdxx7Gcy/ChJWwtSXYeWzsOTvcOsY8Gi5jCktSdsT0Ivvh9Stx7fNDgNh4hP1ro6IiGD48OEsWbKEadOmMX/+fC6//HKUUvj6+rJgwQKCg4PJzMxkxIgRTJ06tV5fp9deew1/f3+2bNnCli1bGDJkSOW6f//734SHh+NwOBg/fjxbtmzhzjvv5Nlnn2XZsmV1XB/Wr1/PnDlz+O2339Bac8YZZzBmzBjCwsLYu3cv8+bN47///S+XXXYZn332GVdffXWN/UeNGsXq1atRSvHWW2/x5JNP8swzz/Cvf/2LkJAQtm6Vcc7JySEjI4ObbrqJn376iW7dupGdnd3c0TYYDK0QrTXZReUczi4mMaeExOxiDmcVk1lYhpeHDR8vG76eHthsioLSKktrdlE56flllDucjT6Wr5eNLuEBdI0MYHSvduQWV7AjJZ+39x+gwiGCuGOoH+f0ac9ZPSIY1CmEjqH+lb69LhxOTWZhGbnFFXjYwKYUnjYbvt422gX6NMnnNCrYlyGdwxrcxsOmOLNHBGf2iGh0uwZDk0haB54+okuOlbTtsOVjeX9gxbEL6KJMSN8BGbvBJwii+kJkb1A2cdvYvxSmvgRD/gABkTDvCljzXzjzT8d+LieBtiegTxIuNw6XgHZZfbXWPPDAA/z000/YbDaOHDlCWloaHTp0cNvOTz/9xJ133glAXFwccXFxles+/vhj3nzzTex2OykpKezYsaPG+tqsXLmSiy++mICAAACmT5/Ozz//zNSpU+nWrRvx8fEADB06lISEhDr7JyUlcfnll5OSkkJ5eTndunUD4IcffmD+/PmV24WFhbFo0SJGjx5duU14eHhjh85gMLQg5XYnu1Lz2ZyYy6bEPPJKynFZfm0KlPVe1XivUMiyojIHSVbQV3GtjAXtgsRKa3doSu0Oyiqc2J1OgnwlUC7M35tukQF0CPElplomBE+bpLnSaLQGH09xPXD57Ab7eroVt+V2J/szCiuzLxxNAHvYFO2DfevNe2swnFIUpMH/LvaYRt0AACAASURBVJL3N34vAvVYWPov8A2GoBg4sBzOebDpbTid8NkfxS2jKKPuemUD/0goSodJT8OQa2R5rwugx3hY/gTEXSaC+hSj7QnoBizFLclFF13E3XffzYYNGygpKam0HM+dO5eMjAzWr1+Pl5cXXbt2pbS0tMG23P0oHDx4kKeffpq1a9cSFhbGddddd9R2GgoQ9fGpmnb08PCo4Sri4o477uDuu+9m6tSpLF++nNmzZ1e2W7uP7pYZDIbm4XBqknNLSM4tITzAmw4hvjUKQ5TZHWQUlJGWX8ru1EJ2peazMyWf3amSMcFV8cvb08aR3JLKILTIQG+ignzRVP1/0FYqK9cybS1zvffxtNE53J8ze0TQKcyfzuH+dI7wJzbMr8G0WS2Bt6dknTAYfpcsfQTspeAXKr7ENy2DgGbOdhz+DfYshvH/hPJiWPkclOaLoG4KR9bD9s9FEHcbLaK+XV8oyxdrdPpOyNgFPSfA4Gqz3ErBBf+B186CH/8FU15o3nmcRNqegD5JBAYGMnbsWG644QZmzpxZuTwvL4+oqCi8vLxYtmwZhw4darCd0aNHM3fuXMaNG8e2bdvYsmULAPn5+QQEBBASEkJaWhqLFy+uDLoLCgqioKCgjgvH6NGjue6667j//vvRWrNgwQLef//9Rp9TXl4eHTt2BOC9996rXD5hwoTKzBkgLhxnnnkmt912GwcPHqx04TBWaMPvEYdTk1tcTk5xOdlFFWQXlZFdJOnK8ksqsDs1DqcUhbA7dLXPmuIyO4cs14jaLg+BPp5EBnqTV1JRw+/Xta5PhyCmxsfg6+lhFSxwUmp3cG7fKOI7hVluDke32hoMhlbIkfWwaS6M/DP0nQpzJsHH18AfFoCn5WdvL4MN/5NgvbPugPq+61rD0kchIArOuEXa/vlpOPQL9J7YtH7t/gaUB1z8OvhVd3GKhna9of/F9e/brjcMnwWrX4NhN0D0oPq3ddjBo3VJ1tbVm1OcmTNnMn369BruDVdddRVTpkxh2LBhxMfH06dPnwbbuPXWW7n++uuJi4sjPj6e4cOHAzBo0CAGDx5M//796d69OyNHjqzcZ9asWUycOJHo6GiWLVtWuXzIkCFcd911lW3ceOONDB482K27hjtmz57NpZdeSseOHRkxYgQHDx4E4KGHHuK2225jwIABeHh48PDDDzN9+nTefPNNpk+fjtPpJCoqiu+//75Om0uXLiU2Nrby8yeffMLatWt58sknSU1NJS4ujkmTJvHWW281qo8GQ0uTll/KuoQc1h/K4UhuMTnFFZZArqDc7sTDpqxiD+JikFtSQX2TP96eNrw9JEOCp1UcwtNW9dnHy4Me7QIY3zeK7pEBRIf4kVNcTmpeKan5pWQWlhPi50lUkC9RQT60D/alR7tAYsP8KvPLGgxtlvxkCIquXxi2VZxOWHyfCN6z7xEr8bRX4PMb4Zt74MJnRFyveAryk2Qfm2f9vsX7l8KhleJS4R0AscPB00/cOGoL6JwE+OASuOQtiHET8L97MXQ5q5Z4bgJj7pMgxv9Ng45DxYId1U/6lb6ryopdlA5/O9iqrr3JA204ZTDX2XA8yS0ux8fTo0bgmdOp2ZNeUCmY1yZkk5Qj7k0uV4awAG/C/MW/18fThkNrHE7Z18tTER7gQ0SAN2EB3oT7exMW4EVEgA+h/l74ep34MrQGQ5vgwAoRWRP+JdbV5rDvB/ANg9ihzds/55CIzKHXNm//5rJ5Piy4Gaa9CoOvqlq+9FH4+RkR1kXp0HGY+DGvewd2fQ1Xfgw9z6vZltMJb46B0jy4fV2V9fr9iyE/BW5bXXP7bx+EX1+GQTPFylyd7APw4mC44AkYcWvzz+/walg3pyoA0eFKK6kgrCu07y/C+ux7wOvExzOYPNAGg6FNkppXyg8701iXkC3W4ZIK8orLKbM7GdAxhDO6hTOiewS92gex9UguP+5K58ddGexMyQekNG9kkA+h/t4cyCikoFQKUkQG+jCsSxjXndWVoV3C6B8Tgren7WSequH3gsMuIsI74GT3pPk4nZC8scqCmL4DvPzh8g/A1sTvkdbi/4uG5f8HAy+DoPZN78/ns0SQ3fRj0/Z18c09sPc7sZR2GNC8NppKWSF8/7Acc9DMmuvGPQR5SZC1D6a9LH7GSkGnM+Dt8+HTG+DGH8RVAqA4G1b8H6RugYvfrBLPAN3GwA8PQ0EqBFlJDsqLYeMHEgi4/QuY+H/gG1K1z+7F8rfXBcd2jp1HyAvk3s9JgPICiOzVqr8DRkAbDIZWhdaalfsy2Z1aQIxVCKNjqB9Bvp5kFJSRXlBKWn4Zu1MLWLorjW1HRAh3CPalfbAPIf7edA73x0PBxsRcvt+RBkjGCaeWzAxDu4Rx7/m9UQoyC8rJLCwju6icyXExDOsSxrCuYXQO9zf+woajo7VYNjud0fQALHckbxJrY0muiJ/Q+jJHV6O8CPZ+D/2mtZ4p7u//IZZLEPeAoA6QcxCS1kLnM5rW1q6vxE931F9g1ctieb3olaa1kbYNirOgJEfG1q+JlXpTNot4BtgyHzo8Vncbe7ncCz0nNM5ft6IUdnwJJQ2kfU38DQpT4Yq5dR88bDaY/mbdfbwDYOY8+O85Emx4zZdixf71ZSgrgPirYeCMmvt0Hyt/D6yAQZfL++2fQ2kuTHhM8kVv/RRO/2PVPrsXi7tFeLejn2tj8fCEyNOOX3stiBHQBoOhVWB3OPl6awpvrDjADss63BBKwZDOYfztgt6c17c9p0UFuhW8KXklrDmYzY7kfAZ0DGF0z3aE+J+aifsNrZAfH5MArBF/kqwC9aF1w+LWYZdMCCuekDLHFcUwfybc8O3RrXArnoRfnhfrbt8pjeu30wHO6uW/VU2L5LFQUQob34deE+H8f4vVt7wInuoBOxc2TUA7HZJuLbKXWFydDlj1Ipx+g1hlG8uB5fJXO6WYR9/JTTkj+Olp8AmB6DgRkuc+Urdy3+pXxYo7fBZMaqASsaNCLLs/PQX5R45+7OGzpNBJUwjtJKL73QvhBSvdbZ/JMO5BaN+v7vYd4sSP+WA1Ab32LcmocebtsGmeXFOXgC7OhkOrYNRdTetXG6LNCGiTRq1tc6r56v9e0VqTW1xBYk4xeSUVFJU5KC63U1TuoLjMTnF51We7w4lNqcqKdCv3ZZCYXUKPdgE8OSOOc/pEkZ5fxpHcEo7kFFNU7qjMOxwV5EvHUL9GCeHoED+mxXdkWnzHFj//3z27voZP/wjdzoYBl0DvScfHKttaWfGUiGcvf9i5CM5/vK5I1hreniCipb5UXVn74fObxMo6YAZc+LQUzPjwMrFGX/q/+t0eirNF6IAIsj6Tj26Fztgtwqp23t7z/1N/4FnmPhHcUQ0HwgOw91vxsR1+E0RYJcF9g8XKuXOhWDQb+3u9eT5k7oZL3xPr5Oh7Zdni++CG7xrvDnJwBYR3l1zKB1c0TUCn75R+j74X2g+AT66VNnqcU7WNvRx+ewO8AmDNm9CuT01rLci9sOVjWP64uCnEni6uF+6C8ypRTbeWu+g0XIL/tn8BI+9s+Dg2m6ShO7Bc+nlkg7jgTHraslZcA0vug9Rt4r6y93vQDuh9YfP61gZoEwLa19eXrKwsIiIijIhug2itycrKwtfXFENoTbgC7lbvz2JtQg4HMotIzC6msMze4H7+3h74e3vgabNVFtJwaugeGcA/LuzHuX3bV2aUiAz0oV9MGxZgbYmSHPjqLxAYJYJjwc3g6SsievJzzRcBLYHTIQLG5Z9rLxP3AJ/Axrfxy4uw7DGIu0IquC28XQRHxyE1t0veCElr5NVnCvQ8t+b6klwpjlGWDzPekQcPkOCvCY/Btw/A8v/UX+TitzegvBBG3AarX7FcCM5zvy2IdfjTG8QSe84/qoTs7sVi/Y6fWTejQlEWvHWOiOKofjBguvQzvLv7Y2z+CAI7VLkFuOg7VdwgUjZDTHzNdYXp4mIQd0WVhdReJuceHS/uKSBC/NyH4cvbYOvHMOiK+s/Vhb1crKWDr4bsg1XW6NokrJT7Ydgfawrzn58VYXzGrTIb4BMi51hdQO/4AgqSYeZ8WPs2LP4bRPYUUQqSQeTL2yUDRoeBVoDfhJZ3uek3rWrsjkb3seJSkrVPHsq8AyHOskbHXSZuORvfF1/o3d9AYPujiP+2TZsQ0LGxsSQlJZGR4aYKjqFN4OvrWyP9naHlKCl3sDkpF6dTZnVcvsMZhWWk5JaQkldKUk4x6w7lkGvlI+4Y6kfvDkGc0S2cTuH+dArzIzzAG39vTwJ8PPD39sTf2wM/Lw+Tbq2t8t1DUsp31jJoP1B8Xbd9KqV6I3vCuAca1072AbG+VhZh2A1Drzt+U8VbP4WFd4iLRCVKfE2v+gS8/Brev7xIMgZ8/w/oP13SiZXlw1d3iZWytoDe8hF4eENIJ9nmT79KmWMQS99Xf5Fp/Bu+hU6n19x3xJ9kHH56UgLBavutlubDb6+J1fnc2XL8FU/CaefWL8y+/6f4A1/5CfSaULW85wR4fZQ8GJz7cM19lj0mwWzjHhKB/uNj8hp6PUx5vua2xdkiks+4ua6LQ+9JkjN456K6AnrZ47B+jhx/4AwY+3excuYlwtQXa57PoCtFpH7/sKRdqx7Y5o6ktXK9u4+F0C7w3YMiaINjqrbRGhb9WcTjoVVw0WuS8SFrv9zHZ95WVbSk/zTY+hmUPyuCWmtY9ZKUre55vqR1e+s8ydN841J5iPr6bhHyk56uK9BbC93Hyt/tC2DbZ/LA4ZpB8g+X+2zzfHED2bdUHqRa43mcINqEgPby8qosIW0wGJpOmd3Bit0ZLNqSwtKdaXVKNlcn0MeT6BBfzu3bnhHdIypF8++OAyvA06cqevz3zIHl4tM58q6qYgidz5BXbqJYs0b9pWFx6qgQF4SfnpapYZun+L16eEu530FXVGUHaC75ySJYXdPrUX1F9Oz6Wizm86+S4CvPqkqt5B2BDe9B6lYRszkJsrzPZAng8vAUcdH1bNixEMY/XCX2HBUi2HtdIALsnQvEn3fSk7J+4wcSqDX+n3XFM0g7Fz4HWQfgiz/JcapbPde+JVbhs/8q/ssj/yyZIhJ+rrJ8Vmf3Yljzhgjz6uIZxCo6YAb89roU13BluUjdCuvfFT/cMffKKzdRRP36OSKiqh9r22fgrHBvGQ6IgK4jReiP/0fNMd40V6zPQR3Eqr7tc5nB6Ho2dB9Xsx2bDSY+CW+fB8/2hz4XikW8xzjwcOPWdWC5ZJLoOgpCO1vLVoi13cXhX0U89xgv1yT/CFzxofil27zgzGqp8+KukIIlu74Wy2zCSslsMeUF6ZtvCFw5X4L43hwrD1ixp8PFb1S5tLRGwrpBSGf5DjrK4PQba64f8gcZmyV/lywZvSednH62EtqEgDYYDI2jpNxBQlYRCZlFHHT9zSxiZ0oBhWV2wvy9mBbfkQn92uPv7YFTV/mftwvyqVNS+ndLQSrMv1KmOO/aevyCr6rjdIr1zZUCLH2nfO53kVhkm5MP1WFVMHQnMnITYaVlUZvgJsNAfZQXwcI7IbwHjL2/7vqzbhd/2y0fSb/dkb4LFsySqf1BM+GsOyHiNBnX7IPw8jCxrE5+tvH9qo3W8PVfZQxmvF3T/WDQ5SIYFt4BH18Ll/1Psg+sfE4snc4KEfMxgyH+KslL23NCzXHsO0WsjOk7q1wQ9v8IxZkiJjuPEEGy5k2xsPqGyjR/t9Hy4FEfnt4SDPbeFJh3JVz9qQjB8mL49RWxNrus3oP/YD2EPFVXQOcniwjvMFCs1e4Y94C4Ivz0lPhhaw2L75e+Vr+2oZ1EwO5fLutv/qkq68SWjyCqvxzHHX2nishP31XlT73qJXEpGfcAhHURgb/yOenLeY+6t6Z3Oh1uWCLCe8dCyYzhFwYXvQ69a6VVO7AcYoaIsI3qD/6Rsqy6gN7wPngHweXvi+V7wc0igPOPSJW86mnzOp8pQnPzfBHQv74sbbrcHUDur8vel9R5I++EkX9pdZX06qAUdB8jbhpdRtYNNuw2Vs570wfi9999zEnpZmuhlV9Ng8HQFLTWJGaXsDe9gNT8UlLzSknJK+VITgkJWUWk5JXW2D4y0Idukf5MjY9hQr/2jDwtEi+P3++UXKP5Ybb4nZYXikWmMX6YR6MkV8RH2jZI2wEZu6R9F8EdRcgsuU8Ex5h7Rcy5E8O1KSsUy+MvL8rnflPF/aDr2SLwfn5WrImOclnfZ7J7y3phBhxYJuK2XW8R28seh9xDcN037i3MXUaKVfrXV2DwNTWnfLUWa+P3/xT/48vel75VJ7ybCO/174oYr8/v9mhsXyB+m+f9y30bQ64Rn9tv7oF3zpfxt5eKu8CYv4mwa4g+k0Wg71xYJTw2zwe/cDjN8kk+92GxAn95uwhjLz/Jx1vb1aE2/uHwhy/kQeTDy6V885H1cu1G31u1nZevPHx89yAc/q0q20VBmgg5eynMmFPTwl6diB4yDq6xTt4oFesufLauX7SXnxQ1+eRa2PCuPBxk7Rd3ifMebXicvrlH3Dii+ojv8/o5YtV1jXFQe5j4hLwawpU/eNIz8rDyw8PSdo9xVedYml+VAg+qguUOrqjKjFKaL2J94KVyT/e/SL5v864AlIxpdWw2Ec4rn4WDP8OeJTDm/rr3f7ez4a87Gz6H1kaPcTWzbVTHZpNCLsv/IzMhR3N3auO0iUqEBsPvBa01yXmlZBSUUW53ysvh4GBmMesPZbM2IYeMgrLK7W0KooJ8iQ71pVtEAN0iA+gaKX+7RPi3XWty4lqZdj/noWOf9q9N0jp4a7xMl+/5VqZ3b/n52IKB9i+ToKj8IyK4XJW3XGVt2/WRIDyt5Yf/x8dEqIR1FdEZHee+3YpSWPe2COTiTPHP9AuVqefyQkmXVlYownnw1VLh7d3JIlqvX1zznLSG/02Fgz9ZC6wqYbmHYMi1dX1hq7PlEyk7XNvvds1/RfD0ugCmvFh/cYyCVHghXjInXPJWEwbWojgbXhkOIbHwxx8atgT++gp89w/of7H44TYlJ+07F4gY+9Mq+ft0TxnXC5+p2mbv9zDX8mW+8mPodX7j2y9IhTkTxdfc00fui+u+qrlNeRE8N0AeWvpfLP67CSvFwnvRaxB/ZcPHyE+R6nK9zhfh6RsKN69wL/K1Fst42ja4Y4O4f6x4Eu7eUdO/uDZvTxCf5FtWysPTqpfgtrXHnv93/zJ4/6KalfF2LxYhfO1XImgB1r8Hi+6E29bIg+C6OeKffuPSmuni8lMkMNBdurzMvTIz4h8h36G/bIfAdsfW/9aA0yH+zT3Pc/8/LS8JXjlDfP/7X3Ti+3cSMJUIDYZTkNIKBxsP57LhcA4bD+eyKTGXzMIyt9vGhvkxskeEVM3rGEJMiB+Rgd54NtWinLQePr0OJj8Pp40/9pNwR94RsZwGRh3fdu3lUmlr5bMiGNJ3wHVfHz9LidMp0+6BHcTyF3GaTPsf/KnudOa3D4rYverT+kV8ebFYs9e8ARE9RdzFDqtfjCslgT7dxkig1sI7Zap51oq6biSl+fDWuZICrPtYCQBz+dlWlMj+2xeIG8qov1T5Zo65Vyype7+vKXY3fiDnOf6f4s6QtkPGN7IXnPdIw+PW/yIRSr++VNXm/h8lFVmviVaRiAassEEdYMQtsPJ5cXdoahW4bx+QLCF/+OLo0+hn3iZBXs1xkek7Fb79u1hiD/8qFt+4WrMTPc8TYe4d0DTxDDIO1y4SEZ172P3DhHeAnMOP/6qaLRh9r/gIuyrSNURwtAQA/mI9EF38Rv3XRikRq2+cLTMR+76X70FD4hlknL57UAT62rdlNuR4FM/oMU6+Gz89LQ8uPkFWrIKfpHRz0X2s/D2wXMZk4/vyoFpbKAdHy8sdkT3FLSR5g1jt24J4BrnWtf3jqxMSC3872DJua6cYxgJtMJwktNYs253Oh78l4uWhKivudQjxZW9aIb8eyGTD4VzK7U5A0rzFdwolvnMosWF+eHt44O1pw9vTRnSIL+2Dj1Oav89vFn9CTz/JSuCy2hwvClLhtZEicK/4ELqceXzaTd8p09SpW8S1oevZ8MUtMi07/b/HJ13UpnnS5kWvi/9kRSk8P0B+SK/6uGq7HV9KBD5IkNp1X9f9gU1aL+I3a68EbY1/GLybGIzpsq6NfQDG3ldz3eezYOsnMsa9Jza+TUcFvHy6COubf5Jp24JUseC2HyCWvOZE3q98XqbYb/5Z/CffOkemyf/4XVVWioYoyYEXBon/6ZUfybLcRBlrTx8RTLUflJxO8ddceAecfU/NwLWWIDdR7odzZ4sVLz8Z7lh//FOV5R2BxNUiPN21XVEiQW6dR0iBjKYevyQHXhomgrQxFv+v/1qVi9r13WiInAS5liGdxK//1l/dF/doDknr5d5yfSdeGSEi+A8Lam73wiDxhz7nQXjtrIZzYNfHunfgm3vhll8alx/bcEpiLNAGQyvBVXHvteX72ZVaQPtgHwJ8PFm2O53SChHLSkG/6GCuGdGFEd0jGNY1jFD/Zj7xb/pQMgFMe/nolqHyIvFN7DsVMvdU+Vs2tfRufTidIhrLi+RH7X9TZVq5dnqupnLwZ/jgEhFil8+tKpKQf0QscVF9JVOBC60lXVqNVGZuCIqGgEh5X1YgArDj0KpgIS9fOP0mKYyQsVusWbmJItg6DpU8u/NmyrTytYvEl7V6tomgDmIV7TGu/j40RO+JYln86SnJ9er6Ed88X/ypxz3YNPEMMjMw7kFxudj+uVybb+6Vh4UpLzY/bdXQ62R6f8X/iX+xzVNy5jZGPIP44I68C5Y+Ilb7Q6sk9ZyLn5+B0feIn7WHl7jXLHtMskjEDKnpK9xShHaSQMP174lIHPv3lsnzG9IRQi6pf72Xn1iRm4tfmAj/xl6bcQ/K/xhHeeMqIYZ1FReTlM3iE328xDNA7FBpc9VL0peMne4Fffexkulj3Rxxw6oeANhYhl4v7kdH+79qaJMYC7TB0ELYHU72ZxSxMyVfqunllpCcW8Lu1AJS8ko5LSqQW8b0YFp8DF4eNrTWZBeVk5JXSmyYX/MFc41OlMHzA6EwDYJixEpaX3Q8SHGABbPE/zW8O8yZJNXKrvmiaWVz68NlhZzygoj0j66GQ7+Ir/LZ94hfbvoucQ2wl4qPZ1S/hqdHnU54c4xkTbjxx5rbai0V3rZ+IsK6XW9Js7XtM3lAaAwBUSLAtVPSg9X2kyzKhGf7yY/0pGck0CttO9zyk4zh/mXyIBLVV8r7fnOPCIe4K6QgwbEWGCnMgFdOl6n6G74V4fbGaBEo1y46eoCaO5xOmZavKJZr8+kNYiE/++5j6+vi+8RP1uYF1y6UfLlNobxY/HMLU8V6OGC6vPKOiF944mrJEhDYTtwDwrqJiB04o3nj0Bx+flZEPsCdm8Sf/PfAvqXiax53aeO2X/mcPAjNWn78i3Gk74LXzpTvX9Y+cXGqnXd62+fw6fXyINdnMlz23vHtg6HNUJ8F2ghog+E44HBq9qUXsvVIHtuO5LH1SB47kvMpqajKpxwR4E10qC+xof5cNFhSxbV4UZFNH8IXt8KEf8PqVyVn7Iw59fu4vX+x/ODcuVksjXlHxN+yNBeu+sx9rtrGkrQe3pkgP1aXviuWOXuZ+PFumS9CtSjd/b7+kZKua9rLdbNOuH4IL37DfTaMihIRtckbRQSjJDNE/4saDjDUTrEmu9LIZeyW9t2lUlt4p1h8B/8B1v4Xpr9VU0js+VZyDDsrJEhwyvONrw7WGDbPF8v+ef+Sh4PcQzKtHHIM5ct3L4F5l4vAiOoLNy1rXMaPhsg5JEFnY+8/ejBbvW0kyH1T259Xa6nytuw/UJwlhVcam6XkeJK5D14eCp1GwB+/PbHHPpWwl8lMhCtv+PFmwa2w+UOxpt97oO7MSVEWPGVlY7n6M/n/YjC4wQhog+E4UGZ3sDetkISsIg5lFXMoq4j9GUU1xLK/twf9Y4IZ0DGEuNgQ+seE0CnMHz/vE2QBc6G1+Bqj4dZV4sf64WUSMT/pqbpJ8gtS4VnL1eGch6qW5xwSV4uCVBGpzYm8Ls0Xi6bTKRkrqltdtYbVr4nFMKqPWBaj+oqfbMZOEbDJG0Wgnv1XCWJz4bDDq2dIsY1bVtZvZSxIlcwKMYOtFFXNmHJ1pbxyR8Zu8REGSXt28Wt1t9nzraRRG/tA/dkmmovWktlh3w/yuboby7G0+c75knXkph/rWvCOpd2WLl98sln6qBXs6aaYieHEkHMIXhoqRVbqsy6/MVqE9F1bTtwMheGUwwhog6EZlNkdbDqcy+oD2aw+kMWGwzmUWUF9UJVHeUDHEAZar+7tAvFoDeWqXSmdpr0iAVYg6ZY+uxH2LK6bUmzVS1KO+fb1dSPiizKlcEjib3DuI5LCrXaKs7wkq+CHZa2t7l+ckwCp28Q1pLn+1F/eLpkgrvmyKuOFKx3VFfOgz0muivXJdTJ1fOP3jfcdPZ7kHhZBEHfF0fPnNpbCdLl21TMYGAynCodXS6BqaCf36zN2g9MuaSMNhnowAtpgOAp2h5P8Ujt70wrqCGZXUN+I7pImrltkAJ3D/QnwacVxuB9cAilb4C/bahZOqCiV9GYFKXDrL1VuDK+NktREN/3ovr2KUnEH2f65CPL2A6sq5KXvlNKuLoKipepXJQrOmCUVvZpLeRG8MUaC+W5dJRkrXhxi5fb97uRbNR12+Xsyq41VlDYv/ZrBYDAY3GKycBgM1UjKKebHXeks3ZnO/oxC8koqKCi1V653CearrSwYw7uGE+LfioqOOB1iGXSJ1/Buko3BJSLTd8p0/riH6lYd8/KFGe9I4N2Cm+HqBeIqkbYVJj5V/zG9fOGSt+VYP1uFIfzCxOVi0BVVRT+i+tStWnY88A6Qfr81Hr78k/gxFyTD9DdPvniG1lGm14hng8FgfDDyewAAIABJREFUOCG0gv/4BkPLU1LuYN2hbH7Zl8Xy3ensShVrabfIAIZ1kRRxof5ehPh5ERvmX79gdjrF0lrDutoE0ndJFoax90PXUe63KSsAlJQ2rk5RppSb3WaV8bWX1Fy/9ZOqam6rX5U8zvVZfNv1kgIIi+6EVS9I9LzNU0R4Q9hs4oMcf5XkCQ6MOrHiNTpOAuWW3CcPCD3GH/881QaDwWAwHAUjoA1tirziChJziknJKyU1r4QjuaVWFb8cKhwaT5tiaJcwHpzUl/F9o+jeLvDojVZn8d+sEtH/kGpfTQk8ydwnwXiFaTB/q7hKuKq/uUj4BeZeChVFENrFKuPcS3LZHlgB2iGp3YbdILlTo/pKJbgN70tKqFdHSBGHzR/B4KsgIKL+/gy5RqrB/fiY+Oyedl7D21endr9PJGfcLP3e+23LF8YwGAwGg8ENxgfacMridGo2HM5hw+EcNiflsSUpl8TsmlZZT5uib3QwZ50WwVk9IhnWJaz5fssJKyUdWkhnyDsMnc+SbAthXY++b/ZByansKIeLXhXXiYB2cOMPVdbsxLUS9BccI9XzXO4ZWXvFz3fAJfKK6ufe6pu+S9pN2SSfb18n5WYboiQXXj9bzufSd6H/xU0ZkZNHRYmk22sop7XBYDAYDMeICSI0tBkOZxXz6YYkPlufxJFcEcwdQ/0Y1CmEgR1D6RYZQHSIL9GhvkQG+DScazkvCZTt6GnNKkokJZzTDn/6VcoHL75PcgWP+ZtEervw8BbhGnGa5KDNTYR3J4lrxrVfQYcBUjnv/Ysk1dXMj8T/+L1pYgG+7hup0ufCYRdLd2NcJRwV8MsLkhVjTCMrrx3ZIMUtprxofGgNBoPBYKiGEdCGU5IKh5P9GYXsTMlnZ0oBGw/nsDYhB6Vg1GmRzBgay8jTIokM9Dl6Y7UpK4SXTxcRfOsvVSWb3fHDbKmcVb3scu5h+OJPUp3OHTYvEdIluZJB4tova1bcWjcHvroLBsyQAhDeQXD9N/WnXDIYDAaDwXBCMVk4DKcMTqdm1f4sPlqXyHfbUyvzLnt72OjVIZB7JvRi+pBYYkL9ju1AK5+TLA42LxHCV37k3sqbvAl+eRHir64SzwChneGahZBzULJiuKgohsy9kL5dXDC8A+D8/9QtVzvseqnE9dvrUmb72oVGPBsMBoPBcApgBLSh1XAkt4RP1iXyyTpxzQjx8+LSYbGc3jWcPh2C6d4uAC8P29EbcpFzCHZ9LdkuouNqrss+KIVDBl4GsafD4nvhtzdgxC01t3PYYeEd4B8B5z9W9xg2m/uAuph44NK6y2sz4d/iQ93rfEkPZzAYDAaDodVjBLThpFJmd/D9jjQ+WpvIyn2ZaC2uGfdN7MOEfu3x9WpiedX8FCvV22eQtFaW+YSIdbd6KeLv/yFp2857RIp+7P9RlnU5q0ps5yeL60bqFrjsfy2T29jDE0bcevzbNRgMBoPB0GIYAW04oRSX29malMfmpFw2Jeayan8WucUVxIT4csc5Pbl0aCydwv2b1mhRFuxcKKI5YSWgJTvDubOh85nw2U0SsHfd11Ky9cAK2LlIUtG5ggenvQKvj4RPb4CrP4M1b8LatyRocORd0G/acR4Jg8FgMBgMpyomiNDQ4lQ4nCzdmc7c3w7xy75MnNYtFxvmx7AuYUwfIoGAHg1ly6hNaR7s+kZE84FlInQjelalemvXq2rb7AMw50JJIXftIvjsjxLUd9uamlknDv4E700FtGTmGDRTMmw0Jk2dwWAwGAyGNocJIjSccFLySpj322Hmr00kvaCM6BBfbh7Tg9O7hhEXG9q0zBmu0tXJG2H7Atj7PTjKJCfzmbeLaO4w0H0QYHh3ceGYMwneHCv7Xf5B3ZRt3UbDxP+DlM0w6i9Hz6FsMBgMBoPhd4kR0Ibjzs6UfP770wEWbk7+//buPc6uur73/+szey65EEAkQUm4E1AEBc1BrVVR8Qg/PWCLVaCeY6UtWrV6ausR6tH+6q/1VD0/pR5p+7PearXiDRFbRFGx1gs3QS4BApGLhEASbrmQzN6z1/78/thrwhAmYe+ZvTPJrNfz8ZjHzFp7zc53vqwwbz581vdLkckJRyzkQ88/iBOOXMjgjh4CvOun7e2oW83HzjXr8MBtsG7FY1tX7/G09k58R58GS5Z1tj7yvkvbIfrzr4an/yY84zWTX/f8t3T+g0qSpEoyQKsnxooWP75tHZ//2V38x+0PMG+4xn994UGc9aJDnryn+Z6r4fK/gjt+1F4LeWTBY68NDLZXuVh2Vnvb6v2Ogqcf290W2uMWPRPedX17o5NOQrckSdIkDNCaslYr+cWvH+ai6+7lkhvv4+HNYyxcMMJ7XnUkb3z+Qew1b2j731w04a4ft5eOu+1SmLcvvOpD7aA8NM31nXdkYjiXJEmaAgO0unbr/Ru46LrVfPv61dz7yBbmDA3wyqOexmuP3Z8XL13I8OB22jRaLbjnyvaDfzdfBI+ugzl7tVfDeP5bYWSPnfuDSJIkTYEBWh0ZHSv40pW/5qtX38OKNRupDQQvXrovf/aqI/jPRz2N+SPbuZUy2w/+3fSN9sN/G+6FwTlwxEntHualr+xvxVmSJKnHDNDaoaKVXHjtKj5+2W2sXj/KcQfuzQdPfRavPubpPPXJVtG47Xtw6Xvby8gNDMHhJ8KJfwlHnmQrhSRJ2m0ZoDWpzOTyFWv5yKUruPX+jTxnyV7879c/h984bN/O3qDxKHzr7e0WjVP+Dzzzv/RnJz9JkqSdzACtx2m1kstuWcMnf7iSG+9dz0FPnccnzzyOVx/zdKKblSuu/Ad4dG17veUDn9+/AUuSJO1kBmgB0Gi2uHT5/fzd5Su59f6NHLjPPD582jH81nFLtv9Q4PZsfgh+8rdwxMmGZ0mSNOsYoCtu5dqNfOXqe7jw2nt58NEGhy6cz8de/xxOec7+O970ZEd++rdQ3wCveH9vBytJkrQLMEBX1M9WPsDHv38bV9/1MIMDwYnP3I83HH8AL1m6kNrANDYZ2Xh/e23nZ78e9ntW7wYsSZK0izBAV8zy1ev58KUr+PFt69h/rzmce/Iz+O3nLmHhgidZUWMy61ZAYxPs/9zHdvb7949AawxOOLe3A5ckSdpFGKAr4o51m/jED27nol+uZu95Q/zPVz+TN77gIOYMTWFL7GYD/v3D8JOPQbZg7wPhWb8NB74Qrv0neN7vwT6H9PxnkCRJ2hUYoGe529ds5JOXr+Tb169meHCAt51wGG956WHsNXcH22zvyNpb4MKz4f4b4NjfhYN/E266EH72f+Cn58HgXHjJe3r7Q0iSJO1CDNCz1O1rNnLe92/nkpvuY+5QjT98yaH84YsPZd8n2/xkex75NVz3JfjJx9uboLzhS/DM17RfO/ZMePRBuPXbsODpsOBpvftBJEmSdjF9DdARcRLwt0AN+HRm/s02r38ceFl5OA9YlJl793NMs92qhzdz3vdv58JrVzFveJC3n3A4Z/3mIewzf3jH39h4FL7yRiBg0TNh0VGw71K499r2Ntyrrmpf94zXwGvOgz0WPv775z+13bohSZI0y/UtQEdEDTgfeCWwCrg6Ii7OzJvHr8nMP5lw/R8Dx/VrPLPdPQ9t5nM/vYsvXnE3BJz1okN428sOf/LgPO4n58Gvfgj7HQN3/QSK+mOv7XcMvOIv4Fm/ZW+zJEmqvH5WoI8HVmbmHQARcQFwKnDzdq4/A/iLPo5n1lm/eYx/u/E+vnndKq6+62EGAn7neQfwrhOXsv/eczt/o4fvhp99Ao5+HbzuM9Aq4KE74YEV8NTDYeGR/fshJEmSdjP9DNCLgXsmHK8CJt2WLiIOAg4BftjH8cwKmcnVdz3MF6+4m0tvup9G0eLwRXvwnlcdyWuPW8ziboLzuMveDzEAr/xg+3igBvse3v6QJEnS4/QzQE+2G0du59rTga9nZjHpG0WcDZwNcOCBB/ZmdLuZzY0m37j2Xr7487tZsWYjC+YMcubzD+S05y7h6MV7EjHFzU/u/DHc/C142ftgr8W9HbQkSdIs1M8AvQo4YMLxEmD1dq49HXj79t4oMz8FfApg2bJl2wvhs9YPb13D+y9azr2PbOFZ++/Jh087hv/ynP2ZNzzNf3xFE75zTnsd59/4494MVpIkaZbrZ4C+GlgaEYcA99IOyWdue1FEHAk8Bfh5H8eyW1q7cZS//PbN/NsN97F00R58+Q9fwAsO3Wdq1eb6RrjuizD3KeUKG0fAdf8Ma5fD678AQ1No/ZAkSaqgvgXozGxGxDuA79Jexu6zmbk8Ij4IXJOZF5eXngFckJmVqyxvT6uVfPWae/jQJbcwOtbiT195BG956WEMDw5M7Q3X3wv/8npYc9Nj52IAogYHvxieeUpvBi5JklQBfV0HOjMvAS7Z5twHtjn+v/s5ht3NyrWb+PNv3shVdz7E8w/Zhw/99jEctnCPqb/h6l/Cl0+H+iY482vwlINg7c2w5mZ4+C546Xthqv3TkiRJFeROhLuIerPgH350B+dfvpK5wzU+ctqz+Z1lS6b+cCDAikvh62e12zZ+/3uw31Ht8wuPbK/pLEmSpK4ZoHcBV935EOdeeAO/Wvcopzxnf97/mqNYuGCKW26Pu/L/g0vPgac9G878ittrS5Ik9YgBegat3zLG33znVr581a9Z8pS5fP7N/4kTjlw0vTdtFfDdP4cr/wGOfDWc9o8wPL83A5YkSZIBeqZ8b/n9vO+im3hwU52zX3Io//3EpdNflq6+Cb7xB3Dbd+AFb4P//FftTVEkSZLUMwbonSwz+eQPV/L/XnYbRy/ek8/93n/i6MV7df9GG1bD9Re0K87jbrm4vdLGyR+F55/du0FLkiRpKwP0TlRvFpz7jRu58Lp7+a3jFvM3px3DyOAUKsSj6+ELr4UHVjz+/Jy94PQvw5En9WbAkiRJegID9E7y0KMN3vrPv+Cqux7i3a88gj9++eFTW2GjVcDXfx8e+hX8t4vhoBc99loMwMAU14qWJElSRwzQO0Grlbzx01eyct0mPnHGcZzynP2n/maXfQBWXgavOQ8OfWnvBilJkqSOWK7cCX76qwe4+b4N/PVrj55eeL72C/DzT8Lxb4Flb+7dACVJktQxK9A7wT///G72mT/MKcdOMTyProfl34R/+zM49GXwqg/1doCSJEnqmAG6z1Y/soXv37KGt7z0sO4eGBzbAiu+Azd9A26/DIo6PO0Y+J3PQc1/bJIkSTPFJNZnX77q1yRw5vEHdv5Nv74SvvkWePhO2ONpsOwsOPo0WLIMprO1tyRJkqbNAN1HjWaLL191Dy8/chEH7DPv8S+2Wu3PE1fNaDbgR/8Lfnoe7LUEzvwaHP4KN0ORJEnahRig++i7y+/ngU113vjCg9onWgXc/bN2W8bN34LmKCx8Biw6ChYeATd8DdbcCMf913af85w9Z/YHkCRJ0hMYoPvon6+4mwP2mctLD98XfvxRuOrTsOl+GJoPR54M8xfC2pvh9u/BL7/YPj7jgvZrkiRJ2iUZoPtkxf0buerOhzj35GcwcOXfwQ//Cg4/EY79X3DESTC8TUvHow+2zw3NnZkBS5IkqSMG6D754hV3Mzw4wJn73AoXvh+OOhVe9/nt7xQ4/6k7dXySJEmaGjdS6YPM5KLr7uWsI+os+PZbYL+j4bV/7zbbkiRJs4CJrg8e3jzGYP0h3nbf+9ptGWdcAMPzZ3pYkiRJ6gFbOPpg7cZRPjH0SebX18JZ34G9Fs/0kCRJktQjVqD74KG1q3lx7Sbue/bb25ufSJIkadYwQPfB2OobARg6+AUzPBJJkiT1mgG6D2prlwOw50HHzfBIJEmS1GsG6D6Y/8itrM2nMPcp+830UCRJktRjBug+2HfT7dw1eMhMD0OSJEl9YIDutWKMpzXu4v65h830SCRJktQHBuhee+B2hmiyfsERMz0SSZIk9YEBusdyzU0AjD71qBkeiSRJkvrBjVR6rLHqBshBBhYunemhSJIkqQ8M0D3WvO9G7srFLNx7wUwPRZIkSX1gC0ePDT5wM7fmgSxaMDLTQ5EkSVIfGKB76dEHGNmylptbBmhJkqTZygDdS+UDhLfmgSzac84MD0aSJEn9YIDupTXtLbzvHjyUPUZsL5ckSZqNTHm9dP9NrK/tw9Aei2Z6JJIkSeoTK9C9tOYm7qwdYv+zJEnSLGaA7pViDNbdyi15gP3PkiRJs5gtHL3y4EooGlw3tsQKtCRJ0ixmBbpX7m+vwHH92BL229MALUmSNFsZoHtlzU3kwBB35P4sWmALhyRJ0mxlgO6VNcvZvNfhjDHIIivQkiRJs5YBulfW3MRDeywFsAItSZI0ixmge2F0PWy8j9XDBwNYgZYkSZrFDNC9sOVhANYWC5g7VGOBuxBKkiTNWgboXqhvBGBNY4RFe44QETM8IEmSJPWLAboXRjcAcP/ooGtAS5IkzXIG6F4oK9D3bhl2F0JJkqRZzgDdC/V2BfqezVagJUmSZjsDdC+UAXpNfdgl7CRJkmY5A3QvlD3QG5jnNt6SJEmznAG6F+obaMUgdYasQEuSJM1yBuheqG9kbGgPINxERZIkaZYzQPfC6AbqA/MB2M8KtCRJ0qxmgO6F+kY2D8xneHCAPee6C6EkSdJsZoDuhfoGNuVc9nMXQkmSpFnPAN0LoxtYn3N9gFCSJKkCDNC9UN/AQ8UcN1GRJEmqAAN0L9Q38ODYMPu5jbckSdKsZ4CerkyyvpEHm3NYaAVakiRp1jNAT9fYFqLVZFPOY8+5QzM9GkmSJPWZAXq66hsB2MhcRgadTkmSpNmur4kvIk6KiBURsTIiztnONa+PiJsjYnlE/Es/x9MX9Q0AbMh5BmhJkqQK6NuuHxFRA84HXgmsAq6OiIsz8+YJ1ywFzgVelJkPR8Sifo2nb0bbAXoTcxkZrM3wYCRJktRv/SyZHg+szMw7MrMBXACcus01fwicn5kPA2Tm2j6Opz/KCvTGnMfIkBVoSZKk2a6fiW8xcM+E41XluYmOAI6IiJ9GxBURcVIfx9Mf9YkVaAO0JEnSbNe3Fg5gsj2tc5I/fylwArAE+I+IODozH3ncG0WcDZwNcOCBB/Z+pNOx9SHCebZwSJIkVUA/S6argAMmHC8BVk9yzbcycywz7wRW0A7Uj5OZn8rMZZm5bOHChX0b8JSMjrdwWIGWJEmqgn4mvquBpRFxSEQMA6cDF29zzUXAywAiYl/aLR139HFMvTehhWPOkBVoSZKk2a5vATozm8A7gO8CtwBfzczlEfHBiDilvOy7wIMRcTNwOfCezHywX2Pqi/pGmrW5FNSsQEuSJFVAP3ugycxLgEu2OfeBCV8n8O7yY/c0up7G4B4ArsIhSZJUASa+6apvpFErA7QPEUqSJM16Bujpqm+gXpsHYAuHJElSBZj4pqu+kdGtFWinU5IkabYz8U3X6Aa2DMxneHCAiMmWvpYkSdJsYoCervoGtsQ8q8+SJEkVYeqbrvpGHo35PkAoSZJUEQbo6WgV0NjEo7gLoSRJUlWY+qajvhGATTHPNaAlSZIqwtQ3HePbeOdcWzgkSZIqwgA9HaPtAL0BHyKUJEmqClPfdJQtHOtb9kBLkiRVhalvOsoWjvWtOYwM2cIhSZJUBQbo6Sgr0I+05jLHCrQkSVIlmPqmY3Q9AI80R6xAS5IkVYQBejrKCvRDhT3QkiRJVWHqm476Boga65uDBmhJkqSKMPVNx+gGGFlAvZmuAy1JklQRBujpqG+EOXtSb7bciVCSJKkiTH3TUd9AjiygUbRs4ZAkSaoIU9901DeSw3sC2MIhSZJUEQbo6RhdTzG0B4AVaEmSpIow9U1HfSPF8AIAe6AlSZIqwtQ3HfUNNIfKAG0LhyRJUiUYoKcqE0Y3MDY4H7CFQ5IkqSpMfVPVrENrjPqgPdCSJElVYuqbqvoGABq1MkAP2cIhSZJUBQboqapvBGB0wBYOSZKkKjH1TdXo+vanWjtAz7ECLUmSVAkG6KkqWzi2DMwDrEBLkiRVhalvqsoWjs1hC4ckSVKVmPqmarRdgd4cZQXaFg5JkqRKMEBPVVmB3oQtHJIkSVVi6puqsgd6E3MBA7QkSVJVmPqmqr4BBucy2mq3briVtyRJUjUYoKdqdAPM2ZP6WEEEDNVipkckSZKkncAAPVX1DTCygHqzxcjgABEGaEmSpCowQE9VfSOM7FkGaNs3JEmSqsIAPVWj4xXowgcIJUmSKsTkN1X1jWUPdIuRIadRkiSpKkx+U1XfYAuHJElSBRmgp2q0HaBHx2zhkCRJqhKT31S0WtAoWzjKVTgkSZJUDSa/qWi0t/Eef4hwzpAtHJIkSVVhgJ6K+niAtgItSZJUNSa/qWg82v48PL+9CocPEUqSJFWGAXoqikb78+BIex1ol7GTJEmqDJPfVDTLAF0btoVDkiSpYkx+UzFega4NuQ60JElSxRigp6KYUIF2HWhJkqRKMflNRTHW/jzewmEPtCRJUmWY/KairEA3Y4hmK23hkCRJqhAD9FSUAXqMQQBbOCRJkiqko+QXEYdFxEj59QkR8c6I2Lu/Q9uFlS0cjTRAS5IkVU2nye8bQBERhwOfAQ4B/qVvo9rVlRXoRrZbN0bcyluSJKkyOg3QrcxsAr8FnJeZfwI8vX/D2sUVdQBGW2WAtgItSZJUGZ0mv7GIOAN4E/Cv5bmh/gxpN1C2cNS3tnBYgZYkSaqKTgP0m4EXAn+dmXdGxCHAF/s3rF1c2cIxmu3pswItSZJUHYOdXJSZNwPvBIiIpwALMvNv+jmwXdp4gG61p2+OPdCSJEmV0ekqHD+KiD0jYh/geuBzEfGx/g5tF1a2cGztgXYjFUmSpMroNPntlZkbgN8GPpeZzwNO7N+wdnFFAwYGqRcJ2MIhSZJUJZ0mv8GIeDrweh57iLC6isbWbbzBhwglSZKqpNMA/UHgu8CvMvPqiDgUuL1/w9rFFWNQG6LeLAAr0JIkSVXSUfLLzK9l5rMz84/K4zsy87Qn+76IOCkiVkTEyog4Z5LXfy8i1kXEL8uPP+j+R5gBzXq7Aj1WVqDtgZYkSaqMTh8iXBIR34yItRGxJiK+ERFLnuR7asD5wMnAUcAZEXHUJJd+JTOPLT8+3fVPMBOKMVs4JEmSKqrT0unngIuB/YHFwLfLcztyPLCyrFY3gAuAU6c60F1K0bCFQ5IkqaI6TX4LM/NzmdksPz4PLHyS71kM3DPheFV5blunRcQNEfH1iDhgsjeKiLMj4pqIuGbdunUdDrmPxh8iHG/hMEBLkiRVRqfJ74GIeGNE1MqPNwIPPsn3xCTncpvjbwMHZ+azge8D/zTZG2XmpzJzWWYuW7jwyXL7TlCMQW2EerNFbSAYrBmgJUmSqqLT5HcW7SXs7gfuA15He3vvHVkFTKwoLwFWT7wgMx/MzHp5+I/A8zocz8ya0MJh9VmSJKlaOl2F49eZeUpmLszMRZn5WtqbquzI1cDSiDgkIoaB02n3UW9Vri097hTgli7GPnPKFo7RsZYBWpIkqWKmk/7evaMXM7MJvIP2+tG3AF/NzOUR8cGIOKW87J0RsTwirgfeCfzeNMaz80xYB9oVOCRJkqplcBrfO1mP8+Nk5iXAJduc+8CEr88Fzp3GGGZGUYehvak3W64BLUmSVDHTSX/bPhBYHRNW4ZhjBVqSJKlSdliBjoiNTB6UA5jblxHtDsZbOOqFFWhJkqSK2WGAzswFO2sgu5XxCnTThwglSZKqxvQ3FcUYDI6UAdoWDkmSpCoxQE+F60BLkiRVlulvKiY8RGgPtCRJUrWY/qaiGJvQA20LhyRJUpUYoKfCFg5JkqTKMv11K9NVOCRJkirM9NetYqz9uTZU9kDbwiFJklQlBuhuFQ0AcmDYFg5JkqQKMv11qwzQxcAwrcQALUmSVDGmv26VLRzNaLduuAqHJElStRigu1VWoMcYAnAdaEmSpIox/XVra4AeBGzhkCRJqhrTX7fKFo6xbLduzHEVDkmSpEoxQHerqAPQsAItSZJUSaa/bpUV6McCtBVoSZKkKjFAd6vsgW60xlfhcAolSZKqxPTXrTJA112FQ5IkqZJMf90qWzjqaQuHJElSFRmguzVegc721NnCIUmSVC2mv26VAXq0ZQVakiSpigzQ3Rpv4Rh/iNAeaEmSpEox/XWr2V4HekvLFg5JkqQqMv11q2zh2FKML2NnC4ckSVKVGKC7VbZwjFegh61AS5IkVYrpr1tlBXpza5ChWlAbiBkekCRJknYmA3S3xgN0s2b7hiRJUgUZoLs13sJRhA8QSpIkVZAJsFtFAwaGqBfJnCEr0JIkSVVjgO5W0YDaMPVmywq0JElSBZkAu1U0oDZEfaxwBQ5JkqQKMgF2a2IF2hYOSZKkyjFAd6sYKwN0YQuHJElSBZkAu1U0YNAeaEmSpKoyAXZrvIVjrOU60JIkSRVkgO5WMdZ+iLBZMDLk9EmSJFWNCbBbLmMnSZJUaSbAbpUBetQWDkmSpEoyQHer2XishcMKtCRJUuWYALv1uHWgnT5JkqSqMQF2qxgja0M0mrZwSJIkVZEBultFg9bAMIAtHJIkSRVkAuxW0aCIIcAALUmSVEUmwG4VYxQxCMCcIVs4JEmSqsYA3S0r0JIkSZVmAuxW0aBZBuhhA7QkSVLlmAC7VTRoli0crsIhSZJUPQbobhUNmowHaKdPkiSpakyA3Wi1oNU0QEuSJFWYCbAbrTEAxuyBliRJqiwTYDeKBgBj2AMtSZJUVQbobhRlBboM0FagJUmSqscE2I2yAt1Ie6AlSZKqygTYja0But26YQVakiSpekyA3Wi2A3TdVTgkSZIqywTYjW1aOKxAS5IkVY8JsBtlgK632tPmKhySJEnVY4DuRrkKRz3b60AP1WImRyNJkqQZYIDuRlmBHs0aI4MDRBigJUmSqqavAToiTooTp4P3AAASAUlEQVSIFRGxMiLO2cF1r4uIjIhl/RzPtI0H6FbN/mdJkqSK6lsKjIgacD5wMnAUcEZEHDXJdQuAdwJX9mssPVO2cGxp1ex/liRJqqh+llGPB1Zm5h2Z2QAuAE6d5Lr/B/gIMNrHsfTGhAq0S9hJkiRVUz9T4GLgngnHq8pzW0XEccABmfmvfRxH7xR1ALYUAwZoSZKkiupnCpzsCbvc+mLEAPBx4E+f9I0izo6IayLimnXr1vVwiF2a0MJhD7QkSVI19TMFrgIOmHC8BFg94XgBcDTwo4i4C3gBcPFkDxJm5qcyc1lmLlu4cGEfh/wkyhaOzYUtHJIkSVXVzxR4NbA0Ig6JiGHgdODi8Rczc31m7puZB2fmwcAVwCmZeU0fxzQ9ZYDeUliBliRJqqq+pcDMbALvAL4L3AJ8NTOXR8QHI+KUfv25fVW2cDxahKtwSJIkVdRgP988My8BLtnm3Ae2c+0J/RxLT4y3cLRq7GUFWpIkqZJMgd0oA/SjY67CIUmSVFWmwG6Mr8JRhD3QkiRJFWUK7EazDrVh6s20Ai1JklRRpsBuFGNQG6ZRtKxAS5IkVZQpsBtFA2pD1McKV+GQJEmqKAN0N4oG1EasQEuSJFWYKbAbxRhZG2KssAdakiSpqkyB3SgaZG0YwAq0JElSRZkCu1E0yIEhAHugJUmSKsoA3Y1ijFYZoK1AS5IkVZMpsBtFnVaMV6CdOkmSpCoyBXZjQgXaAC1JklRNpsBuFA0KA7QkSVKlmQK7UTQowh5oSZKkKjMFdqMY2xqgXYVDkiSpmgzQ3SgaFDEIWIGWJEmqKlNgN4oGzTJA2wMtSZJUTabAbhRjNO2BliRJqjRTYDeadcYYr0DbAy1JklRFBuhuFGM0sQdakiSpykyB3SgaEyrQTp0kSVIVmQK7UTRoYA+0JElSlZkCO9UqIAsa2e59tgItSZJUTabAThVjADTGe6BrTp0kSVIVmQI7VTQAqGeN4cEBImKGByRJkqSZYIDu1HgFOgcZsfosSZJUWSbBThV1oF2BHhly2iRJkqrKJNip8RaO1qD9z5IkSRVmEuxU2cIxmjVGhtyFUJIkqaoM0J0qK9CjrZoVaEmSpAozCXZqQoC2B1qSJKm6TIKdGm/hsAItSZJUaSbBTpUV6C1WoCVJkirNJNip8QBdWIGWJEmqMpNgp5rtAL25GGBk0FU4JEmSqsoA3amtFegBhgedNkmSpKoyCXaqDNCPFjVGDNCSJEmVZRLsVLkKx+aiZgVakiSpwkyCndpagbYHWpIkqcoM0J0aD9BNe6AlSZKqzCTYqa0tHAP2QEuSJFWYSbBTZQW6waAVaEmSpAozCXaqDNBjDFqBliRJqjCTYKeKBklQYAuHJElSlZkEO1U0oDYMhKtwSJIkVZgBulPFGFkbBrAHWpIkqcJMgp0qGrQGhgBs4ZAkSaowk2CnigZZBmgr0JIkSdVlEuxUMTahAm0PtCRJUlUZoDtVNCjCCrQkSVLVmQQ71azbAy1JkiQDdMeKMYoYBKxAS5IkVZlJsFMTWjisQEuSJFWXSbBTxRhNe6AlSZIqzyTYqaJBs2zhcBUOSZKk6jJAd6po0MQKtCRJUtWZBDtVjDG2tQLttEmSJFWVSbBTRYMm5SocNadNkiSpqkyCnSoajDHIcG2AgYGY6dFIkiRphhigO1U0aOSg/c+SJEkVZxrsVNFgjJr9z5IkSRXX1zQYESdFxIqIWBkR50zy+lsj4saI+GVE/CQijurneKalGKOeQ1agJUmSKq5vaTAiasD5wMnAUcAZkwTkf8nMYzLzWOAjwMf6NZ5pKxo0GLQCLUmSVHH9TIPHAysz847MbAAXAKdOvCAzN0w4nA9kH8czPUWDetasQEuSJFXcYB/fezFwz4TjVcDzt70oIt4OvBsYBl7ex/FMXauAbNHIQXchlCRJqrh+llMnW+vtCRXmzDw/Mw8D3gv8z0nfKOLsiLgmIq5Zt25dj4fZgaIBwGhrwAq0JElSxfUzDa4CDphwvARYvYPrLwBeO9kLmfmpzFyWmcsWLlzYwyF2qAzQ9bQHWpIkqer6mQavBpZGxCERMQycDlw88YKIWDrh8NXA7X0cz9Q1xyvQ9kBLkiRVXd96oDOzGRHvAL4L1IDPZubyiPggcE1mXgy8IyJOBMaAh4E39Ws801I8FqCtQEuSJFVbPx8iJDMvAS7Z5twHJnz9rn7++T1TBugtrRrDPkQoSZJUaZZTO1GMAe0AbQVakiSp2kyDnRivQBeuwiFJklR1psFOlAF6sxVoSZKkyjMNdqJs4dhsBVqSJKnyTIOdGBgk9zmU9c0RdyKUJEmqOAN0J5Y8j8bbruHaPMIWDkmSpIozDXao0WwBGKAlSZIqzjTYoXoZoO2BliRJqjbTYIesQEuSJAkM0B2zAi1JkiQwQHfssQq0q3BIkiRVmQG6Q/VmAcBwzSmTJEmqMtNgh7ZWoIecMkmSpCozDXZoaw+0FWhJkqRKMw126LEKtD3QkiRJVWaA7pA90JIkSQIDdMfq9kBLkiQJA3TH7IGWJEkSGKA75iockiRJAgN0x7a2cNR8iFCSJKnKDNAdsgItSZIkMEB3zFU4JEmSBAbojjWaLYZqwcBAzPRQJEmSNIMM0B2qN1tWnyVJkmSA7lSj2XIXQkmSJBmgO1VvFlagJUmSZIDuVLsC7XRJkiRVnYmwQ/ZAS5IkCQzQHbMCLUmSJDBAd8wKtCRJksAA3bFGs8XIoKtwSJIkVZ0BukP1ZsHwoNMlSZJUdSbCDtWbLUYM0JIkSZVnIuxQo9myAi1JkiQDdKfq9kBLkiQJA3TH6lagJUmShAG6Y41mYQ+0JEmSDNCd8iFCSZIkgQG6I5lJo7CFQ5IkSQbojowVSSZWoCVJkmSA7kSjaAFYgZYkSZIBuhP1sQLAZewkSZJkgO6EFWhJkiSNMxF2oD7WDtD2QEuSJMlE2AEr0JIkSRpnIuzAYxVoe6AlSZKqzgDdgUbRfojQCrQkSZJMhB0YGaxx7AF785R5QzM9FEmSJM2wwZkewO7g6MV7cdHbXzTTw5AkSdIuwAq0JEmS1AUDtCRJktQFA7QkSZLUBQO0JEmS1AUDtCRJktQFA7QkSZLUBQO0JEmS1AUDtCRJktQFA7QkSZLUBQO0JEmS1AUDtCRJktQFA7QkSZLUBQO0JEmS1IW+BuiIOCkiVkTEyog4Z5LX3x0RN0fEDRHxg4g4qJ/jkSRJkqarbwE6ImrA+cDJwFHAGRFx1DaXXQcsy8xnA18HPtKv8UiSJEm90M8K9PHAysy8IzMbwAXAqRMvyMzLM3NzeXgFsKSP45EkSZKmrZ8BejFwz4TjVeW57fl94DuTvRARZ0fENRFxzbp163o4REmSJKk7/QzQMcm5nPTCiDcCy4CPTvZ6Zn4qM5dl5rKFCxf2cIiSJElSdwb7+N6rgAMmHC8BVm97UUScCLwPeGlm1p/sTX/xi188EBF392yU27cv8MBO+HNmO+exN5zH3nAep8857A3nsTecx+lzDnds0gUuInPSovC0RcQgcBvwCuBe4GrgzMxcPuGa42g/PHhSZt7el4FMUURck5nLZnocuzvnsTecx95wHqfPOewN57E3nMfpcw6npm8tHJnZBN4BfBe4BfhqZi6PiA9GxCnlZR8F9gC+FhG/jIiL+zUeSZIkqRf62cJBZl4CXLLNuQ9M+PrEfv75kiRJUq+5E+H2fWqmBzBLOI+94Tz2hvM4fc5hbziPveE8Tp9zOAV964GWJEmSZiMr0JIkSVIXDNCTiIiTImJFRKyMiHNmejy7i4g4ICIuj4hbImJ5RLyrPL9PRFwWEbeXn58y02Pd1UVELSKui4h/LY8PiYgryzn8SkQMz/QYd3URsXdEfD0ibi3vyRd6L3YvIv6k/Pt8U0R8OSLmeD8+uYj4bESsjYibJpyb9P6Ltk+Uv3NuiIjnztzIdx3bmcOPln+nb4iIb0bE3hNeO7ecwxUR8aqZGfWuZ7J5nPDan0VERsS+5bH3YocM0NuIiBpwPnAycBRwRkQcNbOj2m00gT/NzGcCLwDeXs7dOcAPMnMp8IPyWDv2Ltqr14z7MPDxcg4fpr1zp3bsb4FLM/MZwHNoz6f3YhciYjHwTmBZZh4N1IDT8X7sxOeBk7Y5t73772RgaflxNvD3O2mMu7rP88Q5vAw4OjOfTXup3HMByt81pwPPKr/n78rf55p8HomIA4BXAr+ecNp7sUMG6Cc6HliZmXdkZgO4ADh1hse0W8jM+zLz2vLrjbQDy2La8/dP5WX/BLx2Zka4e4iIJcCrgU+XxwG8nPaa6eAcPqmI2BN4CfAZgMxsZOYjeC9OxSAwt1zbfx5wH96PTyozfww8tM3p7d1/pwJfyLYrgL0j4uk7Z6S7rsnmMDO/Vy6TC3AF7U3aoD2HF2RmPTPvBFbS/n1eedu5FwE+DvwPHr9LtPdihwzQT7QYuGfC8arynLoQEQcDxwFXAvtl5n3QDtnAopkb2W7hPNr/UmuVx08FHpnwS8N78skdCqwDPle2wnw6IubjvdiVzLwX+N+0K1T3AeuBX+D9OFXbu//8vTM1ZwHfKb92DrtQ7sdxb2Zev81LzmOHDNBPFJOcc6mSLkTEHsA3gP+emRtmejy7k4h4DbA2M38x8fQkl3pP7tgg8Fzg7zPzOOBRbNfoWtmjeypwCLA/MJ/2/+Ldlvfj9Ph3vEsR8T7abYNfGj81yWXO4SQiYh7wPuADk708yTnncRIG6CdaBRww4XgJsHqGxrLbiYgh2uH5S5l5YXl6zfj/Aio/r52p8e0GXgScEhF30W4fejntivTe5f9CB+/JTqwCVmXmleXx12kHau/F7pwI3JmZ6zJzDLgQ+A28H6dqe/efv3e6EBFvAl4D/G4+thavc9i5w2j/R/H15e+aJcC1EfE0nMeOGaCf6GpgafmU+TDthxLcYrwDZa/uZ4BbMvNjE166GHhT+fWbgG/t7LHtLjLz3MxckpkH0773fpiZvwtcDryuvMw5fBKZeT9wT0QcWZ56BXAz3ovd+jXwgoiYV/79Hp9H78ep2d79dzHw38oVEF4ArB9v9dDjRcRJwHuBUzJz84SXLgZOj4iRiDiE9kNwV83EGHd1mXljZi7KzIPL3zWrgOeW/970XuyQG6lMIiL+L9pVvxrw2cz86xke0m4hIn4T+A/gRh7r3/1z2n3QXwUOpP0L+Xcyc7IHGjRBRJwA/FlmviYiDqVdkd4HuA54Y2bWZ3J8u7qIOJb2g5jDwB3Am2kXDbwXuxARfwm8gfb/Lr8O+APaPZHejzsQEV8GTgD2BdYAfwFcxCT3X/kfJ5+kvVLCZuDNmXnNTIx7V7KdOTwXGAEeLC+7IjPfWl7/Ptp90U3aLYTf2fY9q2iyeczMz0x4/S7aK+084L3YOQO0JEmS1AVbOCRJkqQuGKAlSZKkLhigJUmSpC4YoCVJkqQuGKAlSZKkLhigJWkXFxFFRPxywkfPdlWMiIMj4qZevZ8kVcHgk18iSZphWzLz2JkehCSpzQq0JO2mIuKuiPhwRFxVfhxenj8oIn4QETeUnw8sz+8XEd+MiOvLj98o36oWEf8YEcsj4nsRMbe8/p0RcXP5PhfM0I8pSbscA7Qk7frmbtPC8YYJr23IzONp7x52Xnnuk8AXMvPZwJeAT5TnPwH8e2Y+B3gusLw8vxQ4PzOfBTwCnFaePwc4rnyft/brh5Ok3Y07EUrSLi4iNmXmHpOcvwt4eWbeERFDwP2Z+dSIeAB4emaOlefvy8x9I2IdsGTittsRcTBwWWYuLY/fCwxl5l9FxKXAJtpbUF+UmZv6/KNK0m7BCrQk7d5yO19v75rJ1Cd8XfDY8zGvBs4Hngf8IiJ8bkaSMEBL0u7uDRM+/7z8+mfA6eXXvwv8pPz6B8AfAURELSL23N6bRsQAcEBmXg78D2Bv4AlVcEmqIqsJkrTrmxsRv5xwfGlmji9lNxIRV9IuiJxRnnsn8NmIeA+wDnhzef5dwKci4vdpV5r/CLhvO39mDfhiROwFBPDxzHykZz+RJO3G7IGWpN1U2QO9LDMfmOmxSFKV2MIhSZIkdcEKtCRJktQFK9CSJElSFwzQkiRJUhcM0JIkSVIXDNCSJElSFwzQkiRJUhcM0JIkSVIX/n90fsg45DmybQAAAABJRU5ErkJggg==\n",
      "text/plain": [
       "<Figure size 864x576 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "fig, ax = plt.subplots(figsize=(12, 8))\n",
    "\n",
    "L1_model_dict = L1_model_val.history\n",
    "\n",
    "acc_values = L1_model_dict['acc'] \n",
    "val_acc_values = L1_model_dict['val_acc']\n",
    "\n",
    "epochs = range(1, len(acc_values) + 1)\n",
    "ax.plot(epochs, acc_values, label='Training acc L1')\n",
    "ax.plot(epochs, val_acc_values, label='Validation acc L1')\n",
    "ax.set_title('Training & validation accuracy with L1 regularization')\n",
    "ax.set_xlabel('Epochs')\n",
    "ax.set_ylabel('Loss')\n",
    "ax.legend();"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Notice how the training and validation accuracy don't diverge as much as before. Unfortunately, the validation accuracy isn't still that good. Next, experiment with dropout regularization to see if it offers any advantages. \n",
    "\n",
    "\n",
    "## Dropout Regularization \n",
    "\n",
    "It's time to try another technique: applying dropout to layers. As discussed in the earlier lesson, this involves setting a certain proportion of units in each layer to zero. In the following cell: \n",
    "\n",
    "- Apply a dropout rate of 30% to the input layer \n",
    "- Add a first hidden layer with 50 units and `'relu'` activation \n",
    "- Apply a dropout rate of 30% to the first hidden layer \n",
    "- Add a second hidden layer with 25 units and `'relu'` activation \n",
    "- Apply a dropout rate of 30% to the second hidden layer \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 57500 samples, validate on 1000 samples\n",
      "Epoch 1/150\n",
      "57500/57500 [==============================] - 4s 70us/step - loss: 1.9277 - acc: 0.1820 - val_loss: 1.8805 - val_acc: 0.2230\n",
      "Epoch 2/150\n",
      "57500/57500 [==============================] - 4s 71us/step - loss: 1.8605 - acc: 0.2310 - val_loss: 1.7797 - val_acc: 0.2990\n",
      "Epoch 3/150\n",
      "57500/57500 [==============================] - 4s 71us/step - loss: 1.7651 - acc: 0.2990 - val_loss: 1.6288 - val_acc: 0.4550\n",
      "Epoch 4/150\n",
      "57500/57500 [==============================] - 4s 65us/step - loss: 1.6521 - acc: 0.3684 - val_loss: 1.4623 - val_acc: 0.5740\n",
      "Epoch 5/150\n",
      "57500/57500 [==============================] - 3s 56us/step - loss: 1.5319 - acc: 0.4285 - val_loss: 1.2993 - val_acc: 0.6250\n",
      "Epoch 6/150\n",
      "57500/57500 [==============================] - 3s 56us/step - loss: 1.4257 - acc: 0.4738 - val_loss: 1.1675 - val_acc: 0.6580\n",
      "Epoch 7/150\n",
      "57500/57500 [==============================] - 3s 58us/step - loss: 1.3324 - acc: 0.5049 - val_loss: 1.0587 - val_acc: 0.6730\n",
      "Epoch 8/150\n",
      "57500/57500 [==============================] - 3s 58us/step - loss: 1.2640 - acc: 0.5290 - val_loss: 0.9789 - val_acc: 0.6990\n",
      "Epoch 9/150\n",
      "57500/57500 [==============================] - 3s 56us/step - loss: 1.2063 - acc: 0.5519 - val_loss: 0.9192 - val_acc: 0.7050\n",
      "Epoch 10/150\n",
      "57500/57500 [==============================] - 3s 57us/step - loss: 1.1686 - acc: 0.5655 - val_loss: 0.8742 - val_acc: 0.7100\n",
      "Epoch 11/150\n",
      "57500/57500 [==============================] - 3s 57us/step - loss: 1.1241 - acc: 0.5859 - val_loss: 0.8333 - val_acc: 0.7100\n",
      "Epoch 12/150\n",
      "57500/57500 [==============================] - 3s 57us/step - loss: 1.0886 - acc: 0.5971 - val_loss: 0.7992 - val_acc: 0.7260\n",
      "Epoch 13/150\n",
      "57500/57500 [==============================] - 3s 56us/step - loss: 1.0590 - acc: 0.6080 - val_loss: 0.7780 - val_acc: 0.7300\n",
      "Epoch 14/150\n",
      "57500/57500 [==============================] - 3s 59us/step - loss: 1.0414 - acc: 0.6187 - val_loss: 0.7556 - val_acc: 0.7350\n",
      "Epoch 15/150\n",
      "57500/57500 [==============================] - 3s 59us/step - loss: 1.0147 - acc: 0.6266 - val_loss: 0.7340 - val_acc: 0.7350\n",
      "Epoch 16/150\n",
      "57500/57500 [==============================] - 3s 57us/step - loss: 0.9985 - acc: 0.6329 - val_loss: 0.7248 - val_acc: 0.7390\n",
      "Epoch 17/150\n",
      "57500/57500 [==============================] - 3s 59us/step - loss: 0.9833 - acc: 0.6376 - val_loss: 0.7056 - val_acc: 0.7400\n",
      "Epoch 18/150\n",
      "57500/57500 [==============================] - 4s 62us/step - loss: 0.9626 - acc: 0.6482 - val_loss: 0.6981 - val_acc: 0.7460\n",
      "Epoch 19/150\n",
      "57500/57500 [==============================] - 3s 58us/step - loss: 0.9447 - acc: 0.6525 - val_loss: 0.6805 - val_acc: 0.7500\n",
      "Epoch 20/150\n",
      "57500/57500 [==============================] - 3s 58us/step - loss: 0.9349 - acc: 0.6561 - val_loss: 0.6717 - val_acc: 0.7490\n",
      "Epoch 21/150\n",
      "57500/57500 [==============================] - 3s 59us/step - loss: 0.9197 - acc: 0.6631 - val_loss: 0.6628 - val_acc: 0.7540\n",
      "Epoch 22/150\n",
      "57500/57500 [==============================] - 3s 57us/step - loss: 0.9087 - acc: 0.6671 - val_loss: 0.6584 - val_acc: 0.7540\n",
      "Epoch 23/150\n",
      "57500/57500 [==============================] - 3s 58us/step - loss: 0.8978 - acc: 0.6713 - val_loss: 0.6515 - val_acc: 0.7580\n",
      "Epoch 24/150\n",
      "57500/57500 [==============================] - 3s 58us/step - loss: 0.8935 - acc: 0.6710 - val_loss: 0.6457 - val_acc: 0.7570\n",
      "Epoch 25/150\n",
      "57500/57500 [==============================] - 3s 58us/step - loss: 0.8829 - acc: 0.6778 - val_loss: 0.6396 - val_acc: 0.7570\n",
      "Epoch 26/150\n",
      "57500/57500 [==============================] - 3s 61us/step - loss: 0.8722 - acc: 0.6806 - val_loss: 0.6336 - val_acc: 0.7590\n",
      "Epoch 27/150\n",
      "57500/57500 [==============================] - 3s 58us/step - loss: 0.8621 - acc: 0.6838 - val_loss: 0.6263 - val_acc: 0.7600\n",
      "Epoch 28/150\n",
      "57500/57500 [==============================] - 3s 59us/step - loss: 0.8588 - acc: 0.6869 - val_loss: 0.6244 - val_acc: 0.7610\n",
      "Epoch 29/150\n",
      "57500/57500 [==============================] - 3s 59us/step - loss: 0.8541 - acc: 0.6878 - val_loss: 0.6223 - val_acc: 0.7590\n",
      "Epoch 30/150\n",
      "57500/57500 [==============================] - 3s 59us/step - loss: 0.8431 - acc: 0.6915 - val_loss: 0.6168 - val_acc: 0.7610\n",
      "Epoch 31/150\n",
      "57500/57500 [==============================] - 3s 60us/step - loss: 0.8307 - acc: 0.6949 - val_loss: 0.6110 - val_acc: 0.7600\n",
      "Epoch 32/150\n",
      "57500/57500 [==============================] - 3s 60us/step - loss: 0.8262 - acc: 0.6973 - val_loss: 0.6103 - val_acc: 0.7640\n",
      "Epoch 33/150\n",
      "57500/57500 [==============================] - 3s 59us/step - loss: 0.8241 - acc: 0.6993 - val_loss: 0.6070 - val_acc: 0.7670\n",
      "Epoch 34/150\n",
      "57500/57500 [==============================] - 3s 61us/step - loss: 0.8144 - acc: 0.6998 - val_loss: 0.6019 - val_acc: 0.7650\n",
      "Epoch 35/150\n",
      "57500/57500 [==============================] - 4s 65us/step - loss: 0.8111 - acc: 0.7040 - val_loss: 0.5968 - val_acc: 0.7670\n",
      "Epoch 36/150\n",
      "57500/57500 [==============================] - 3s 61us/step - loss: 0.8067 - acc: 0.7042 - val_loss: 0.5951 - val_acc: 0.7660\n",
      "Epoch 37/150\n",
      "57500/57500 [==============================] - 4s 64us/step - loss: 0.8102 - acc: 0.7033 - val_loss: 0.5951 - val_acc: 0.7680\n",
      "Epoch 38/150\n",
      "57500/57500 [==============================] - 4s 63us/step - loss: 0.7965 - acc: 0.7070 - val_loss: 0.5925 - val_acc: 0.7690\n",
      "Epoch 39/150\n",
      "57500/57500 [==============================] - 4s 61us/step - loss: 0.7940 - acc: 0.7095 - val_loss: 0.5915 - val_acc: 0.7680\n",
      "Epoch 40/150\n",
      "57500/57500 [==============================] - 4s 64us/step - loss: 0.7821 - acc: 0.7152 - val_loss: 0.5862 - val_acc: 0.7660\n",
      "Epoch 41/150\n",
      "57500/57500 [==============================] - 4s 61us/step - loss: 0.7861 - acc: 0.7133 - val_loss: 0.5868 - val_acc: 0.7690\n",
      "Epoch 42/150\n",
      "57500/57500 [==============================] - 4s 77us/step - loss: 0.7797 - acc: 0.7155 - val_loss: 0.5841 - val_acc: 0.7750\n",
      "Epoch 43/150\n",
      "57500/57500 [==============================] - 4s 62us/step - loss: 0.7753 - acc: 0.7163 - val_loss: 0.5817 - val_acc: 0.7760\n",
      "Epoch 44/150\n",
      "57500/57500 [==============================] - 4s 61us/step - loss: 0.7710 - acc: 0.7202 - val_loss: 0.5802 - val_acc: 0.7740\n",
      "Epoch 45/150\n",
      "57500/57500 [==============================] - 4s 61us/step - loss: 0.7703 - acc: 0.7202 - val_loss: 0.5800 - val_acc: 0.7740\n",
      "Epoch 46/150\n",
      "57500/57500 [==============================] - 4s 72us/step - loss: 0.7647 - acc: 0.7209 - val_loss: 0.5766 - val_acc: 0.7750\n",
      "Epoch 47/150\n",
      "57500/57500 [==============================] - 4s 64us/step - loss: 0.7613 - acc: 0.7225 - val_loss: 0.5765 - val_acc: 0.7760\n",
      "Epoch 48/150\n",
      "57500/57500 [==============================] - 4s 66us/step - loss: 0.7585 - acc: 0.7238 - val_loss: 0.5744 - val_acc: 0.7780\n",
      "Epoch 49/150\n",
      "57500/57500 [==============================] - 4s 76us/step - loss: 0.7520 - acc: 0.7268 - val_loss: 0.5738 - val_acc: 0.7760\n",
      "Epoch 50/150\n",
      "57500/57500 [==============================] - 4s 63us/step - loss: 0.7443 - acc: 0.7261 - val_loss: 0.5700 - val_acc: 0.7760\n",
      "Epoch 51/150\n",
      "57500/57500 [==============================] - 4s 69us/step - loss: 0.7492 - acc: 0.7271 - val_loss: 0.5733 - val_acc: 0.7770\n",
      "Epoch 52/150\n",
      "57500/57500 [==============================] - 3s 58us/step - loss: 0.7433 - acc: 0.7291 - val_loss: 0.5708 - val_acc: 0.7790\n",
      "Epoch 53/150\n",
      "57500/57500 [==============================] - 5s 84us/step - loss: 0.7391 - acc: 0.7288 - val_loss: 0.5701 - val_acc: 0.7800\n",
      "Epoch 54/150\n",
      "57500/57500 [==============================] - 5s 86us/step - loss: 0.7426 - acc: 0.7287 - val_loss: 0.5690 - val_acc: 0.7800\n",
      "Epoch 55/150\n",
      "57500/57500 [==============================] - 5s 94us/step - loss: 0.7383 - acc: 0.7299 - val_loss: 0.5673 - val_acc: 0.7800\n",
      "Epoch 56/150\n",
      "57500/57500 [==============================] - 4s 76us/step - loss: 0.7403 - acc: 0.7313 - val_loss: 0.5653 - val_acc: 0.7780\n",
      "Epoch 57/150\n",
      "57500/57500 [==============================] - 4s 74us/step - loss: 0.7288 - acc: 0.7354 - val_loss: 0.5654 - val_acc: 0.7840\n",
      "Epoch 58/150\n",
      "57500/57500 [==============================] - 4s 76us/step - loss: 0.7246 - acc: 0.7363 - val_loss: 0.5600 - val_acc: 0.7780\n",
      "Epoch 59/150\n",
      "57500/57500 [==============================] - 4s 64us/step - loss: 0.7244 - acc: 0.7350 - val_loss: 0.5651 - val_acc: 0.7760\n",
      "Epoch 60/150\n",
      "57500/57500 [==============================] - 4s 64us/step - loss: 0.7294 - acc: 0.7339 - val_loss: 0.5610 - val_acc: 0.7850\n",
      "Epoch 61/150\n",
      "57500/57500 [==============================] - 3s 56us/step - loss: 0.7272 - acc: 0.7358 - val_loss: 0.5610 - val_acc: 0.7790\n",
      "Epoch 62/150\n",
      "57500/57500 [==============================] - 3s 45us/step - loss: 0.7237 - acc: 0.7386 - val_loss: 0.5590 - val_acc: 0.7830\n",
      "Epoch 63/150\n",
      "57500/57500 [==============================] - 3s 47us/step - loss: 0.7224 - acc: 0.7382 - val_loss: 0.5608 - val_acc: 0.7810\n",
      "Epoch 64/150\n",
      "57500/57500 [==============================] - 3s 47us/step - loss: 0.7189 - acc: 0.7367 - val_loss: 0.5620 - val_acc: 0.7760\n",
      "Epoch 65/150\n",
      "57500/57500 [==============================] - 3s 47us/step - loss: 0.7126 - acc: 0.7387 - val_loss: 0.5584 - val_acc: 0.7810\n",
      "Epoch 66/150\n",
      "57500/57500 [==============================] - 3s 45us/step - loss: 0.7157 - acc: 0.7398 - val_loss: 0.5601 - val_acc: 0.7790\n",
      "Epoch 67/150\n",
      "57500/57500 [==============================] - 3s 45us/step - loss: 0.7118 - acc: 0.7406 - val_loss: 0.5586 - val_acc: 0.7830\n",
      "Epoch 68/150\n",
      "57500/57500 [==============================] - 3s 47us/step - loss: 0.7090 - acc: 0.7431 - val_loss: 0.5564 - val_acc: 0.7860\n",
      "Epoch 69/150\n",
      "57500/57500 [==============================] - 2s 43us/step - loss: 0.7084 - acc: 0.7420 - val_loss: 0.5568 - val_acc: 0.7860\n",
      "Epoch 70/150\n",
      "57500/57500 [==============================] - 3s 48us/step - loss: 0.7089 - acc: 0.7433 - val_loss: 0.5555 - val_acc: 0.7870\n",
      "Epoch 71/150\n",
      "57500/57500 [==============================] - 3s 54us/step - loss: 0.7039 - acc: 0.7420 - val_loss: 0.5530 - val_acc: 0.7890\n",
      "Epoch 72/150\n",
      "57500/57500 [==============================] - 3s 47us/step - loss: 0.7001 - acc: 0.7446 - val_loss: 0.5528 - val_acc: 0.7870\n",
      "Epoch 73/150\n",
      "57500/57500 [==============================] - 3s 46us/step - loss: 0.6989 - acc: 0.7432 - val_loss: 0.5536 - val_acc: 0.7880\n",
      "Epoch 74/150\n",
      "57500/57500 [==============================] - 3s 46us/step - loss: 0.6990 - acc: 0.7468 - val_loss: 0.5507 - val_acc: 0.7890\n",
      "Epoch 75/150\n",
      "57500/57500 [==============================] - 3s 45us/step - loss: 0.7000 - acc: 0.7439 - val_loss: 0.5516 - val_acc: 0.7910\n",
      "Epoch 76/150\n",
      "57500/57500 [==============================] - 3s 46us/step - loss: 0.6945 - acc: 0.7470 - val_loss: 0.5499 - val_acc: 0.7880\n",
      "Epoch 77/150\n",
      "57500/57500 [==============================] - 3s 45us/step - loss: 0.6940 - acc: 0.7459 - val_loss: 0.5506 - val_acc: 0.7880\n",
      "Epoch 78/150\n",
      "57500/57500 [==============================] - 3s 45us/step - loss: 0.6924 - acc: 0.7479 - val_loss: 0.5486 - val_acc: 0.7890\n",
      "Epoch 79/150\n",
      "57500/57500 [==============================] - 3s 46us/step - loss: 0.6949 - acc: 0.7484 - val_loss: 0.5498 - val_acc: 0.7950\n",
      "Epoch 80/150\n",
      "57500/57500 [==============================] - 3s 46us/step - loss: 0.6909 - acc: 0.7483 - val_loss: 0.5501 - val_acc: 0.7930\n",
      "Epoch 81/150\n",
      "57500/57500 [==============================] - 3s 45us/step - loss: 0.6918 - acc: 0.7475 - val_loss: 0.5485 - val_acc: 0.7910\n",
      "Epoch 82/150\n",
      "57500/57500 [==============================] - 3s 47us/step - loss: 0.6893 - acc: 0.7500 - val_loss: 0.5488 - val_acc: 0.7920\n",
      "Epoch 83/150\n",
      "57500/57500 [==============================] - 3s 46us/step - loss: 0.6856 - acc: 0.7499 - val_loss: 0.5475 - val_acc: 0.7930\n",
      "Epoch 84/150\n",
      "57500/57500 [==============================] - 3s 46us/step - loss: 0.6874 - acc: 0.7506 - val_loss: 0.5453 - val_acc: 0.7930\n",
      "Epoch 85/150\n",
      "57500/57500 [==============================] - 3s 46us/step - loss: 0.6813 - acc: 0.7521 - val_loss: 0.5460 - val_acc: 0.7940\n",
      "Epoch 86/150\n",
      "57500/57500 [==============================] - 3s 45us/step - loss: 0.6845 - acc: 0.7513 - val_loss: 0.5455 - val_acc: 0.7910\n",
      "Epoch 87/150\n",
      "57500/57500 [==============================] - 3s 47us/step - loss: 0.6806 - acc: 0.7518 - val_loss: 0.5429 - val_acc: 0.7960\n",
      "Epoch 88/150\n",
      "57500/57500 [==============================] - 3s 45us/step - loss: 0.6782 - acc: 0.7530 - val_loss: 0.5441 - val_acc: 0.7960\n",
      "Epoch 89/150\n",
      "57500/57500 [==============================] - 3s 47us/step - loss: 0.6750 - acc: 0.7552 - val_loss: 0.5431 - val_acc: 0.7970\n",
      "Epoch 90/150\n",
      "57500/57500 [==============================] - 3s 49us/step - loss: 0.6753 - acc: 0.7544 - val_loss: 0.5416 - val_acc: 0.7910\n",
      "Epoch 91/150\n",
      "57500/57500 [==============================] - 3s 46us/step - loss: 0.6737 - acc: 0.7541 - val_loss: 0.5447 - val_acc: 0.7920\n",
      "Epoch 92/150\n",
      "57500/57500 [==============================] - 3s 46us/step - loss: 0.6697 - acc: 0.7571 - val_loss: 0.5447 - val_acc: 0.7910\n",
      "Epoch 93/150\n",
      "57500/57500 [==============================] - 3s 46us/step - loss: 0.6700 - acc: 0.7560 - val_loss: 0.5418 - val_acc: 0.7940\n",
      "Epoch 94/150\n",
      "57500/57500 [==============================] - 3s 47us/step - loss: 0.6727 - acc: 0.7568 - val_loss: 0.5439 - val_acc: 0.7920\n",
      "Epoch 95/150\n",
      "57500/57500 [==============================] - 3s 45us/step - loss: 0.6696 - acc: 0.7578 - val_loss: 0.5442 - val_acc: 0.7900\n",
      "Epoch 96/150\n",
      "57500/57500 [==============================] - 3s 47us/step - loss: 0.6710 - acc: 0.7558 - val_loss: 0.5407 - val_acc: 0.7920\n",
      "Epoch 97/150\n",
      "57500/57500 [==============================] - 3s 50us/step - loss: 0.6677 - acc: 0.7605 - val_loss: 0.5409 - val_acc: 0.7900\n",
      "Epoch 98/150\n",
      "57500/57500 [==============================] - 3s 47us/step - loss: 0.6658 - acc: 0.7587 - val_loss: 0.5400 - val_acc: 0.7930\n",
      "Epoch 99/150\n",
      "57500/57500 [==============================] - 3s 48us/step - loss: 0.6662 - acc: 0.7597 - val_loss: 0.5392 - val_acc: 0.7950\n",
      "Epoch 100/150\n",
      "57500/57500 [==============================] - 3s 48us/step - loss: 0.6605 - acc: 0.7605 - val_loss: 0.5386 - val_acc: 0.7930\n",
      "Epoch 101/150\n",
      "57500/57500 [==============================] - 3s 46us/step - loss: 0.6593 - acc: 0.7619 - val_loss: 0.5390 - val_acc: 0.7920\n",
      "Epoch 102/150\n",
      "57500/57500 [==============================] - 3s 46us/step - loss: 0.6666 - acc: 0.7587 - val_loss: 0.5408 - val_acc: 0.7950\n",
      "Epoch 103/150\n",
      "57500/57500 [==============================] - 3s 47us/step - loss: 0.6602 - acc: 0.7615 - val_loss: 0.5384 - val_acc: 0.7970\n",
      "Epoch 104/150\n",
      "57500/57500 [==============================] - 3s 46us/step - loss: 0.6563 - acc: 0.7606 - val_loss: 0.5393 - val_acc: 0.7950\n",
      "Epoch 105/150\n",
      "57500/57500 [==============================] - 3s 47us/step - loss: 0.6557 - acc: 0.7618 - val_loss: 0.5372 - val_acc: 0.7940\n",
      "Epoch 106/150\n",
      "57500/57500 [==============================] - 3s 48us/step - loss: 0.6550 - acc: 0.7629 - val_loss: 0.5372 - val_acc: 0.7950\n",
      "Epoch 107/150\n",
      "57500/57500 [==============================] - 3s 49us/step - loss: 0.6625 - acc: 0.7597 - val_loss: 0.5409 - val_acc: 0.7960\n",
      "Epoch 108/150\n",
      "57500/57500 [==============================] - 3s 49us/step - loss: 0.6555 - acc: 0.7615 - val_loss: 0.5373 - val_acc: 0.7960\n",
      "Epoch 109/150\n",
      "57500/57500 [==============================] - 3s 50us/step - loss: 0.6566 - acc: 0.7645 - val_loss: 0.5341 - val_acc: 0.7990\n",
      "Epoch 110/150\n",
      "57500/57500 [==============================] - 3s 53us/step - loss: 0.6536 - acc: 0.7645 - val_loss: 0.5365 - val_acc: 0.7960\n",
      "Epoch 111/150\n",
      "57500/57500 [==============================] - 3s 49us/step - loss: 0.6523 - acc: 0.7660 - val_loss: 0.5341 - val_acc: 0.7970\n",
      "Epoch 112/150\n",
      "57500/57500 [==============================] - 3s 52us/step - loss: 0.6497 - acc: 0.7650 - val_loss: 0.5340 - val_acc: 0.7990\n",
      "Epoch 113/150\n",
      "57500/57500 [==============================] - 3s 49us/step - loss: 0.6560 - acc: 0.7617 - val_loss: 0.5338 - val_acc: 0.8010\n",
      "Epoch 114/150\n",
      "57500/57500 [==============================] - 3s 47us/step - loss: 0.6481 - acc: 0.7663 - val_loss: 0.5342 - val_acc: 0.8000\n",
      "Epoch 115/150\n",
      "57500/57500 [==============================] - 3s 47us/step - loss: 0.6494 - acc: 0.7665 - val_loss: 0.5332 - val_acc: 0.7990\n",
      "Epoch 116/150\n",
      "57500/57500 [==============================] - 3s 46us/step - loss: 0.6460 - acc: 0.7675 - val_loss: 0.5370 - val_acc: 0.8010\n",
      "Epoch 117/150\n",
      "57500/57500 [==============================] - 3s 46us/step - loss: 0.6482 - acc: 0.7668 - val_loss: 0.5323 - val_acc: 0.8020\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 118/150\n",
      "57500/57500 [==============================] - 3s 47us/step - loss: 0.6431 - acc: 0.7672 - val_loss: 0.5328 - val_acc: 0.8040\n",
      "Epoch 119/150\n",
      "57500/57500 [==============================] - 3s 47us/step - loss: 0.6485 - acc: 0.7656 - val_loss: 0.5334 - val_acc: 0.7980\n",
      "Epoch 120/150\n",
      "57500/57500 [==============================] - 3s 49us/step - loss: 0.6471 - acc: 0.7677 - val_loss: 0.5323 - val_acc: 0.8000\n",
      "Epoch 121/150\n",
      "57500/57500 [==============================] - 3s 46us/step - loss: 0.6417 - acc: 0.7678 - val_loss: 0.5313 - val_acc: 0.8030\n",
      "Epoch 122/150\n",
      "57500/57500 [==============================] - 3s 47us/step - loss: 0.6453 - acc: 0.7663 - val_loss: 0.5294 - val_acc: 0.7980\n",
      "Epoch 123/150\n",
      "57500/57500 [==============================] - 3s 47us/step - loss: 0.6419 - acc: 0.7668 - val_loss: 0.5299 - val_acc: 0.8050\n",
      "Epoch 124/150\n",
      "57500/57500 [==============================] - 3s 46us/step - loss: 0.6390 - acc: 0.7683 - val_loss: 0.5285 - val_acc: 0.8020\n",
      "Epoch 125/150\n",
      "57500/57500 [==============================] - 3s 46us/step - loss: 0.6438 - acc: 0.7685 - val_loss: 0.5298 - val_acc: 0.8000\n",
      "Epoch 126/150\n",
      "57500/57500 [==============================] - 3s 47us/step - loss: 0.6431 - acc: 0.7687 - val_loss: 0.5294 - val_acc: 0.8020\n",
      "Epoch 127/150\n",
      "57500/57500 [==============================] - 3s 47us/step - loss: 0.6359 - acc: 0.7695 - val_loss: 0.5321 - val_acc: 0.8010\n",
      "Epoch 128/150\n",
      "57500/57500 [==============================] - 3s 47us/step - loss: 0.6386 - acc: 0.7687 - val_loss: 0.5298 - val_acc: 0.8040\n",
      "Epoch 129/150\n",
      "57500/57500 [==============================] - 3s 46us/step - loss: 0.6403 - acc: 0.7714 - val_loss: 0.5298 - val_acc: 0.8020\n",
      "Epoch 130/150\n",
      "57500/57500 [==============================] - 3s 47us/step - loss: 0.6416 - acc: 0.7681 - val_loss: 0.5338 - val_acc: 0.7990\n",
      "Epoch 131/150\n",
      "57500/57500 [==============================] - 3s 47us/step - loss: 0.6369 - acc: 0.7714 - val_loss: 0.5315 - val_acc: 0.8060\n",
      "Epoch 132/150\n",
      "57500/57500 [==============================] - 3s 46us/step - loss: 0.6384 - acc: 0.7698 - val_loss: 0.5293 - val_acc: 0.8050\n",
      "Epoch 133/150\n",
      "57500/57500 [==============================] - 3s 46us/step - loss: 0.6316 - acc: 0.7722 - val_loss: 0.5298 - val_acc: 0.8050\n",
      "Epoch 134/150\n",
      "57500/57500 [==============================] - 3s 48us/step - loss: 0.6322 - acc: 0.7736 - val_loss: 0.5310 - val_acc: 0.8060\n",
      "Epoch 135/150\n",
      "57500/57500 [==============================] - 3s 48us/step - loss: 0.6378 - acc: 0.7712 - val_loss: 0.5306 - val_acc: 0.8050\n",
      "Epoch 136/150\n",
      "57500/57500 [==============================] - 3s 48us/step - loss: 0.6315 - acc: 0.7716 - val_loss: 0.5301 - val_acc: 0.8020\n",
      "Epoch 137/150\n",
      "57500/57500 [==============================] - 3s 45us/step - loss: 0.6381 - acc: 0.7701 - val_loss: 0.5280 - val_acc: 0.8060\n",
      "Epoch 138/150\n",
      "57500/57500 [==============================] - 3s 47us/step - loss: 0.6338 - acc: 0.7720 - val_loss: 0.5266 - val_acc: 0.8040\n",
      "Epoch 139/150\n",
      "57500/57500 [==============================] - 3s 48us/step - loss: 0.6293 - acc: 0.7742 - val_loss: 0.5264 - val_acc: 0.8040\n",
      "Epoch 140/150\n",
      "57500/57500 [==============================] - 3s 46us/step - loss: 0.6315 - acc: 0.7723 - val_loss: 0.5284 - val_acc: 0.8080\n",
      "Epoch 141/150\n",
      "57500/57500 [==============================] - 3s 49us/step - loss: 0.6284 - acc: 0.7733 - val_loss: 0.5278 - val_acc: 0.8080\n",
      "Epoch 142/150\n",
      "57500/57500 [==============================] - 3s 47us/step - loss: 0.6293 - acc: 0.7745 - val_loss: 0.5270 - val_acc: 0.8090\n",
      "Epoch 143/150\n",
      "57500/57500 [==============================] - 3s 47us/step - loss: 0.6338 - acc: 0.7751 - val_loss: 0.5260 - val_acc: 0.8030\n",
      "Epoch 144/150\n",
      "57500/57500 [==============================] - 3s 47us/step - loss: 0.6310 - acc: 0.7727 - val_loss: 0.5252 - val_acc: 0.8080\n",
      "Epoch 145/150\n",
      "57500/57500 [==============================] - 3s 46us/step - loss: 0.6244 - acc: 0.7761 - val_loss: 0.5249 - val_acc: 0.8060\n",
      "Epoch 146/150\n",
      "57500/57500 [==============================] - 3s 47us/step - loss: 0.6219 - acc: 0.7751 - val_loss: 0.5215 - val_acc: 0.8080\n",
      "Epoch 147/150\n",
      "57500/57500 [==============================] - 3s 45us/step - loss: 0.6283 - acc: 0.7759 - val_loss: 0.5247 - val_acc: 0.8090\n",
      "Epoch 148/150\n",
      "57500/57500 [==============================] - 3s 45us/step - loss: 0.6281 - acc: 0.7746 - val_loss: 0.5275 - val_acc: 0.8050\n",
      "Epoch 149/150\n",
      "57500/57500 [==============================] - 3s 46us/step - loss: 0.6253 - acc: 0.7759 - val_loss: 0.5244 - val_acc: 0.8040\n",
      "Epoch 150/150\n",
      "57500/57500 [==============================] - 3s 47us/step - loss: 0.6275 - acc: 0.7741 - val_loss: 0.5233 - val_acc: 0.8080\n"
     ]
    }
   ],
   "source": [
    "# ⏰ This cell may take about a minute to run\n",
    "random.seed(123)\n",
    "from keras.layers import Dropout\n",
    "\n",
    "dropout_model = models.Sequential()\n",
    "\n",
    "# Implement dropout to the input layer\n",
    "# NOTE: This is where you define the number of units in the input layer\n",
    "dropout_model = models.Sequential()\n",
    "dropout_model.add(Dropout(0.3))\n",
    "dropout_model.add(layers.Dense(50, activation='relu', input_shape=(2000,)))\n",
    "dropout_model.add(Dropout(0.3))\n",
    "dropout_model.add(layers.Dense(25, activation='relu'))\n",
    "dropout_model.add(Dropout(0.3))\n",
    "\n",
    "\n",
    "\n",
    "# Add the output layer\n",
    "dropout_model.add(layers.Dense(7, activation='softmax'))\n",
    "\n",
    "\n",
    "# Compile the model\n",
    "dropout_model.compile(optimizer='SGD', \n",
    "                      loss='categorical_crossentropy', \n",
    "                      metrics=['accuracy'])\n",
    "\n",
    "# Train the model\n",
    "dropout_model_val = dropout_model.fit(X_train_tokens, \n",
    "                                      y_train_lb, \n",
    "                                      epochs=150, \n",
    "                                      batch_size=256, \n",
    "                                      validation_data=(X_val_tokens, y_val_lb))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "57500/57500 [==============================] - 6s 97us/step\n",
      "Training Loss: 0.4 \n",
      "Training Accuracy: 0.865\n",
      "----------\n",
      "1500/1500 [==============================] - 0s 161us/step\n",
      "Test Loss: 0.496 \n",
      "Test Accuracy: 0.802\n"
     ]
    }
   ],
   "source": [
    "results_train = dropout_model.evaluate(X_train_tokens, y_train_lb)\n",
    "print(f'Training Loss: {results_train[0]:.3} \\nTraining Accuracy: {results_train[1]:.3}')\n",
    "\n",
    "print('----------')\n",
    "\n",
    "results_test = dropout_model.evaluate(X_test_tokens, y_test_lb)\n",
    "print(f'Test Loss: {results_test[0]:.3} \\nTest Accuracy: {results_test[1]:.3}') "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "You can see here that the validation performance has improved again, and the training and test accuracy are very close!  \n",
    "\n",
    "## Bigger Data? \n",
    "\n",
    "Finally, let's examine if we can improve the model's performance just by adding more data. We've quadrapled the sample dataset from 10,000 to 40,000 observations, and all you need to do is run the code! "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_bigger_sample = df.sample(40000, random_state=123)\n",
    "\n",
    "X = df['Consumer complaint narrative']\n",
    "y = df['Product']\n",
    "\n",
    "# Train-test split\n",
    "X_train_bigger, X_test_bigger, y_train_bigger, y_test_bigger = train_test_split(X, \n",
    "                                                                                y, \n",
    "                                                                                test_size=6000, \n",
    "                                                                                random_state=42)\n",
    "\n",
    "# Validation set\n",
    "X_train_final_bigger, X_val_bigger, y_train_final_bigger, y_val_bigger = train_test_split(X_train_bigger, \n",
    "                                                                                          y_train_bigger, \n",
    "                                                                                          test_size=4000, \n",
    "                                                                                          random_state=42)\n",
    "\n",
    "\n",
    "# One-hot encoding of the complaints\n",
    "tokenizer = Tokenizer(num_words=2000)\n",
    "tokenizer.fit_on_texts(X_train_final_bigger)\n",
    "\n",
    "X_train_tokens_bigger = tokenizer.texts_to_matrix(X_train_final_bigger, mode='binary')\n",
    "X_val_tokens_bigger = tokenizer.texts_to_matrix(X_val_bigger, mode='binary')\n",
    "X_test_tokens_bigger = tokenizer.texts_to_matrix(X_test_bigger, mode='binary')\n",
    "\n",
    "# One-hot encoding of products\n",
    "lb = LabelBinarizer()\n",
    "lb.fit(y_train_final_bigger)\n",
    "\n",
    "y_train_lb_bigger = to_categorical(lb.transform(y_train_final_bigger))[:, :, 1]\n",
    "y_val_lb_bigger = to_categorical(lb.transform(y_val_bigger))[:, :, 1]\n",
    "y_test_lb_bigger = to_categorical(lb.transform(y_test_bigger))[:, :, 1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 50000 samples, validate on 4000 samples\n",
      "Epoch 1/150\n",
      "50000/50000 [==============================] - 3s 60us/step - loss: 1.8887 - acc: 0.2338 - val_loss: 1.8196 - val_acc: 0.3007\n",
      "Epoch 2/150\n",
      "50000/50000 [==============================] - 2s 33us/step - loss: 1.6988 - acc: 0.3868 - val_loss: 1.5705 - val_acc: 0.4547\n",
      "Epoch 3/150\n",
      "50000/50000 [==============================] - 2s 34us/step - loss: 1.4063 - acc: 0.5400 - val_loss: 1.2740 - val_acc: 0.5988\n",
      "Epoch 4/150\n",
      "50000/50000 [==============================] - 2s 32us/step - loss: 1.1346 - acc: 0.6535 - val_loss: 1.0427 - val_acc: 0.6655\n",
      "Epoch 5/150\n",
      "50000/50000 [==============================] - 2s 35us/step - loss: 0.9428 - acc: 0.6996 - val_loss: 0.8960 - val_acc: 0.6967\n",
      "Epoch 6/150\n",
      "50000/50000 [==============================] - 2s 34us/step - loss: 0.8234 - acc: 0.7257 - val_loss: 0.8046 - val_acc: 0.7205\n",
      "Epoch 7/150\n",
      "50000/50000 [==============================] - 2s 34us/step - loss: 0.7498 - acc: 0.7403 - val_loss: 0.7488 - val_acc: 0.7328\n",
      "Epoch 8/150\n",
      "50000/50000 [==============================] - 2s 35us/step - loss: 0.7014 - acc: 0.7518 - val_loss: 0.7117 - val_acc: 0.7423\n",
      "Epoch 9/150\n",
      "50000/50000 [==============================] - 2s 33us/step - loss: 0.6671 - acc: 0.7611 - val_loss: 0.6854 - val_acc: 0.7480\n",
      "Epoch 10/150\n",
      "50000/50000 [==============================] - 2s 32us/step - loss: 0.6413 - acc: 0.7674 - val_loss: 0.6640 - val_acc: 0.7550\n",
      "Epoch 11/150\n",
      "50000/50000 [==============================] - 2s 34us/step - loss: 0.6207 - acc: 0.7739 - val_loss: 0.6489 - val_acc: 0.7653\n",
      "Epoch 12/150\n",
      "50000/50000 [==============================] - 2s 33us/step - loss: 0.6035 - acc: 0.7795 - val_loss: 0.6361 - val_acc: 0.7703\n",
      "Epoch 13/150\n",
      "50000/50000 [==============================] - 2s 48us/step - loss: 0.5888 - acc: 0.7856 - val_loss: 0.6226 - val_acc: 0.7722\n",
      "Epoch 14/150\n",
      "50000/50000 [==============================] - 2s 39us/step - loss: 0.5760 - acc: 0.7898 - val_loss: 0.6168 - val_acc: 0.7740\n",
      "Epoch 15/150\n",
      "50000/50000 [==============================] - 2s 48us/step - loss: 0.5648 - acc: 0.7941 - val_loss: 0.6048 - val_acc: 0.7807\n",
      "Epoch 16/150\n",
      "50000/50000 [==============================] - 2s 46us/step - loss: 0.5542 - acc: 0.7988 - val_loss: 0.5986 - val_acc: 0.7842\n",
      "Epoch 17/150\n",
      "50000/50000 [==============================] - 2s 48us/step - loss: 0.5449 - acc: 0.8032 - val_loss: 0.5940 - val_acc: 0.7873\n",
      "Epoch 18/150\n",
      "50000/50000 [==============================] - 2s 36us/step - loss: 0.5364 - acc: 0.8061 - val_loss: 0.5859 - val_acc: 0.7890\n",
      "Epoch 19/150\n",
      "50000/50000 [==============================] - 2s 35us/step - loss: 0.5284 - acc: 0.8091 - val_loss: 0.5814 - val_acc: 0.7903\n",
      "Epoch 20/150\n",
      "50000/50000 [==============================] - 2s 33us/step - loss: 0.5213 - acc: 0.8136 - val_loss: 0.5769 - val_acc: 0.7932\n",
      "Epoch 21/150\n",
      "50000/50000 [==============================] - 2s 34us/step - loss: 0.5141 - acc: 0.8152 - val_loss: 0.5738 - val_acc: 0.7920\n",
      "Epoch 22/150\n",
      "50000/50000 [==============================] - 2s 32us/step - loss: 0.5077 - acc: 0.8169 - val_loss: 0.5705 - val_acc: 0.7940\n",
      "Epoch 23/150\n",
      "50000/50000 [==============================] - 2s 32us/step - loss: 0.5019 - acc: 0.8204 - val_loss: 0.5671 - val_acc: 0.7945\n",
      "Epoch 24/150\n",
      "50000/50000 [==============================] - 2s 32us/step - loss: 0.4962 - acc: 0.8224 - val_loss: 0.5630 - val_acc: 0.7980\n",
      "Epoch 25/150\n",
      "50000/50000 [==============================] - 2s 31us/step - loss: 0.4908 - acc: 0.8243 - val_loss: 0.5608 - val_acc: 0.8047\n",
      "Epoch 26/150\n",
      "50000/50000 [==============================] - 2s 32us/step - loss: 0.4857 - acc: 0.8262 - val_loss: 0.5584 - val_acc: 0.8000\n",
      "Epoch 27/150\n",
      "50000/50000 [==============================] - 2s 32us/step - loss: 0.4815 - acc: 0.8272 - val_loss: 0.5558 - val_acc: 0.8035\n",
      "Epoch 28/150\n",
      "50000/50000 [==============================] - 2s 32us/step - loss: 0.4764 - acc: 0.8296 - val_loss: 0.5526 - val_acc: 0.8043\n",
      "Epoch 29/150\n",
      "50000/50000 [==============================] - 2s 33us/step - loss: 0.4721 - acc: 0.8321 - val_loss: 0.5544 - val_acc: 0.8085\n",
      "Epoch 30/150\n",
      "50000/50000 [==============================] - 2s 32us/step - loss: 0.4677 - acc: 0.8333 - val_loss: 0.5496 - val_acc: 0.8058\n",
      "Epoch 31/150\n",
      "50000/50000 [==============================] - 2s 32us/step - loss: 0.4640 - acc: 0.8343 - val_loss: 0.5493 - val_acc: 0.8080\n",
      "Epoch 32/150\n",
      "50000/50000 [==============================] - 2s 34us/step - loss: 0.4599 - acc: 0.8359 - val_loss: 0.5508 - val_acc: 0.8110\n",
      "Epoch 33/150\n",
      "50000/50000 [==============================] - 2s 33us/step - loss: 0.4565 - acc: 0.8380 - val_loss: 0.5449 - val_acc: 0.8070\n",
      "Epoch 34/150\n",
      "50000/50000 [==============================] - 2s 35us/step - loss: 0.4530 - acc: 0.8387 - val_loss: 0.5471 - val_acc: 0.8042\n",
      "Epoch 35/150\n",
      "50000/50000 [==============================] - 2s 34us/step - loss: 0.4494 - acc: 0.8398 - val_loss: 0.5444 - val_acc: 0.8100\n",
      "Epoch 36/150\n",
      "50000/50000 [==============================] - 2s 33us/step - loss: 0.4461 - acc: 0.8421 - val_loss: 0.5425 - val_acc: 0.8085\n",
      "Epoch 37/150\n",
      "50000/50000 [==============================] - 2s 33us/step - loss: 0.4428 - acc: 0.8434 - val_loss: 0.5440 - val_acc: 0.8060\n",
      "Epoch 38/150\n",
      "50000/50000 [==============================] - 2s 33us/step - loss: 0.4398 - acc: 0.8452 - val_loss: 0.5397 - val_acc: 0.8120\n",
      "Epoch 39/150\n",
      "50000/50000 [==============================] - 2s 34us/step - loss: 0.4369 - acc: 0.8460 - val_loss: 0.5396 - val_acc: 0.8100\n",
      "Epoch 40/150\n",
      "50000/50000 [==============================] - 2s 34us/step - loss: 0.4340 - acc: 0.8474 - val_loss: 0.5422 - val_acc: 0.8085\n",
      "Epoch 41/150\n",
      "50000/50000 [==============================] - 2s 34us/step - loss: 0.4312 - acc: 0.8491 - val_loss: 0.5380 - val_acc: 0.8145\n",
      "Epoch 42/150\n",
      "50000/50000 [==============================] - 2s 32us/step - loss: 0.4285 - acc: 0.8500 - val_loss: 0.5370 - val_acc: 0.8118\n",
      "Epoch 43/150\n",
      "50000/50000 [==============================] - 2s 32us/step - loss: 0.4259 - acc: 0.8506 - val_loss: 0.5380 - val_acc: 0.8120\n",
      "Epoch 44/150\n",
      "50000/50000 [==============================] - 2s 33us/step - loss: 0.4234 - acc: 0.8514 - val_loss: 0.5383 - val_acc: 0.8117\n",
      "Epoch 45/150\n",
      "50000/50000 [==============================] - 2s 33us/step - loss: 0.4210 - acc: 0.8523 - val_loss: 0.5363 - val_acc: 0.8140\n",
      "Epoch 46/150\n",
      "50000/50000 [==============================] - 2s 33us/step - loss: 0.4184 - acc: 0.8531 - val_loss: 0.5364 - val_acc: 0.8138\n",
      "Epoch 47/150\n",
      "50000/50000 [==============================] - 2s 33us/step - loss: 0.4164 - acc: 0.8535 - val_loss: 0.5349 - val_acc: 0.8123\n",
      "Epoch 48/150\n",
      "50000/50000 [==============================] - 2s 33us/step - loss: 0.4141 - acc: 0.8547 - val_loss: 0.5358 - val_acc: 0.8147\n",
      "Epoch 49/150\n",
      "50000/50000 [==============================] - 2s 32us/step - loss: 0.4116 - acc: 0.8560 - val_loss: 0.5368 - val_acc: 0.8110\n",
      "Epoch 50/150\n",
      "50000/50000 [==============================] - 2s 32us/step - loss: 0.4092 - acc: 0.8565 - val_loss: 0.5372 - val_acc: 0.8115\n",
      "Epoch 51/150\n",
      "50000/50000 [==============================] - 2s 34us/step - loss: 0.4075 - acc: 0.8571 - val_loss: 0.5368 - val_acc: 0.8110\n",
      "Epoch 52/150\n",
      "50000/50000 [==============================] - 2s 33us/step - loss: 0.4055 - acc: 0.8577 - val_loss: 0.5367 - val_acc: 0.8123\n",
      "Epoch 53/150\n",
      "50000/50000 [==============================] - 2s 33us/step - loss: 0.4032 - acc: 0.8593 - val_loss: 0.5340 - val_acc: 0.8130\n",
      "Epoch 54/150\n",
      "50000/50000 [==============================] - 2s 33us/step - loss: 0.4012 - acc: 0.8598 - val_loss: 0.5382 - val_acc: 0.8120\n",
      "Epoch 55/150\n",
      "50000/50000 [==============================] - 2s 33us/step - loss: 0.3997 - acc: 0.8607 - val_loss: 0.5362 - val_acc: 0.8140\n",
      "Epoch 56/150\n",
      "50000/50000 [==============================] - 2s 33us/step - loss: 0.3976 - acc: 0.8605 - val_loss: 0.5361 - val_acc: 0.8143\n",
      "Epoch 57/150\n",
      "50000/50000 [==============================] - 2s 32us/step - loss: 0.3956 - acc: 0.8623 - val_loss: 0.5347 - val_acc: 0.8132\n",
      "Epoch 58/150\n",
      "50000/50000 [==============================] - 2s 31us/step - loss: 0.3939 - acc: 0.8628 - val_loss: 0.5358 - val_acc: 0.8125\n",
      "Epoch 59/150\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "50000/50000 [==============================] - 2s 32us/step - loss: 0.3921 - acc: 0.8639 - val_loss: 0.5394 - val_acc: 0.8130\n",
      "Epoch 60/150\n",
      "50000/50000 [==============================] - 2s 33us/step - loss: 0.3905 - acc: 0.8647 - val_loss: 0.5382 - val_acc: 0.8133\n",
      "Epoch 61/150\n",
      "50000/50000 [==============================] - 2s 33us/step - loss: 0.3887 - acc: 0.8643 - val_loss: 0.5387 - val_acc: 0.8113\n",
      "Epoch 62/150\n",
      "50000/50000 [==============================] - 2s 32us/step - loss: 0.3872 - acc: 0.8650 - val_loss: 0.5408 - val_acc: 0.8108\n",
      "Epoch 63/150\n",
      "50000/50000 [==============================] - 2s 32us/step - loss: 0.3855 - acc: 0.8653 - val_loss: 0.5390 - val_acc: 0.8067\n",
      "Epoch 64/150\n",
      "50000/50000 [==============================] - 2s 33us/step - loss: 0.3838 - acc: 0.8654 - val_loss: 0.5382 - val_acc: 0.8108\n",
      "Epoch 65/150\n",
      "50000/50000 [==============================] - 2s 33us/step - loss: 0.3821 - acc: 0.8677 - val_loss: 0.5399 - val_acc: 0.8135\n",
      "Epoch 66/150\n",
      "50000/50000 [==============================] - 2s 32us/step - loss: 0.3807 - acc: 0.8675 - val_loss: 0.5388 - val_acc: 0.8083\n",
      "Epoch 67/150\n",
      "50000/50000 [==============================] - 2s 34us/step - loss: 0.3794 - acc: 0.8668 - val_loss: 0.5379 - val_acc: 0.8107\n",
      "Epoch 68/150\n",
      "50000/50000 [==============================] - 2s 32us/step - loss: 0.3777 - acc: 0.8687 - val_loss: 0.5385 - val_acc: 0.8145\n",
      "Epoch 69/150\n",
      "50000/50000 [==============================] - 2s 34us/step - loss: 0.3761 - acc: 0.8691 - val_loss: 0.5391 - val_acc: 0.8115\n",
      "Epoch 70/150\n",
      "50000/50000 [==============================] - 2s 33us/step - loss: 0.3749 - acc: 0.8695 - val_loss: 0.5422 - val_acc: 0.8117\n",
      "Epoch 71/150\n",
      "50000/50000 [==============================] - 2s 31us/step - loss: 0.3734 - acc: 0.8685 - val_loss: 0.5561 - val_acc: 0.7993\n",
      "Epoch 72/150\n",
      "50000/50000 [==============================] - 2s 33us/step - loss: 0.3721 - acc: 0.8697 - val_loss: 0.5471 - val_acc: 0.8043\n",
      "Epoch 73/150\n",
      "50000/50000 [==============================] - 2s 34us/step - loss: 0.3704 - acc: 0.8710 - val_loss: 0.5404 - val_acc: 0.8123\n",
      "Epoch 74/150\n",
      "50000/50000 [==============================] - 2s 32us/step - loss: 0.3690 - acc: 0.8705 - val_loss: 0.5485 - val_acc: 0.8065\n",
      "Epoch 75/150\n",
      "50000/50000 [==============================] - 2s 32us/step - loss: 0.3679 - acc: 0.8712 - val_loss: 0.5412 - val_acc: 0.8138\n",
      "Epoch 76/150\n",
      "50000/50000 [==============================] - 2s 36us/step - loss: 0.3665 - acc: 0.8715 - val_loss: 0.5415 - val_acc: 0.8150\n",
      "Epoch 77/150\n",
      "50000/50000 [==============================] - 2s 34us/step - loss: 0.3652 - acc: 0.8721 - val_loss: 0.5412 - val_acc: 0.8145\n",
      "Epoch 78/150\n",
      "50000/50000 [==============================] - 2s 32us/step - loss: 0.3637 - acc: 0.8731 - val_loss: 0.5487 - val_acc: 0.8103\n",
      "Epoch 79/150\n",
      "50000/50000 [==============================] - 2s 33us/step - loss: 0.3626 - acc: 0.8730 - val_loss: 0.5467 - val_acc: 0.8100\n",
      "Epoch 80/150\n",
      "50000/50000 [==============================] - 2s 35us/step - loss: 0.3617 - acc: 0.8735 - val_loss: 0.5426 - val_acc: 0.8115\n",
      "Epoch 81/150\n",
      "50000/50000 [==============================] - 2s 34us/step - loss: 0.3601 - acc: 0.8738 - val_loss: 0.5453 - val_acc: 0.8138\n",
      "Epoch 82/150\n",
      "50000/50000 [==============================] - 2s 33us/step - loss: 0.3588 - acc: 0.8743 - val_loss: 0.5458 - val_acc: 0.8090\n",
      "Epoch 83/150\n",
      "50000/50000 [==============================] - 2s 33us/step - loss: 0.3575 - acc: 0.8745 - val_loss: 0.5451 - val_acc: 0.8118\n",
      "Epoch 84/150\n",
      "50000/50000 [==============================] - 2s 33us/step - loss: 0.3567 - acc: 0.8752 - val_loss: 0.5522 - val_acc: 0.8038\n",
      "Epoch 85/150\n",
      "50000/50000 [==============================] - 2s 33us/step - loss: 0.3555 - acc: 0.8753 - val_loss: 0.5504 - val_acc: 0.8083\n",
      "Epoch 86/150\n",
      "50000/50000 [==============================] - 2s 33us/step - loss: 0.3542 - acc: 0.8762 - val_loss: 0.5455 - val_acc: 0.8155\n",
      "Epoch 87/150\n",
      "50000/50000 [==============================] - 2s 31us/step - loss: 0.3529 - acc: 0.8758 - val_loss: 0.5586 - val_acc: 0.8060\n",
      "Epoch 88/150\n",
      "50000/50000 [==============================] - 2s 33us/step - loss: 0.3518 - acc: 0.8768 - val_loss: 0.5480 - val_acc: 0.8110\n",
      "Epoch 89/150\n",
      "50000/50000 [==============================] - ETA: 0s - loss: 0.3508 - acc: 0.878 - 2s 33us/step - loss: 0.3506 - acc: 0.8781 - val_loss: 0.5500 - val_acc: 0.8103\n",
      "Epoch 90/150\n",
      "50000/50000 [==============================] - 2s 33us/step - loss: 0.3494 - acc: 0.8775 - val_loss: 0.5481 - val_acc: 0.8150\n",
      "Epoch 91/150\n",
      "50000/50000 [==============================] - 2s 34us/step - loss: 0.3483 - acc: 0.8782 - val_loss: 0.5496 - val_acc: 0.8120\n",
      "Epoch 92/150\n",
      "50000/50000 [==============================] - 2s 33us/step - loss: 0.3474 - acc: 0.8789 - val_loss: 0.5502 - val_acc: 0.8105\n",
      "Epoch 93/150\n",
      "50000/50000 [==============================] - 2s 33us/step - loss: 0.3461 - acc: 0.8789 - val_loss: 0.5497 - val_acc: 0.8140\n",
      "Epoch 94/150\n",
      "50000/50000 [==============================] - 2s 33us/step - loss: 0.3454 - acc: 0.8795 - val_loss: 0.5526 - val_acc: 0.8123\n",
      "Epoch 95/150\n",
      "50000/50000 [==============================] - 2s 32us/step - loss: 0.3439 - acc: 0.8796 - val_loss: 0.5537 - val_acc: 0.8153\n",
      "Epoch 96/150\n",
      "50000/50000 [==============================] - 2s 37us/step - loss: 0.3433 - acc: 0.8790 - val_loss: 0.5503 - val_acc: 0.8113\n",
      "Epoch 97/150\n",
      "50000/50000 [==============================] - 2s 34us/step - loss: 0.3416 - acc: 0.8808 - val_loss: 0.5515 - val_acc: 0.8123\n",
      "Epoch 98/150\n",
      "50000/50000 [==============================] - 2s 34us/step - loss: 0.3410 - acc: 0.8809 - val_loss: 0.5518 - val_acc: 0.8117\n",
      "Epoch 99/150\n",
      "50000/50000 [==============================] - 2s 37us/step - loss: 0.3395 - acc: 0.8813 - val_loss: 0.5543 - val_acc: 0.8100\n",
      "Epoch 100/150\n",
      "50000/50000 [==============================] - 2s 39us/step - loss: 0.3388 - acc: 0.8811 - val_loss: 0.5567 - val_acc: 0.8073\n",
      "Epoch 101/150\n",
      "50000/50000 [==============================] - 2s 33us/step - loss: 0.3377 - acc: 0.8818 - val_loss: 0.5558 - val_acc: 0.8093\n",
      "Epoch 102/150\n",
      "50000/50000 [==============================] - 2s 33us/step - loss: 0.3364 - acc: 0.8815 - val_loss: 0.5566 - val_acc: 0.8095\n",
      "Epoch 103/150\n",
      "50000/50000 [==============================] - 2s 36us/step - loss: 0.3354 - acc: 0.8832 - val_loss: 0.5568 - val_acc: 0.8117\n",
      "Epoch 104/150\n",
      "50000/50000 [==============================] - 2s 42us/step - loss: 0.3345 - acc: 0.8834 - val_loss: 0.5630 - val_acc: 0.8043\n",
      "Epoch 105/150\n",
      "50000/50000 [==============================] - 2s 40us/step - loss: 0.3336 - acc: 0.8838 - val_loss: 0.5628 - val_acc: 0.8067\n",
      "Epoch 106/150\n",
      "50000/50000 [==============================] - 2s 36us/step - loss: 0.3328 - acc: 0.8831 - val_loss: 0.5607 - val_acc: 0.8085\n",
      "Epoch 107/150\n",
      "50000/50000 [==============================] - 2s 33us/step - loss: 0.3313 - acc: 0.8847 - val_loss: 0.5573 - val_acc: 0.8105\n",
      "Epoch 108/150\n",
      "50000/50000 [==============================] - 2s 33us/step - loss: 0.3303 - acc: 0.8846 - val_loss: 0.5594 - val_acc: 0.8115\n",
      "Epoch 109/150\n",
      "50000/50000 [==============================] - 2s 33us/step - loss: 0.3298 - acc: 0.8847 - val_loss: 0.5632 - val_acc: 0.8078\n",
      "Epoch 110/150\n",
      "50000/50000 [==============================] - 2s 34us/step - loss: 0.3283 - acc: 0.8863 - val_loss: 0.5607 - val_acc: 0.8117\n",
      "Epoch 111/150\n",
      "50000/50000 [==============================] - 2s 34us/step - loss: 0.3276 - acc: 0.8857 - val_loss: 0.5629 - val_acc: 0.8085\n",
      "Epoch 112/150\n",
      "50000/50000 [==============================] - 2s 36us/step - loss: 0.3266 - acc: 0.8859 - val_loss: 0.5619 - val_acc: 0.8123\n",
      "Epoch 113/150\n",
      "50000/50000 [==============================] - 2s 33us/step - loss: 0.3258 - acc: 0.8854 - val_loss: 0.5699 - val_acc: 0.8050\n",
      "Epoch 114/150\n",
      "50000/50000 [==============================] - 2s 32us/step - loss: 0.3247 - acc: 0.8870 - val_loss: 0.5640 - val_acc: 0.8103\n",
      "Epoch 115/150\n",
      "50000/50000 [==============================] - 2s 33us/step - loss: 0.3236 - acc: 0.8871 - val_loss: 0.5700 - val_acc: 0.8035\n",
      "Epoch 116/150\n",
      "50000/50000 [==============================] - 2s 33us/step - loss: 0.3226 - acc: 0.8880 - val_loss: 0.5668 - val_acc: 0.8133\n",
      "Epoch 117/150\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "50000/50000 [==============================] - 2s 33us/step - loss: 0.3219 - acc: 0.8880 - val_loss: 0.5668 - val_acc: 0.8085\n",
      "Epoch 118/150\n",
      "50000/50000 [==============================] - 2s 33us/step - loss: 0.3206 - acc: 0.8875 - val_loss: 0.5682 - val_acc: 0.8088\n",
      "Epoch 119/150\n",
      "50000/50000 [==============================] - 2s 33us/step - loss: 0.3196 - acc: 0.8878 - val_loss: 0.5825 - val_acc: 0.8007\n",
      "Epoch 120/150\n",
      "50000/50000 [==============================] - 2s 33us/step - loss: 0.3184 - acc: 0.8894 - val_loss: 0.5717 - val_acc: 0.8125\n",
      "Epoch 121/150\n",
      "50000/50000 [==============================] - 2s 32us/step - loss: 0.3181 - acc: 0.8894 - val_loss: 0.5685 - val_acc: 0.8085\n",
      "Epoch 122/150\n",
      "50000/50000 [==============================] - 2s 33us/step - loss: 0.3168 - acc: 0.8896 - val_loss: 0.5715 - val_acc: 0.8105\n",
      "Epoch 123/150\n",
      "50000/50000 [==============================] - 2s 32us/step - loss: 0.3155 - acc: 0.8904 - val_loss: 0.5749 - val_acc: 0.8033\n",
      "Epoch 124/150\n",
      "50000/50000 [==============================] - 2s 33us/step - loss: 0.3150 - acc: 0.8911 - val_loss: 0.5767 - val_acc: 0.8060\n",
      "Epoch 125/150\n",
      "50000/50000 [==============================] - 2s 33us/step - loss: 0.3139 - acc: 0.8906 - val_loss: 0.5713 - val_acc: 0.8105\n",
      "Epoch 126/150\n",
      "50000/50000 [==============================] - 2s 31us/step - loss: 0.3131 - acc: 0.8911 - val_loss: 0.5748 - val_acc: 0.8062\n",
      "Epoch 127/150\n",
      "50000/50000 [==============================] - 2s 34us/step - loss: 0.3116 - acc: 0.8919 - val_loss: 0.5777 - val_acc: 0.8070\n",
      "Epoch 128/150\n",
      "50000/50000 [==============================] - 2s 33us/step - loss: 0.3110 - acc: 0.8913 - val_loss: 0.5799 - val_acc: 0.8097\n",
      "Epoch 129/150\n",
      "50000/50000 [==============================] - 2s 34us/step - loss: 0.3103 - acc: 0.8923 - val_loss: 0.5758 - val_acc: 0.8063\n",
      "Epoch 130/150\n",
      "50000/50000 [==============================] - 2s 32us/step - loss: 0.3093 - acc: 0.8919 - val_loss: 0.5858 - val_acc: 0.7980\n",
      "Epoch 131/150\n",
      "50000/50000 [==============================] - 2s 32us/step - loss: 0.3081 - acc: 0.8928 - val_loss: 0.5779 - val_acc: 0.8068\n",
      "Epoch 132/150\n",
      "50000/50000 [==============================] - 2s 33us/step - loss: 0.3070 - acc: 0.8928 - val_loss: 0.5835 - val_acc: 0.8047\n",
      "Epoch 133/150\n",
      "50000/50000 [==============================] - 2s 32us/step - loss: 0.3063 - acc: 0.8937 - val_loss: 0.5796 - val_acc: 0.8080\n",
      "Epoch 134/150\n",
      "50000/50000 [==============================] - 2s 31us/step - loss: 0.3055 - acc: 0.8936 - val_loss: 0.5854 - val_acc: 0.8067\n",
      "Epoch 135/150\n",
      "50000/50000 [==============================] - 2s 32us/step - loss: 0.3041 - acc: 0.8946 - val_loss: 0.5802 - val_acc: 0.8055\n",
      "Epoch 136/150\n",
      "50000/50000 [==============================] - 2s 32us/step - loss: 0.3032 - acc: 0.8952 - val_loss: 0.5951 - val_acc: 0.8018\n",
      "Epoch 137/150\n",
      "50000/50000 [==============================] - 2s 31us/step - loss: 0.3027 - acc: 0.8958 - val_loss: 0.5852 - val_acc: 0.8055\n",
      "Epoch 138/150\n",
      "50000/50000 [==============================] - 2s 33us/step - loss: 0.3017 - acc: 0.8958 - val_loss: 0.5835 - val_acc: 0.8100\n",
      "Epoch 139/150\n",
      "50000/50000 [==============================] - 2s 31us/step - loss: 0.3006 - acc: 0.8960 - val_loss: 0.5876 - val_acc: 0.8050\n",
      "Epoch 140/150\n",
      "50000/50000 [==============================] - 2s 34us/step - loss: 0.2998 - acc: 0.8965 - val_loss: 0.5891 - val_acc: 0.8065\n",
      "Epoch 141/150\n",
      "50000/50000 [==============================] - 2s 32us/step - loss: 0.2984 - acc: 0.8970 - val_loss: 0.5864 - val_acc: 0.8083\n",
      "Epoch 142/150\n",
      "50000/50000 [==============================] - ETA: 0s - loss: 0.2978 - acc: 0.896 - 2s 33us/step - loss: 0.2976 - acc: 0.8970 - val_loss: 0.5921 - val_acc: 0.8050\n",
      "Epoch 143/150\n",
      "50000/50000 [==============================] - 2s 32us/step - loss: 0.2966 - acc: 0.8968 - val_loss: 0.5953 - val_acc: 0.8023\n",
      "Epoch 144/150\n",
      "50000/50000 [==============================] - 2s 34us/step - loss: 0.2958 - acc: 0.8974 - val_loss: 0.5893 - val_acc: 0.8055\n",
      "Epoch 145/150\n",
      "50000/50000 [==============================] - 2s 33us/step - loss: 0.2943 - acc: 0.8981 - val_loss: 0.5918 - val_acc: 0.8063\n",
      "Epoch 146/150\n",
      "50000/50000 [==============================] - 2s 32us/step - loss: 0.2934 - acc: 0.8979 - val_loss: 0.5895 - val_acc: 0.8058\n",
      "Epoch 147/150\n",
      "50000/50000 [==============================] - 2s 36us/step - loss: 0.2928 - acc: 0.8992 - val_loss: 0.5948 - val_acc: 0.8088\n",
      "Epoch 148/150\n",
      "50000/50000 [==============================] - 2s 34us/step - loss: 0.2917 - acc: 0.8992 - val_loss: 0.5979 - val_acc: 0.8037\n",
      "Epoch 149/150\n",
      "50000/50000 [==============================] - 2s 35us/step - loss: 0.2906 - acc: 0.9002 - val_loss: 0.5928 - val_acc: 0.8063\n",
      "Epoch 150/150\n",
      "50000/50000 [==============================] - 3s 60us/step - loss: 0.2895 - acc: 0.9012 - val_loss: 0.6035 - val_acc: 0.7983\n"
     ]
    }
   ],
   "source": [
    "# ⏰ This cell may take several minutes to run\n",
    "random.seed(123)\n",
    "bigger_data_model = models.Sequential()\n",
    "bigger_data_model.add(layers.Dense(50, activation='relu', input_shape=(2000,)))\n",
    "bigger_data_model.add(layers.Dense(25, activation='relu'))\n",
    "bigger_data_model.add(layers.Dense(7, activation='softmax'))\n",
    "\n",
    "bigger_data_model.compile(optimizer='SGD', \n",
    "                          loss='categorical_crossentropy', \n",
    "                          metrics=['accuracy'])\n",
    "\n",
    "bigger_data_model_val = bigger_data_model.fit(X_train_tokens_bigger,  \n",
    "                                              y_train_lb_bigger,  \n",
    "                                              epochs=150,  \n",
    "                                              batch_size=256,  \n",
    "                                              validation_data=(X_val_tokens_bigger, y_val_lb_bigger))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "50000/50000 [==============================] - 4s 83us/step\n",
      "Training Loss: 0.293 \n",
      "Training Accuracy: 0.897\n",
      "----------\n",
      "4000/4000 [==============================] - 0s 50us/step\n",
      "Test Loss: 0.603 \n",
      "Test Accuracy: 0.798\n"
     ]
    }
   ],
   "source": [
    "results_train = bigger_data_model.evaluate(X_train_tokens_bigger, y_train_lb_bigger)\n",
    "print(f'Training Loss: {results_train[0]:.3} \\nTraining Accuracy: {results_train[1]:.3}')\n",
    "\n",
    "print('----------')\n",
    "\n",
    "results_test = bigger_data_model.evaluate(X_val_tokens_bigger, y_val_lb_bigger)\n",
    "print(f'Test Loss: {results_test[0]:.3} \\nTest Accuracy: {results_test[1]:.3}')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "With the same amount of epochs and no regularization technique, you were able to get both better test accuracy and loss. You can still consider early stopping, L1, L2 and dropout here. It's clear that having more data has a strong impact on model performance! \n",
    "\n",
    "\n",
    "## Additional Resources\n",
    "\n",
    "* https://github.com/susanli2016/Machine-Learning-with-Python/blob/master/Consumer_complaints.ipynb\n",
    "* https://machinelearningmastery.com/dropout-regularization-deep-learning-models-keras/\n",
    "* https://catalog.data.gov/dataset/consumer-complaint-database \n",
    "\n",
    "\n",
    "## Summary  \n",
    "\n",
    "In this lesson, you built deep learning models using a validation set and used several techniques such as L2 and L1 regularization, dropout regularization, and early stopping to improve the accuracy of your models. "
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python [conda env:learn-env] *",
   "language": "python",
   "name": "conda-env-learn-env-py"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.9"
  },
  "toc": {
   "base_numbering": 1,
   "nav_menu": {},
   "number_sections": true,
   "sideBar": true,
   "skip_h1_title": false,
   "title_cell": "Table of Contents",
   "title_sidebar": "Contents",
   "toc_cell": false,
   "toc_position": {},
   "toc_section_display": true,
   "toc_window_display": false
  },
  "varInspector": {
   "cols": {
    "lenName": 16,
    "lenType": 16,
    "lenVar": 40
   },
   "kernels_config": {
    "python": {
     "delete_cmd_postfix": "",
     "delete_cmd_prefix": "del ",
     "library": "var_list.py",
     "varRefreshCmd": "print(var_dic_list())"
    },
    "r": {
     "delete_cmd_postfix": ") ",
     "delete_cmd_prefix": "rm(",
     "library": "var_list.r",
     "varRefreshCmd": "cat(var_dic_list()) "
    }
   },
   "types_to_exclude": [
    "module",
    "function",
    "builtin_function_or_method",
    "instance",
    "_Feature"
   ],
   "window_display": false
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
